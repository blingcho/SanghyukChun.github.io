<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Machine-Learning-Study | README]]></title>
  <link href="http://SanghyukChun.github.io/blog/categories/machine-learning-study/atom.xml" rel="self"/>
  <link href="http://SanghyukChun.github.io/"/>
  <updated>2014-08-03T16:32:51+09:00</updated>
  <id>http://SanghyukChun.github.io/</id>
  <author>
    <name><![CDATA[Sanghyuk Chun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Machine learning 스터디 (2) Probability Theory]]></title>
    <link href="http://SanghyukChun.github.io/58/"/>
    <updated>2014-08-03T14:18:00+09:00</updated>
    <id>http://SanghyukChun.github.io/58</id>
    <content type="html"><![CDATA[<p>지난 글에서 Machine Learning을 일종의 function 처럼 묘사했었는데, 사실 Machine Learning을 Probability density의 관점에서 보는 것도 가능하다. 이 얘기를 하려면 먼저 Probability density를 포함한 전반적인 probability theory에 대해 먼저 다뤄야할 것 같아서 그 주제로 먼저 글을 써보기로 했다. 일단 엄청 기본적인 내용들, 예를 들어서 조건부 확률이 무엇이고, 이런 얘기들은 일단 생략을 하도록 하겠다. 너무 basic한 얘기이고 \(p(X) = \sum_Y p(X,y) \) 이런거나 \(p(X,Y) = p(Y|X) p(X) \) 이런건 너무나도 기초적인 얘기들이니까. 만약 조건부확률을 잘 모른다면 구글링을 통해 먼저 간단한 지식을 습득하고 오기를 권한다.</p>


<p>다만 그 중에서도 약간 중요하게 다룰만한 주제가 있는데, 그게 바로 Bayes' theorem이다. 이 Theorem 자체는 그냥 간단하게 \(p(X|Y) \)와 \(p(Y|X) \)와의 관계를 표현한 것임에 불과하지만, 그 안에 숨겨진 의미가 매우매우 중요하다.</p>


<h5>Bayes' Theorem</h5>


<p>\[ p(Y|X) = {p(X|Y) p(Y) \over p(X)} \]</p>


<p>식의 모양은 위와 같다. 이 식이 중요한 이유는 무엇이냐면, 실제 우리가 관측하는 데이터와 실제 일어나는 현상과의 관계를 이어주는 연결고리가 되기 때문이다.</p>


<p>우리가 실제로 관측할 수 있는 데이터와 현상의 관계는 어떻게 되느냐 하면 '이런 현상이 나타났을 때 데이터의 분포' 를 보는 것이다. 무슨 얘기냐, 만약 데이터를 X, 현상을 Y라고 해보자. 그럼 우리가 당연히 얻고 싶은 것은 주어진 데이터 X에 대한 현상 Y일 것이다. 즉 \( p(Y|X) \) 를 우리는 실제로 계산하고 싶은 것이다. 그런데 우리가 확인할 수 있는 데이터는 무엇이냐 하면, 어떤 주어진 현상 Y에 대해 존재하는 데이터 X들의 분포 즉, \( p(X|Y) \) 만을 관측할 수 있다. 예를 들어보자. 만약 어떤 질병에 대한 검사를 하는 상황이라고 가정해보자. 우리가 확인할 수 있는 것은 해당 검사에 대해 양성 판정을 받았는지 아닌지 밖에 확인할 수 없다. 만약 이 검사가 완벽하지 않다면 (즉, 정확도가 90% 정도라면) 실제 우리가 관측하는 검사 결과와 그 사람의 질병 보유 상황이 다를 수 있는 것이다. 즉, 검사 결과를 X라고 하고 실제 병에 걸렸는지 아닌지를 Y라고 한다면 우리가 최종적으로 확인하고 싶은 것은 \( p(Y|X) \), 즉 검사 결과를 보고 이 사람이 진짜 질병을 가질 확률을 알고 싶은 것이지만, 실제 우리가 확인할 수 있는 데이터는 \( p(X|Y) \), 즉 이 사람이 실제 병에 걸렸을 때 제대로 검사가 될 확률 (아까 90%라고 했었던) 뿐이 가지고 있지 않다. 더 자세한 것은 <a href="http://musicetc.wikidot.com/bayes-theorem#toc3" target="new">링크</a>를 참조하길 바란다.</p>


<p>중요한 것은 무엇이냐 하면, 진짜 우리가 관측할 수 있는 데이터만 가지고는 우리가 원하는 추론을 하는 것이 어렵다는 점이다. 이때, 주어진 현상에 대해 나타나는 데이터의 분포 \( p(X|Y) \), 즉 우리의 observation을 일컬어 Likelihood라고 한다. 만약 우리가 아무런 정보도 가지고 있는 상황이 아니라면 언제나 이 값을 최대로 만드는 작업을 통해 가장 optimized된 현상을 찾을 수 있는데 이를 maximum likelihood라 한다. (<a href="http://en.wikipedia.org/wiki/Maximum_likelihood" target="new">위키</a>) 즉, 우리가 관측한 정보만을 가지고, 그 정보가 전부라고 가정한 이후에 그 안에서 모든 optimization을 거쳐 가장 좋은 something을 얻어내는 과정이라 할 수 있다. 이를 Maximum Likelihood Estimation 혹은 MLE라 한다. 이 녀석은 Machine learning을 하면서 정말 많이 나오는 용어이고, 실제 이 방법을 사용해 풀어내는 문제들이 많기 때문에 반드시 숙지해야하는 개념이다.</p>


<p>그런데, 앞서 설명했던 예시와 같이, 항상 MLE가 능사는 아니다. 극단적으로 생각해서, 만약 우리가 동전 던지기를 해서 10번 던져서 10번 tail이 나오면 '이 동전은 tail이 100%로 나오는 동전이다' 라고 예측하는 것이 바로 MLE인 것이다. 이 방법이 잘 될 떄도 많지만, 방금처럼 데이터가 부족한 경우 등에는 좋은 결과를 얻지 못할 수 있다. 만약 우리가 '동전 던지기를 하면 head, tail이 50:50 으로 나온다.' 라는 것을 알고 있다면 조금 더 나은 추론을 하는 것이 가능하지 않을까? 이런 생각에서 나오는 것이 바로 Maximize a posterior, 혹은 MAP이다. Posterior는 앞에서 설명했던 주어진 데이터에 대한 현상의 확률, 즉 \( p(Y|X) \)이다. 간단히 생각해서 Likelihood는 내가 본 데이터에 대한 관측값 만을 의미하는 것이고, Posterior는 관측값과 다른 결과들을 조합하여 나온 조금 더 추론하기에 알맞은 형태? 라고 보면 될 것 같다.</p>


<p>앞서 Bayes' theorem에서 계산했듯, Observation, 혹은 Likelihood를 알고 있을 때 Posterior를 계산하기 위해서는 \(p(X), p(Y)\)가 필요하다. 이때 \(p(Y)\)는 어떤 현상에 대한 사전 정보이다. 즉, 아까 동전 던지기에서 동전을 던졌을 때 head tail이 나올 확률이 0.5라는 것에 대한 사전 정보이다. 이를 prior 라고 한다. 만약 이 값을 알고 있다면 observation이 잘못되어도 이 값이 약간의 보정을 해주는 역할을 할 수 있게 되는 것이다. 그리고 여기에서 데이터의 분포 \(p(X)\)는 일종의 normalization 을 해주는 역할을 하며, 실제 모든 데이터에 대해 \(p(X|Y) p(X)\) 를 계산한 뒤 그 값들을 noralization하는 것과 동일한 효과이기 때문에 이 값에 대해 알 필요는 없다.</p>


<p>정리하자면, Bayes' theorem은 observation(likelihood), 현상에 대한 사전정보 (prior), 주어진 데이터에 대한 현상의 확률 (posterior) 의 관계를 define하는 중요한 역할을 한다고 할 수 있겠다.</p>




<h5>Probability densities</h5>


<p>Probability density, 우리 말로 하면 확률밀도가 되겠다. 간단히 생각하면 주어진 domain에 대해 확률이 어떻게 분포하고 있는지를 나타내는 일종의 function이라 할 수 있겠다. 아마 이것도 고등학교 수학시간에 배우는 것으로 기억하는데.. 그만큼 아주 간단한 개념이다. 자세한건 위키를 <a href="http://en.wikipedia.org/wiki/Probability_density_function" target="new">참고</a>하면 될 것 같다. 그럼 이게 실제로 어떤 의미가 있으며 맨 처음에 probability density 관점에서 machine learning을 볼 수 있다는 것의 의미는 무엇인가?</p>


<p>Probaiblity density라는 녀석은 결국 주어진 데이터들이 어떤 방식으로, 어떤 확률로 분포해있는지를 알려주는 녀석이라 할 수 있다. 예를 들어보자. 만약 우리가 스팸필터를 만들었는데 '광고' 라는 단어가 포함이 되면 해당 메일이 스팸일 확률이 80%이고, '구매' 라는 단어가 포함이 되면 90%, 'Machine Learning' 이라는 단어가 포함되면 스팸일 확률이 10%.. 이런식으로 모든 단어, 모든 domain에 대해 스팸일 확률을 알고 있다면, 혹은 그런 probability density를 찾을 수 있다면, 더 정확히 말하면 probability density function을 찾아낼 수 있다면 우리는 매우 좋은 inference를 할 수 있게 될 것이다.</p>


<p>이제 Machine Learning과의 연계를 지어보자. 어떤 우리가 모르는 probability density function을 가지는 데이터들에 대해, 그 데이터들을 사용해 probability density function을 찾아내는, estimate하는 과정을 일컬어 Density estimation이라 부른다. 이전에는 데이터들을 통해 '함수'를 찾아낸 것이고, 지금은 그 함수가 density function이라는 점이 다른 점이다.</p>




<p>Bayes' theorem 이나 probability density 등 이외에도 probability theory 쪽에서 언급해야할 얘기들이 없는 것은 아니다. 예를 들어서 expectation이라거나.. 하지만 내 생각에 이번 글에서 언급한 두 개는 약간 기본적인 probability theory와는 다르게 조금 머신러닝적인 insight가 필요한 부분이 아닐까해서 조금 강조해서 언급해보았다.</p>




<hr>


<p><a href="http://SanghyukChun.github.io/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="http://SanghyukChun.github.io/57">Machine Learning이란?</a></li>
<li><a href="http://SanghyukChun.github.io/58">Probability Theory</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine learning 스터디 (1) Machine Learning이란?]]></title>
    <link href="http://SanghyukChun.github.io/57/"/>
    <updated>2014-08-02T18:48:00+09:00</updated>
    <id>http://SanghyukChun.github.io/57</id>
    <content type="html"><![CDATA[<p>Machine learning이라는 것을 접한지 어느새 거의 1년 반이 넘는 시간이 지났다. 계속 여러 종류의 <a href="http://SanghyukChun.github.io/blog/categories/machine-learning/" target="new">Machine learning과 관련된 글들</a>을 써왔지만, 항상 중구난방이고 제대로 정리가 되지 않은 느낌을 받아서 근래에 다시 머신러닝에 대해 공부를 하는 김에 싹 몰아서 정리해보기로 했다. 8월에 연구실에서 머신러닝 스터디를 하기로 했지만, 그것과는 조금 다르게 내가 생각했을 때 이런 순서로 정리를 하면 되겠다.. 하는 느낌으로 정리를 해볼 생각이다. Bishop 책을 많이 참고했으면 하고.. 특히 이번 ICML에서 느낀거지만, Machine Learning에는 정말 많은 분야가 있는데, 많은 Lecture들에서 어쩔 수 없이 그것들을 전부 커버하지 못하는 점이 너무 아쉬웠다. 그래서 일단 내가 할 수 있는데까지는 정리해보는게 좋지 않을까.. 하는 생각으로 글을 써보려 한다. 이런 글을 써야겠다는 생각은 오래전부터 했는데 정작 실천에 옮기는데에는 시간이 많이 걸렸네.. 그래 무튼 시작해보자.</p>


<p>Machine Learning... 혹은 우리 말로 하면 기계 학습. 이놈이 대체 뭐길래 너도나도 머신러닝 머신러닝 해대는 걸까. 내가 예전 <a href="http://SanghyukChun.github.io/3" target="new">Andrew Ng. 교수의 Machine Learning Lecture를 들으며 정리했던 글</a>에 정의했던바에 따르면, </p>


<blockquote>
    <p>머신러닝은 그 관계를 알 수 없는 수 많은 데이터들 사이에서 관계를 찾아내주는 마법과 같은 기술이다.</p>
</blockquote>


<p>라고 정의했었다. 마법과 같은 기술이라! 어디서 저런 중2병 스멜나는 용어를 가져왔는지 참.. 아무튼 내가 이쪽을 더 공부해보면서 느낀건, 결국에 이 Machine Learning이라는 것은 일종의 Modeling Problem이라는 것이다. 무슨 얘기냐? 머신러닝이란 <b>주어진 데이터</b>에 대해 <b>현상</b>을 <b>가장 잘 설명할 수 있는 관계</b>를 찾아내는 것이라 했었는데, 이 말을 조금 수학적으로 풀어내면 주어진 <b>데이터</b> \(X = (x_1, x_2, x_3, \ldots, x_n)\) 이 있을 때 이 데이터와 실제 <b>현상</b> \(Y = (y_1, y_2, \ldots, y_n) \)에 대한 <b>관계</b> function \(f\)를 찾아야한다. 당연히 우리가 정확한 함수 \(f\)를 찾아낼 수는 없으므로 <b>최대한 잘 설명할 수 있는</b>, 함수 \(f'\)을 찾아내야 한다. 이를 Hypothesis라고 한다. 즉, 이 모든 과정을 일종의 Modeling process로 생각이 가능하다는 뜻이다. 다만 우리의 새로운 process는 for given data에 대해 dependent한 model을 만들어낸다는 점이 독특한 것이다.</p>


<p>스팸필터를 생각해보자. 데이터 X는 메일들이다. 우리가 받는 메일 하나하나가 데이터가 될 수도 있고, 그 메일 안에 있는 단어 하나하나가 될 수도, 혹은 아예 알파벳 하나하나가 될 수도 있다. 그것은 우리가 정하기 나름이니까. 그럼 현상 Y는 무엇일까? 각각의 메일이 스팸인지, 아니면 일반 메일인지 구분하는 구분자, indicator, 혹은 Label, Class가 될 것이다. 마지막으로 가장 잘 설명할 수 있는 함수는 이런 데이터들을 가지고 어떻게 Learning을 할 것인지에 대한 얘기가 될 것이다. 예를 들어 Naïve Bayes라던가, KNN, SVM도 있고, 요새 핫한 Deep learning도 있을 수 있다.</p>


<p>그러면 이 함수로 우리는 무엇을 하고 싶은걸까? 단순히 데이터와 현상의 관계를 함수로 나타내는 것이 무슨 의미가 있지? 이것이 의미가 있는 이유는 우리가 새로 주어진 데이터, 혹은 test data에 대해 새로운 추론, inference를 하는 것이 가능하기 때문이다. 이 메일은 스팸인가? 이런 쇼핑 목록을 가진 사람은 또 뭘 사고 싶어할까? 이런 날씨에는 고속도로가 막힐까 막히지 않을까? 이런 질문들에 대해 앞서 우리가 정의한 방식대로 Machine Learning problem을 풀어 새로운 Hypothesis를 통해 우리는 inference를 내릴 수가 있다. 이런 inference가 맞을 수도 있고 틀릴 수도 있다. 그러나 우리는 최대한 좋은 방법으로 Learning을 한다면 좋은 inference를 할 수 있을 것이라고 생각할 수 있다. 이 '좋은 방법' 을 위해 도입되는 개념이 바로 cost function이다. 내가 원하는 결과와 실제 내가 찾아낸 가설과의 괴리가 얼마나 있는지를 function으로 정의하는 것이다. 가장 간단한 예로, 스팸 필터에서 '스팸이다 아니다'라는 질문이 틀리면 cost function은 1, 맞으면 0이라고 하자. 그렇게 정의하면 이 cost를 최소화 하는 방향으로 model을 learning하면 결국 가장 잘 맞추는 model을 얻을 수 있겠지.</p>


<p>즉, 머신러닝이란, 완전히 raw한 데이터를 다루는 과정, 예를 들면 Dimensionality reduction, Metric Learning 등의 과정에서부터 시작해서, 어떻게 Learning할 것이냐, model이 무엇이냐, 조금 더 구체적으로 얘기하면 어떤 Algorithm을 사용해 이 model을 learning할 것이냐라는 문제를 풀어내고, 마지막으로 어떻게 결정을 내릴 것이냐, decision making을 할 것이냐 하는 이 여러개의 과정으로 나뉘어지는 것이다. 내가 관심있는 부분은 주로 어떤 model을 사용할 것이냐, 또 어떤 방법으로, 어떤 algorithm으로 이 model을 learning할 것이냐에 관심이 있다. 또 추가로 관심이 있는 부분이라면, 어떤 문제가 있을 때 그 문제를 Machine Learning의 관점에서 풀어내는 것도 좋아하고.. 예를 들면 추천 알고리듬 같은게 있겠다.</p>


<p>사실 이렇게 머신러닝을 정의하기에는 조금 어정쩡한 부분이 있는 것이 사실이다. 그럼 Unsupervised Learning은?? Reinforcement Learning은? 그 이외에도 많은 것들을 이 정의만 가지고 설명하기에는 사실 무리가 있는 것이 맞지만, 그래도 이런 컨셉으로 이해를 하게 된다면, 즉 Machine Learning이 근본적으로 model, algorithm 문제라는 것을 이해하게 된다면 이 녀석들에 대한 이해도 빠르게 할 수 있지 않을까 생각된다. 위에 링크 건 <a href="http://SanghyukChun.github.io/3" target="new">예전 글</a>에 이와 관련된 글들이 있으니 궁금하면 읽어보면 될 것 같다.마찬가지 이유로, 요즘 유행하는 Big Data 역시 근본적으로는 Machine Learning의 일부라는 것을 알 수 있다. <a href="http://SanghyukChun.github.io/21" target="new">이에 대한 글</a>도 이전에 적은 적이 있으니 참고바란다. 달라지는 점이라면 algorithm이 굉장히 빨라야 한다하거나, Memory efficient 해야한다거나, 아니면 분산처리가 가능해야한다거나 하는 새로운 challenge들이 존재하기는 하지만, 근본적으로는 같다고 봐도 무방하다. 즉, 이 머신러닝이라는 것을 제대로 이해하고 다룰 수 있다면 정말 많은 문제들을 해결할 수 있다는 의미가 될 것 이다.</p>




<hr>


<p><a href="http://SanghyukChun.github.io/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="http://SanghyukChun.github.io/57">Machine Learning이란?</a></li>
<li><a href="http://SanghyukChun.github.io/58">Probability Theory</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
