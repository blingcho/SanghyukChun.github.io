<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Machine-Learning | README]]></title>
  <link href="http://SanghyukChun.github.io/blog/categories/machine-learning/atom.xml" rel="self"/>
  <link href="http://SanghyukChun.github.io/"/>
  <updated>2013-11-05T19:58:20+09:00</updated>
  <id>http://SanghyukChun.github.io/</id>
  <author>
    <name><![CDATA[Sanghyuk Chun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Machine Learning Week2 - Linear Regression]]></title>
    <link href="http://SanghyukChun.github.io/14/"/>
    <updated>2013-08-04T15:19:00+09:00</updated>
    <id>http://SanghyukChun.github.io/14</id>
    <content type="html"><![CDATA[<p>Coursera강의를 들은지 한참이 지난 줄 알았는데 고작 1주일 밖에 되지 않았다. 아무튼 까먹기 전에 <a href="http://SanghyukChun.github.io/3" target="new">처음 얘기했던대로</a> 하나하나 차근차근 블로그에 정리를 해볼까 한다.</p>


<h3 id="Linear_Regression">Linear Regression</h3>


<p><a href="http://SanghyukChun.github.io/3">지난 Post</a>에서는 간단하게 supervise learning과 unsupervise learning에 대해서 언급했다. 이제 supervise learning 중 linear regression에 대해서 얘기를 해보자. 개인적으로는 regression을 하기 이전에 baysian을 설명하는 것을 선호하지만, 그건 그냥 다음 포스트에 설명하기로 하고 (Andrew Ng 교수는 Coursera강의에서 Baysian을 따로 수업으로 다루지 않았다.) 먼저 regression부터 살펴보자.</p>


<p>Linear regression을 가장 간단하게 설명하자면 Excel의 추세선과 거의 비슷한 개념이라고 생각하면 된다. 즉, 지금 내가 가지고 있는 데이터셋이 어떤 <strong>Linear function</strong>인지를 유추하는 것이다. 간단한 예시를 보자. 아래 그래프를 공부시간과 시험성적의 그래프라고 생각해보자. (가로축을 공부 시간 세로축을 시험성적)</p>


<p><img src="/images/post/14-1.png" width="400"></p>

<p>이 그래프는 대체로 1차 함수(linear function)의 꼴을 가지고 있다는 것을 알 수 있다. 그렇다면 아마도 4.5의 공부 시간을 투자한 학생은 약 4.5 정도의 시험성적을 받을 것이라고 예측할 수 있지 않을까?</p>


<p>물론 현실에서 공부 시간과 성적이 선형 비례하지는 않지만, 아무튼 이런 예시를 통해서 우리는 이 System이 가지고 있는 일종의 특성을 예측할 수 있다. 이때 우리가 '데이터가 x일 때 y의 결과가 나올 것이다' 라고 예측한 둘 사이의 관계 혹은 함수를 hypothesis라 한다. 이 부분은 지난 포스트에서 설명한 부분이니 자세한 설명은 넘어가도록 하겠다. 그렇다면 특정 데이터셋이 들어왔을 때 hypothesis는 어떻게 도출할 수 있을까? 아래 그래프를 보자</p>


<p><img src="/images/post/14-2.png" width="400"></p>

<p>빨간 선과 초록 선 중 어느 hypothesis가 더 좋다고 할 수 있을까? 사람이 선택하는 것은 언제나 부정확하다. 때문에 우리는 수식적으로, 정확하게 scoring할 수 있는 무언가를 원하는데 그 이유로 우리는 <a class="red tip" title="Cost Function이라고도 한다. 본 블로그는 전부 Loss Function으로 칭한다.">Loss Function</a>을 필요로 한다.</p>


<h3 id="Loss_Function">Loss Function</h3>


<p>이 hypothesis가 좋은 hypothesis인지 아닌지 어떻게 알 수 있을까? 사실 답은 간단하다. '새로운 데이터의 결과를 얼마나 잘 예측을 하느냐'. 하지만 새로운 데이터가 없이는 Scoring이 불가능하다. (온전히 불가능한 것은 아니고 model selection을 통해 validation을 하는 skill이 있다. 하지만 지금 포스트의 주제는 아니기 때문에 나중에 설명하도록 하겠다.) 때문에 지금 존재하고 있는 데이터에서 찾은 패턴이 전체 패턴과 동일하다는 가정하에 지금 데이터에 얼마나 잘 fit하느냐로 Scoring을 하는 것이 가능할 것이다. 즉, 새로운 데이터를 이용하여 Scoring을 해야하지만, 새로운 데이터를 받기 이전에 Scoring을 하고 그 hypothesis를 사용해야하기 때문에 지금 가지고 있는 dataset이 향후 새로 들어올 데이터와 유사하다고 생각하고 지금 가지고 있는 값을 이용해 fitting을 하는 것이다.</p>


<p>이때 사용하는 것이 바로 Loss function이다. Hypothesis의 Loss를 측정하여 그 값을 최소화 하는 것이다. Loss 혹은 Cost라는 이름에서 유추할 수 있듯 이 값은 function으로 예측된 (predicted) 값과 측정된 (observed) 값의 차이를 사용하여 계산한 값이다. 여러가지 Loss function의 꼴이 있는데, 가장 간단하게 사용할 수 있는 function은 (data_p - data_o)^2이다. data_p는 이 hypothesis를 사용하여 예측한 값이고 data_o는 실제 관측 결과 얻은 값이다. 그 밖에 0-1 Loss라고 해서 값이 정확하게 일치하면 0, 아니라면 1 만큼의 Loss를 가지는 매우 Strict한 Loss function이다. 이후에 설명하게 될 classfication에서 간혹 쓰인다.</p>


<h3 id="Gradient_Descent">Gradient Descent</h3>


<p>이제 이 Loss function이 가장 작은 값을 가지는 hypothesis를 선택하면 된다. 그렇다면 그 값은 어떻게 찾을 것인가? 여러가지 방법이 있지만, 일반적으로는 Gradient Desent라는 방법을 사용한다. Gradient descent란 쉽게 생각하면 긿을 잃은 상태에서 산을 내려가는 방법이라고 생각하면 된다. 산을 가장 빠르게 내려가기 위해서는 아마 현재 내가 서있는 지점에서 가장 경사가 가파른 지점을 향해서 내려가고, 움직인 위치에서 다시 한번 경사가 가장 가파른 지점을 향해서 내려가고.. 이 과정을 반복하다보면 언젠가 가장 낮은 지점으로 이동할 수 있을 것이다. 이제 이 개념을 머리에 넣어두고 아래 그림을 보자.</p>


<p><img class="<a" src="href="http://www.mathworks.com/matlabcentral/fx_files/27631/1/fff.png">http://www.mathworks.com/matlabcentral/fx_files/27631/1/fff.png</a>"></p>

<p><small>출처: http://www.mathworks.com/matlabcentral/fx_files/27631/1/fff.png</small></p>


<p>위의 그림에서 볼 수 있듯 가장 경사가 가파른 지점을 따라 내려 걸어가다보면 가장 낮은 지점으로 도달할 수 있을 것이다. 그런데 여기에서 문제가 하나 발생한다. 만약에 Initial Condition이 작은 봉우리가 아니라 반대쪽 높은 봉우리였다면? 그렇다면 우리는 아마 Global minimum, 즉 전체에서 가장 낮은 지점이 아닌 Local minimum, 즉 주변에서 가장 낮은 지점으로 이동하게 될 것이다. 전체에서 가장 작은 값과 그 주변에서 가장 작은 값을 선택하는 것은 분명 큰 차이가 있다. 하지만 이런 단점에도 불구하고 gradient descent는 매우 많이 쓰이는 방법 중 하나이다. 그 이유는 (1) 구현이 쉽고, (2) 모든 차원 및 공간으로 확대가 가능하다 라는 이유가 있다. Gradient descent는 또한 내가 속도를 조절할 수 있다. 산을 내려갈 때 얼마나 움직인 다음 방향을 바꿀 것인가에 따라 수렴 속도가 급격하게 변한다. 너무 그 폭이 작으면 시간이 너무 오래걸리고, 폭이 너무 크면 최악의 경우에 한 지점에 수렴하지 못할 수도 있다. 그 뿐 아니라 <a class="red tip" title="가장 간단한 예로 y=x만 생각해봐도 절대 수렴하지 않는다.">경우에 따라서는 gradient descent가 끝이 나지 않을 수도 있다.</a> 하지만 여러 방법으로 그 단점들을 보완할 수 있고 무엇보다 아래 코드에서도 확인할 수 있듯 구현이 너무 간단하기 때문에 상당히 많이 쓰이는 방법이다. 더 자세한 것은 <a href="http://en.wikipedia.org/wiki/Gradient_descent">Wikipedia page</a>를 참고하면 좋은 정보가 많다.</p>


<p>```</p>

<h1>From calculation, we expect that the local minimum occurs at x=9/4</h1>

<p>x_old = 0
x_new = 6 # The algorithm starts at x=6
eps = 0.01 # step size
precision = 0.00001</p>

<p>def f_prime(x):</p>

<pre><code>return 4 * x**3 - 9 * x**2
</code></pre>

<p>while abs(x_new &ndash; x_old) > precision:</p>

<pre><code>x_old = x_new
x_new = x_old - eps * f_prime(x_old)
</code></pre>

<p>print &ldquo;Local minimum occurs at &rdquo;, x_new
```</p>

<p><small>출처: http://en.wikipedia.org/wiki/Gradient_descent#A_computational_example</small></p>


<h3 id="Overfitting">Overfitting</h3>


<p>이제 적절한 hypothesis를 찾기 위하여 loss function의 최소점을 gradient descent로 찾을 수 있다. 이제 더 이상 우리가 고민할 것은 없어보인다. 아니, 사실 그렇지 않다. 앞서 가정한 바에 의하면, 우리는 지금 존재하는 데이터셋이 전체 데이터셋의 분포를 대변한다고 가정했다. 하지만 꼭 그러리라는 보장을 할 수 있을까? 당연히 없다. 우리가 보고 있는 자료가 엄청 큰 패턴 중에서 매우 일부의 예외일 수도 있고, 혹은 노이즈 때문에, 너무 샘플 수가 적어서 잘못된 방향으로 pattern을 찾게 될 수도 있다. 이런 경우를 일컬어 Overfitting이라고 한다. 즉, 기존의 데이터에만 너무 충실해서 새로운 데이터가 들어왔을 때 도저히 써먹을 수가 없는 상태를 일컬어 Overfitting이라 한다. 이 것을 해결하기 위하여 여러가지 방법이 있는데 Model Selection과 Regularization이 그것이다. 이에 대해서는 다음 포스트에서 다루고자 한다.</p>


<p></p>

<p>Linear Regression은 매우 간단한 supervise learning의 예시이지만 상당히 중요한 개념들에 대해서 많이 다뤄야 한다. 특히 Loss function은 정말 중요하고 그 Loss function을 계산하는 gradient descent도 너무 중요하고, 마지막에 잠시 언급한 Overfitting은 너무 중요하다 못해 머리가 아플 정도다. 아직 정말 중요한 부분들을 일부 설명 못했지만 Overfitting에서 할 얘기가 너무 많아서 이쯤에서 줄여야겠다.</p>


<hr>


<h4>참고도서</h4>


<p>Bishop, Pattern Recognition and Machine Learning</p>


<p>Simon Rogers, A First Course in Machine Learning</p>


<p></p>

<p>Stephen Marsland, Machine Learning: An Algorithmic Perspective</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Andrew Ng 교수의 Machine Learning강의 수강 완료]]></title>
    <link href="http://SanghyukChun.github.io/10/"/>
    <updated>2013-07-29T08:11:00+09:00</updated>
    <id>http://SanghyukChun.github.io/10</id>
    <content type="html"><![CDATA[<p>기어코 주말만에 Coursera하나를 끝냈다. 물론 어디까지나 다 아는 내용이었고 강의 난이도도 낮아서 빠르게 스킵하면서 넘어갔기 때문에 가능했던 일이지만.</p>


<p>이 강의를 들으면서 요약을 하면서 천천히 진행하려고 했는데 생각보다 강의 내용도 쉽고 다루는 내용도 상당히 기초적인 것들이 많아서 차라리 빠르게 훑고 뒷 쪽의 Advanced를 보면서 다시 개념 다지는게 좋겠다는 생각으로 질주했으나, 끝까지 난이도가 쉬웠다. 악의가 있는 말은 아니고, 정말 설명도 잘하고 예시도 쉬운 것들이라 금방금방 넘어갈 수 있었다. 결국 19.6시간짜리 강의를 이틀 + 반나절만에 돌파하는 기염을 토하게 되었다 ;;</p>


<p>근데 아무래도 아는 내용들이 주가 되다보니 그냥 비디오를 스킵하면서 강의 하나보는데 5분도 안걸리는 식으로 훑으면서 봤더니 온전하게 소화가 되지 않은 기분이다. 전공서 다시 읽으면서 개념 정리하고 강의 순서대로 나름대로 정리하면서 포스팅을 해봐야겠다. 아쉬운 점이라면 너무 수학적인 내용이 없다보니 (Baysian조차 나오지 않은 것은 나름 신선한 충격이었다.) 아마 내가 공부하는 내용을 바탕으로 정리하면 꽤나 안드로메다로 갈 것 같은 기분이 허허허</p>


<p>Hinton 교수의 Neural Network강의는 다음주쯤부터 시작하고 그 전에는 전공서를 다시 읽어봐야겠다. 한 학기동안 배운 것도 정리하겸. 사실 우리 교수님 강의 순서가 책이랑 달라서 책 공부에 소홀해진 것도 있으니.. 이번 주에는 조금 여유가 있을 듯 하니 이럴 때 좀 열심히 해놔야겠다.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine Learning Week1 - What is Machine Learning]]></title>
    <link href="http://SanghyukChun.github.io/3/"/>
    <updated>2013-07-27T00:14:00+09:00</updated>
    <id>http://SanghyukChun.github.io/3</id>
    <content type="html"><![CDATA[<p>최근 Andrew Ng Standford교수의 Coursera <a href="https://class.coursera.org/ml-003/class/index">Machine Learning Course</a>를 수강 중이다. 사실 나는 이미 Machine Learning Coursework을 끝마친 상태이기 때문에 굳이 이 Course를 다시 들을 필요는 없긴 하지만 나의 개념을 다시 다잡고 최근 공부에 있어 슬럼프 비슷한게 찾아왔기 때문에 이 강의를 들으면서 나 자신을 조금 자극할 생각으로 수강하고 있다. 수강을 하면서 목표한 바가 있는데</p>


<ol>
    <li>최대한 빠른 시간 안에 수강 끝내기</li>
    <li>수강을 끝내고 어느 정도 section을 묶어서 블로그에 정리하기</li>
    <li>수강을 다 끝내고 나면 이를 응용한 프로젝트를 만들어보기</li>
</ol>


<p>이것들을 꼭 달성하는 것이다. 아직까지는 겨우 Week 1의 기본적인 내용들을 끝 마친 상태이기 때문에 별 다른 어려움은 없어보이지만 아무래도 주말에 주로 course를 몰아 들어야하기 때문에 마냥 잘 될 것이라고 기대하는 것에는 조금 무리가 있다는걸 나도 알고 있다. 그래도 열심히 해야지.</p>


<p>이 포스트는 두 번째 목표인 블로그에 정리하기 목적으로 쓰는 포스트이다. Week1은 코스와 머신러닝에 대한 간략한 설명, 그리고 supervise learning을 위한 기본적인 컨셉들 - cost function, gradient descent - 을 주 내용으로 삼고 있다.</p>


<p>이 개념들을 설명하기에 앞서, 과연 머신러닝이란 무엇일까. 단순히 백과사전에 있는 내용이나 인터넷에 있는 내용이 아니라, 내가 생각하는 머신러닝은 무엇일까 먼저 생각해봐야겠다. 일단 머신러닝은 AI쪽에서 맨 처음 나온 개념으로 알고 있다. 처음부터 완벽하고 완성된 알고리즘을 통해 인공지능을 부여하는 것은 사실상 불가능하고, 대신 마치 사람이나 일반적인 지능을 가진 생명체가 그러하듯 기계에도 학습기능을 부여하여 기계가 스스로 알아서 학습하도록하는 개념이 바로 머신러닝이다. 멋지지 않은가. 사실 나는 AI에는 별로 흥미가 없고 지금도 머신러닝을 공부한다고 해서 AI쪽으로 진로를 잡고 싶은 생각은 추호도 없다. 그럼에도 불구하고 내가 머신러닝에 관심을 가지고 있고 계속 공부하는 이유는, 지금의 머신러닝은 단순한 AI가 아니라 (물론 AI가 절대로 단순하지는 않다) 바로 데이터 pattern recognition으로 생각해도 무방하기 때문이다. 다시 말해서 특정 dataset을 계속 학습시켜서 그 데이터에서부터 패턴을 추출하는 것이다. 예를 들어보자. 많은 소비자들이 A라는 상품을 구매하고 나서 B라는 상품을 구매하는 어떤 패턴이 있다고 가정해보자. 하지만 두 개의 상품은 굉장히 연관성도 모호하고 현재 지금 물건을 판매하는 판매상의 입장에서 굉장히 많은 물품이 있어서 모든 물품에 신경을 쓸 수 없는 상황이라 생각해보자. 어디서 많이 본 상황이 아닌가? 바로 인터넷 쇼핑몰이다. 수 많은 웹 로그를 수집하면 이런 소비자들에게 다른 상품을 추천해주고 더 많은 수익을 거둘 수 있는 것이다. 실제로 이런 사례로 아마존이 있다. 자 여기에서 다시 내가 생각하는 머신러닝을 정의해보자.</p>


<p>머신러닝은 그 관계를 알 수 없는 수 많은 데이터들 사이에서 관계를 찾아내주는 마법과 같은 기술이다.</p>


<p>물론 엄밀히 정의하면 위와 같은 말은 틀릴 수 있지만, 내가 생각하기에는 충분히 의미가 있는 말이다. 자 이제 다시 본론으로 넘어가보자. 머신러닝에서는 크게 두 가지 종류가 있다. supervised learning과 unsupervised learning이 그것인데, 사실 더 엄밀히 말하면 더 많은 종류가 있지만 일단 지금은 이것만 알아도 충분하다.</p>


<p>먼저 supervise learning에 대해 설명해보자. supervised learning은 이미 명확하게 답이 정해져 있는 것의 답을 찾는 것이다. 쉽게 생각하면 2차원에 흩뿌려진 점 들을 보고 이 점들이 어떤 함수를 구성하고 있을까를 추측하는 것이다. 예컨데 이 강의에서 예시로 드는 방 평수와 가격 사이의 상관관계를 찾는 방법도 있을 수 있고, 종양의 크기와 그 종양이 악성인지 아닌지의 관계를 찾는 방법도 있을 수 있다. 전자의 방법은 방 평수, 그리고 가격이 전부 continuous한 값을 가진다. 다시 말해서 real value이다. 이런 경우를 regression이라 부른다. 반면 뒤의 경우는 종양은 악성이냐 혹은 그렇지 않느냐 두 가지 경우의 수 밖에 없다. 이런 경우를 classification이라고 부른다.</p>


<p>그러면 unsupervised learning은 무엇일까? 앞서 본 사례들은 그 결과가 정해져있다. 방 평수 그리고 방 가격, 종양의 크기와 악성도 등. 하지만 unsupervised learning은 그 결과가 정해져있지 않다. (정확히 말하면 data가 labeled 되어있지 않은 data이다.) 예를 들어서 특정 데이터들이 흩뿌려져 있고 이 데이터들이 전혀 label되어있지 않을 때 이 데이터들을 clustering하는 것이 대표적인 예이다. supervised learning에 비해서 어렵고 구현하기도 복잡한 편이다.</p>


<p>자 그러면 supervise learning에 대해 조금 더 자세히 알아보자. 아까 예를 들었던 방 평수와 방 가격 사이의 관계도를 다시 생각해보자. 만약 10평일떄 20만원 20평일 때 30만원 30평일 때 40만원이라면 40평 일때의 가격은 어떻게 될까? 아마도 50만원일 가능성이 클 것이다. 이렇게 선형적으로 추론하는 것을 linear regression이라 한다. 그리고 이때 예측 되는 데이터와 결과값 사이의 관계(함수)를 hypothesis라고 부른다. 우리말로 옮기면 가설 정도로 해석이 가능한데, 우리가 올바른 값을 아는 것이 아니라 그 결과를 추론할 수 밖에 없기 떄문에 이런 이름으로 명명했지 않을까 싶다. 방금의 경우는 굉장히 간단하게 그 결과를 예측했지만 조금 모호한 경우는 어떨까? 아마 우리는 regression을 통해 상당히 많은 hypothesis를 얻을 수 있을 것이다. 이 hypothesis 중에서 가장 좋은 녀석은 어떻게 고르지? 그래서 도입되는 개념이 바로 cost function 혹은 loss function이다.</p>


<p>Cost function을 정의함으로써 이 함수가 기존에 주어진 데이터에 대해서 얼마나 정확한지 유추할 수가 있다. 예를 들어서 우리가 예측한 함수가 y = x이고 x,y = 1,2 2,3 4,5라고 생각해보자. 그렇다면 아마 x가 1,2,3일 떄 각각 1 만큼 예측값과 실제 값이 차이가 날 것이다. Cost function은 이 차이값들을 통해 얼마나 이 함수가 원래 개형과 가까운가를 유추한다. 이 강의에서는 그 차이의 제곱꼴을 더한 것의 평균값을 제안하는데, 실제로 무난하게 많이 쓰인다. 또 많이 쓰이는 함수로는 0-1 함수라고 해서, 정확한 값이면 0, 조금이라도 다른 값이라면 1을 return하는 함수를 만들어서 cost를 계산한다.</p>


<p>마지막으로 gradient descent만 설명하면 week 1은 끝난다. Gradient Descent라는 것은 Gradient계산을 통해 함수의 local minimum을 찾아가는 과정이다. 함수가 가장 빠르게 감소하는 방향으로 쭉 따라 내려가다보면 가장 낮은 지점까지 도달하고 그것이 바로 local minimum이다. 산 위에서 가장 빠르게 아래로 내려가는 방향을 따라서 산을 내려가는 것이라고 생각하면 간단하다. 그런데 문제가 하나 있는데, 산을 내려오더라도 우리는 지금 위치에서 가장 빠르게 내려가는 길을 구하는 것이지 전체에서 가장 낮은 지점으로 내려가는 것은 아니기 때문에 항상 전체 함수에서 가장 낮은 값으로 수렴하지는 않는 다는 것이다. 이런! 때문에 초기에 어느 지점에서부터 내려가느냐가 그 결과값에 영향을 크게 미치게 되는 것이다. 머신러닝에서는 상당히 자주 쓰이는 개념이고 이 local minimum problem은 끝까지 성능에 있어서 치명적인 단점이 되는 경우가 많다. 이 강의에서는 최적의 loss function을 찾는 방법으로 이 gradient descent를 소개하는데, 강의에서도 언급되 듯 정말 많은 머신러닝 알고리즘 등에서 gradient descent는 많이 쓰이는 개념이니 어느 정도 개념을 숙지해두는 편이 좋다.</p>


<p>이렇게 첫 주 강의를 정리해보았다. 점점 내용도 많아질테고 지금처럼 텍스트로만 설명하기 점점 힘들어지겠지만 그래도 최대한 노력을 해서 처음 목표한 바를 꼭 이룰 수 있었으면 좋겠다.</p>

]]></content>
  </entry>
  
</feed>
