
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>README</title>
  <meta name="author" content="Sanghyuk Chun">

  
  <meta name="description" content="새로운 Front Framework Webplate에 대한 소견 Oct 10th, 2014 얼마전 Webplate라는 front-end framework를 접하게 되었는데 상당히 좋은 인상을 받아서 블로그에 소개 겸 사용 소감을 남겨보려 한다. 그 동안 내가 웹을 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://SanghyukChun.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/layout480.css" media="only screen and (max-width : 500px)" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="README" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
	<script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/bootstrap.js" type="text/javascript"></script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">



<script>
$(function() {
	$('.tip').attr('data-toggle','tooltip');
	$('.tip').attr('data-placement','top');
	$('.tip').tooltip();
});
</script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42711199-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  
	<div id="fb-root"></div>
	<script>(function(d, s, id) {
	  var js, fjs = d.getElementsByTagName(s)[0];
	  if (d.getElementById(id)) return;
	  js = d.createElement(s); js.id = id;
	  js.src = "//connect.facebook.net/ko_KR/all.js#xfbml=1&appId=182012898639519";
	  fjs.parentNode.insertBefore(js, fjs);
	}(document, 'script', 'facebook-jssdk'));</script>
  
  <div id="main">
  	<header role="banner"><hgroup>
  <h1><a id="blog-title" href="/">README</a>
  
    <span>&nbsp;&nbsp; SanghyukChun's Blog</span>
  
  </h1>
</hgroup>

</header>
  	<nav role="navigation"><ul class="main-navigation list-inline">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="http://sanghyuk.kaist.ac.kr/aboutMe/">About Me</a></li>
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
</ul>

</nav>
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/79/">새로운 Front Framework Webplate에 대한 소견</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-10-10T02:30:00+09:00" pubdate data-updated="true">Oct 10<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>얼마전 <a href="http://getwebplate.com/">Webplate</a>라는 front-end framework를 접하게 되었는데 상당히 좋은 인상을 받아서 블로그에 소개 겸 사용 소감을 남겨보려 한다.</p>


<p>그 동안 내가 웹을 개발하면서 느꼈던 가장 불편한 점은, 디자이너가 없이는 내가 할 수 있는 것들이 상당히 제한된다는 것이었다. 그러던 와중에 <a href="http://getbootstrap.com/">twitter bootstrap</a>을 알게 되었고, 덕분에 상당히 많은 웹 페이지들을 만들 수 있었다. 이 블로그도 그렇고, 내 aboutMe 페이지도 그렇고 홈페이지도 그렇고 요즘 만들고 있는 연구실 홈페이지도 그렇고.</p>


<p>하지만 bootstrap을 사용하면서 불편한 점이 없는건 아니었다. Bootstrap은 매우 훌륭한 디자인 가이드를 제공하고 있기는 하지만, 결국 기본적인 웹 frame조차 내가 처음부터 html 코딩을 해야하는 점은 매우 귀찮은 일이 아닐 수 없었다. 지금은 이것에 어느 정도 익숙해지고 내가 내 나름의 template을 가지게 되었지만 그 이전에는 html부터 코딩을 하는 것이 여간 귀찮은 일이 아니었다. 특히 aboutMe만들 때 생각하면&#8230; 정말 끝없이 고치고 또 고쳤던 기억이 난다.</p>


<p>그러던 와중 webplate를 보게 되었는데, 처음 본 순간 정말 센세이션이었다. 마침 <a href="https://github.com/chrishumboldt/webplate">github</a>도 있길래 fork해서 한 10분 정도 둘러봤는데,</p>


<ol>
<li>Twitter Bootstrap과 비교를 하지 않을 수 없는데, 사실 Webplate에서 가능한건 Bootstrap에서도 다 가능할 뿐 아니라 자유도 역시 Bootstrap이 더 좋다. 하지만 Bootstrap에서는 내가 다 구현을 했어야했던 것들이 Webplate에서는 구현이 되어있다는 것이 좋은 듯. 
한 마디로 Bootstrap은 style에 대한 기본 base느낌이라면 Webplate는 진짜 front framework다</li>
<li>비록 내가 따로 설정을 해줘야하지만, example project에서 기본 글씨체를 Lato로 강제해서 참 좋다. Open Sans 애리얼 헬베티카 꺼졍&#8230;</li>
<li>다시 framework에 대한 얘기인데, pre태그 에서 코드 이쁘게 보여주는 기능을 class로 부르기만 하면 되게 구현이 되어있어서 짱짱 편하다. 내가 라이브러리 찾아서 부를 수도 있지만 귀찮으니까&#8230; </li>
<li>기본적으로 필요한 대부분의 라이브러리가 포함되어있다. response.js를 포함해서! 때문에 반응형으로 만들기도 편하고 호환에 대한 두려움 없이 작업을 하는게 가능하지만 ie에서 완전 호환이 되는지 잘 모르겠다. (아마 되겠지)</li>
<li>이 framework 자체가 vertical UI를 강제하고 있다. 최근 핫한 UI이기는 하지만 (stripe UI같은거) 다른 모양을 원하는 경우에는, 특히 상단 바가 아니라 좌측에 메뉴를 넣고 싶은 경우라면 이 framework을 쓰는게 아니라 따로 만들어야할 것 같다. (하지만 요즘 모든 웹은 다 기본이 vertical UI..)</li>
<li>Service, Product 등의 introduction page를 간단하게 만들 생각이라면 이보다 더 Cool한 web framework는 없어보인다. (전시회 소개나 festival page로도 좋을 것 같네) 그 이외에 어떤 곳에서 이 framework를 사용할 수 있을지 아직은 잘 모르겠다. Vertical UI를 쓸 수 있는 곳이라면 전부 쓸 수 있을 것 같기는 하다.</li>
</ol>


<p>한 마디로 간단하게 만들 수 있는 웹은 이 녀석으로 대략 커버가 가능하다는 점, 그리고 반응형에 대한 이슈를 내가 따로 고민할 필요가 없다는 점이 너무 마음에 들었다. <a href="http://getwebplate.com/documentation">Document</a>링크를 첨부할테니 관심있는 사람들은 한 번 읽어봤으면 좋겠다. 최근 이걸 사용해 따로 개발할 웹이 없어서 정작 내가 사용해볼 수가 없다는게 아쉽기는하다.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/77/">모바일 시대 Platform에 대한 고찰</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-10-10T02:27:00+09:00" pubdate data-updated="true">Oct 10<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>얼마 전 MS에서 윈도우10의 preview를 발표하였다. <a href="http://www.bloter.net/archives/208421">블로터 기사</a>를 참고하면 알 수 있 듯, 아직 테크니컬 프리뷰 단계이기는 하지만 MS가 어떤 철학을 가지고 이런 운영체제를 디자인했는가는 어렵지 않게 예상할 수 있다. 스마트폰과 태블릿 데스크톱 그리고 콘솔 등에 이르는 수 많은 isolate 되어있는 기기들을 통합으로 관리할 수 있는 하나의 거대한 통합 플랫폼을 만들어내겠다라는 의지가 바로 그것이다. <a class="red tip" title="소문에 의하면 95,98 버전 확인을 windows 9가 포함이 되었느냐 아니냐로 하기 떄문이라고.">왜 8다음에 10이냐는 이슈는 넘어가고</a> 과연 MS의 이런 행보가 어떤 파장을 일으킬 수 있을지에 대해 생각해보고 싶어졌다.</p>


<h5>모바일 모바일 모바일</h5>


<p>그래 바야흐로 모바일의 시대가 도래하였다고 해도 과언이 아니다. 내 블로그에 붙여놓은 google analytics를 보니까 내 블로그는 PC가 약 75%, 모바일이 약 18%, 그리고 태블릿이 약 7% 정도의 접속률을 보이고 있다. 즉, 내 블로그를 읽는 사람들의 행동 양식만 보고 비교를 하자면 아직은 PC로 웹을 보는 사람들이 모바일이나 태블릿 (합쳐서 모바일이라 하자) 으로 웹을 보는 사람들에 비해 약 5배 정도 많다. 그러나 이것은 내 블로그가 특수한 환경에 처한 것이고 (대부분의 유입이 구글 검색이고 키워드가 머신러닝이니까..) 실제 전체 웹을 보게 되면 상황이 많이 달라진다. StatCounter의 <a href="http://gs.statcounter.com/#all-comparison-ww-monthly-201309-201409">global stats page</a>를 참고해보면 모바일의 비중이 거의 30% 가까이를 차지하고 있으며, 태블릿까지 포함하면 약 37~8% 정도에 육박한다는 사실을 알 수 있다.</p>


<p><img src="/images/post/77-1.png" width="500"></p>

<p>이 속도가 엄청나게 빠르게 증가하고 있다는 사실이 바로 그것인데, 불과 1년 사이에 모바일 뷰가 17%에서 거의 30%까지 증가한 것이다. 거의 75% 가까이 증가한 셈이다. 지역을 한국으로 좁혀서 보게 되면 (<a href="http://gs.statcounter.com/#all-comparison-KR-monthly-201309-201409">링크</a>) 우리는 상대적으로 태블릿의 점유율은 엄청 낮은 대신, 모바일의 비중이 매우 높다는 것을 알 수 있다.</p>


<p><img src="/images/post/77-2.png" width="500"></p>

<p>그리고 어느 정도 1년 동안의 변화 정도가 일정한 것을 알 수 있다. 경험적으로 비춰보았을 때, PC를 거의 사용하지 않고 모바일로만 보는 사람들이 그만큼 많아졌다는 뜻이 아닐까라고 생각된다.</p>


<p>그리고 또 이렇게 general하게 전체 웹 view만 보는 것이 아니라 큰 서비스로 시선을 돌리면 또 얘기가 달라진다. <a href="http://www.nasmedia.co.kr/">나스미디어</a>의 <a href="http://lib.nasmedia.co.kr/file/534f5d4242381">2014년 NPR (Netizen Profile Research)</a> 에 의하면, PC 인터넷 이용자의 스마트폰 이용률이 현재 88.1%에 육박하며 이는 전년 대비 11.5% 상승한 결과라고 한다. 그리고 사실 정말 재미있는 지표는 11쪽에 있는 SNS 접속 디바이스인데, 싸이, 미투, 구글플러스와 같은 마이너한 서비스는 제외하고 (심지어 미투데이는 올해 서비스를 종로했다 ㅠㅠ) 아래에서 볼 수 있듯 모바일의 비중이 매우 높다는 것을 알 수 있다.</p>


<p><img src="/images/post/77-3.png" width="600"></p>

<p>즉, 이제 모바일은 절대로 무시할 수 없는 현실이라는 것을 데이터가 보여주고 있는 것이다.</p>


<p></p>

<h5>모바일 사용자, PC 사용자</h5>


<p>그런데 내 생각에 저런 수치들이 제대로 반영하지 못하는 하나의 현실이 더 있다. 바로 극명하게 다른 PC 사용자와 모바일 사용자들의 성향이다. 모바일 사용자는 처음 몇 번의 시도 후 제대로 동작하지 않는 것 같다고 느끼면 그냥 서비스에서 이탈해버리고 다시 돌아오지 않는 경우가 많다. 즉, 이탈률이 매우 높다. 따라서 이탈을 하지 않도록 사용자에게 빠르게 지속적으로 동작을 유도해야한다. 또한 PC에 비해 모바일의 화면이 더 작아 너무 많은 정보를 한 번에 받는 것에 대해 부담을 느낀다. 마지막으로 그 둘의 역할이 많이 분리가 되었다. 간단한 검색이나 기사 읽기 등 &#8216;이건 내가 모바일로도 할 수 있겠다&#8217; 하는 일들이라면 모바일에서 처리하는 유저의 비중이 높은 반면, 복잡한 멀티프로세싱을 해야하는 경우라면 PC가 더 사용률이 높다. 다시 말해, PC와 모바일은 비슷해보일지 몰라도 자세히 보면 완전히 다른 성향을 가지고 있는 별개의 플랫폼이다. 즉, 어떤 서비스를 개발했을 때, 완전히 다른 두 개의 플랫폼에서 이 서비스를 동시에 지원할지 말아야할지 염두해두어야하며, 만약 동시에 지원하는 경우 이 작업을 꼭 PC앞에서 해야하는 강력한 motive 가 있는게 아니라면 많은 사람들은 모바일로 그 서비스를 접근하려 할 것이라는 말이다. 그게 웹이되었거나 앱이 되었거나.</p>


<h5>Mobile First</h5>


<p>Start up 쪽에서 흔히 많이 하는 말 중에 Lean Start up 이라거나, Mobile first 등의 용어가 있다. [Mobile first: <a href="http://www.lukew.com/ff/entry.asp?933">링크1</a>, <a href="http://study.gnuboard.org/wiki/read/studygroup/rwd/Mobile-First-and-RWD">링크2</a>, <a href="http://h30458.www3.hp.com/kr/ko/discover-performance/it-execs/2012/oct/1243352.html">링크3</a>], [Lean Startup: <a href="http://theleanstartup.com/">링크1</a>, <a href="http://www.jimmyrim.com/153">링크2</a>, <a href="http://platum.kr/archives/tag/%EB%A6%B0%EC%8A%A4%ED%83%80%ED%8A%B8%EC%97%85">링크3</a>]</p>


<p>Mobile first는 간단히 얘기하면 처음 시작점을 무조건 모바일에 맞춰서 시작을 하라는 의미이다. 이유는 (1) 모바일이 점점 거대해지고 있으며 (2) 모바일 개발에만 치중하면서 적은 리소스를 한 곳에 집중할 수 있을 뿐더라 (3) 모바일에 포함되는 많은 기술들이 (GPS, Multi-touch UI 등) 기존 웹에서 사용되는 javascript 기반의 PC-based Web보다 더 많은 사용자 경험을 줄 수 있기 때문이라는 것이다. 내 생각에도 지금 같은 서비스를 사용하더라도 많은 사람들이 mobile로 그 서비스를 access하는 경우가 점점 늘어나고 있으며, 만약 모바일과 웹이 있을 때 하나를 선택하라고 했을 때 모바일로 접속을 하는 사람들이 많아지고 있는 지금, 웹을 먼저 개발하기 보다는 모바일에 먼저 치중한 이후 나중에 웹으로 확장을 하는 편이 더 좋다고 생각된다. (때에 따라서는 PC 지원을 아예 하지 않는 경우도 존재한다) 하지만 Mobile first를 할 때 주의해야할 점들이 몇 가지가 있는데, 가장 중요한 것은 품질관리이다. 모바일은 아주 빠르게 변화하는 곳이기 떄문에 더 빠른 업데이트와 대응이 필수적인데, 자칫잘못했다가는 제품의 품질이 떨어지고 앱의 평점과 리뷰가 부정적인 방향으로 바뀔 수 있기 때문이다. 또한 현재 모바일 앱의 특성상 나쁜 리뷰와 별점은 추가적인 앱 다운로드에 악영향을 미친다. 따라서 이 <a href="http://h30458.www3.hp.com/kr/ko/discover-performance/it-execs/2012/oct/1243352.html">Mobile first: 링크3</a>에서 제안하는 방법은 애자일 프로세스이다. 기존의 느린 의사결정 방식으로 모바일 애플리케이션을 대해서는 안된다는 의미이다. 더 빠르고 더 기민하게 움직여야만한다. 그리고 난 그런 흐름 속에서 Mobile first가 Lean startup과의 시너지를 도모할 수 있다고 본다. 하지만 애자일을 도입해도 근본적인 제약조건이 존재하는데, (1) 작은 화면, (2) 네트워크 품질 (3) 기기의 성능 이 그것이다. 이 부분에 대해서는 뒤에 더 자세히 다뤄보도록하자.</p>


<p>Lean startup은 일종의 프로덕트 개발 방법론 중 하나인데, 애자일한 개발, 완성되지 않은 프로토타입의 시장 진출, 고객과의 긴밀한 피드백루프 구축 등으로 구성이 되어있다. 기본적인 아이디어는 waterfall 식의 느린 의사결정으로 회사를 운영하거나, 제품을 개발하지 말고, 최대한 lean하게, 혹은 애자일하게 일단 빨리 빨리 무엇을 만들어보고 시장의 반응을 보고 버리거나 다른 식으로 develop을 하라는 얘기이다. 때문에 방금 전에 언급했던 Mobile first와 상당한 시너지를 일으킬 수 있는데 기본적으로 애자일 방법론을 기반으로 하기 때문에 위에서 언급했던 빠른 대응이나 지속적인 배포를 하기에 매우 용이하며, 프로토타입 단계에서 시장에 대한 가설을 테스트할 때에도 모바일에서 먼저 가설을 테스트해보고 더 크기를 키워도 되겠다는 결정을 내리고 나서 웹이나 다른 플랫폼으로의 확장을 결정하라는 것이다. 린스타트업에 대해 파고들어가기 시작하면 너무나 많은 얘기를 해야하기 때문에 깊은 얘기는 가급적 피하도록 하겠지만, 분명 린스타트업은 모바일퍼스트와 궁합이 잘 맞는 조합임에 분명하다.</p>


<p>모바일퍼스트니, 린스타트업이니 하는 거창한 얘기를 하지 않더라도 내가 어떤 서비스를 만든다고 하면 이제는 항상 모바일에 대한 생각을 하지 않을 수 없다. 이 서비스를 지금은 모바일에서 지원할 예정이 없더라도 추후 모바일에서도 지원할지, 아니면 모바일에서만 지원할지 나중에 웹으로 확장을 할 것인지. 네이티브 앱으로 만들 것인지 아니면 웹으로 만들어서 모바일 뷰를 따로 만들 것인지. 모바일 뷰를 따로 만들 것인지 아니면 반응형으로 만들어서 하나의 통합 url로 관리를 하게 할 것인지. 이 모든 것들을 반드시 처음에 한 번 쯤은 생각을 해야만 한다.</p>


<h5>모바일의 제약조건</h5>


<p>그런데 모바일이 만능 키인 것은 아니다. 모바일은 근본적으로 하드웨어에서부터 기인하는 여러 문제점들을 떠안고 있기 때문이다. (1) 작은 화면 (2) 모바일 네트워크 (3) 기기의 성능이 그것이었다.</p>


<p>먼저 작은 화면은 UI적인 측면에서 엄청난 변혁을 일으켰다. 기존의 PC-based 서비스들은 (웹 기반인 경우) 처음 보이는 웹에 굉장히 많은 정보들을 넣고 사용자가 그 정보들을 알아서 고르게하는 방식을 선택했었다면, 모바일로 넘어오고 나서는 그 화면의 크기가 어마어마하게 줄었기 때문에 (간단하게 생각해보면 22인치 모니터에서 5.5인치 아이폰6플러스는 화면의 크기가 16배 차이가 난다.) 처음 보여주는 정보의 양도 제한적일 수밖에 없고 또한 UI 역시 2차원적인 UI가 아니라 스크롤이 들어가는 1차원 세로형 UI가 강제 된다. 때문에 모바일에 익숙하지 않은 상태에서 UX를 web을 만들듯 디자인을 하게 되면 사용자 입장에서는 별로 좋지 못한 UX를 경험할 수 밖에 없는 것이다. 하지만 화면이 작기 때문에 채워야하는 정보의 양도 적고, 내가 어떤 정보를 보여줘야 더 효율적일지 더 고민할 수 있는 여지가 있기 때문에 오히려 작은 화면이 더 좋은 서비스를 개발하는데에 도움이 된다는 주장도 존재한다.</p>


<p>다음으로 모바일 네트워크의 문제는 LTE로 넘어오면서 거의 해결이 되었다. 하지만 아직도 다른 국가들을 봤을 때 3G 이상의 망이 이렇게 보급이 된 곳은 많이 없고, 또한 모바일 유저는 데이터 소모에 매우 민감하기 때문에 앱을 설계할 때 네트워크 리소스에 대한 고민을 해야할 필요가 여전히 존재한다.</p>


<p>마지막으로 기기의 성능 문제가 있다. 이건 꽤나 치명적인데, Web을 생각해보자. 웹은 서버에서 모든 로직이 실행되고 사용자 컴퓨터의 성능에 좌우되는 것은 랜더링을 하는 브라우져 뿐이었다. 즉, 동적으로 무언가를 생성하는 스크립트 등의 속도가 다소 느려질 수 있는 문제를 제외하면 대부분의 속도에 관련된 문제는 서버side에서 해결해야하는 경우가 대다수였다. 하지만 모바일로 넘어오면서 얘기가 완전히 달라졌는데, 먼저 PC보다 브라우져의 성능이 크게 저하되었고, 스마트폰의 여러 리소스를 사용하는 일은 그만큼 배터리 소모를 빠르게하고 스마트폰의 성능을 저하하는 요소가 되었기 때문에 상당히 많은 부분에서 희생을 해야한다. 물론 서비스를 한다는 것 부터가 이미 서버를 사용한다는 의미가 되기 때문에 크게 문제가 없을 수도 있지만, 이는 분명 PC에 비해 어마어마한 단점이다.</p>


<h5>결론1: 모바일을 대하는 우리의 자세</h5>


<p>이제 모바일은 절대로 무시할 수 없는 거대한 공룡이 되어가고 있다. 새로운 서비스를 시작할 때 거의 99.9% 이상 모바일퍼스트를 선택해야하며 이에 따라 필연적으로 애자일방법론, 더 나아가 린스타트업을 적용해야할 필요가 있다. 그러나 근본적으로 모바일의 제약조건이 존재한다는 점은 꽤나 치명적인데, 그만큼 한 서비스를 만들 때 처음부터 모바일에 모든 리소스를 부어가며 시작할 필요가 있다는 것이다. 그리고 모바일 이외의 환경으로 확장하는 것도 항상 염두를 하며 서비스 아키텍쳐 설계를 할 때 이에 대한 문제를 항상 생각을 할 필요가 있을 것이다.</p>


<h5>결론2: 통합 플랫폼을 만드려는 MS의 행보는 어떤 결과를 가져올까</h5>


<p>앞서 설명했듯 MS는 새로운 통합 플랫폼에 대한 원대한 야망을 가지고있다. 하지만 나는 이것이 별로 효과가 없을 것이라고 생각하는데, (1) 모바일과 웹을 동시에 지원하는 것이 아니라 어차피 모바일에만 집중해야하는데 두 개를 전부 고려해서 설계를 하면 리소스가 분산이 되기 쉽다. (2) 모바일과 PC의 사용자 성향은 극도로 다르기 때문에 PC에서 주었던 경험을 모바일에서 그대로 주는 것이 항상 능사는 아니다. (3) PC와 모바일 둘 다 이미 어느정도 정형화된 경험이 존재하는데, 그 경험을 깨어가면서까지 새로운 윈도우를 사용하게할 유인요소가 보이지 않는다. 결론적으로 서비스를 만드는 입장에서 결론적으로는 모바일과 PC는 함께 가져가야할지 모르지만, 처음 시작하는 단계에서부터 반드시 같이 가져가야하는 것은 아니기 때문에 나는 윈도우10 역시 좋은 평가를 받지 못할 것이라 생각된다.</p>




<h5>References</h5>


<ul>
<li>StatCounter <a href="http://gs.statcounter.com/#all-comparison-ww-monthly-201309-201409">global stats page</a></li>
<li><a href="http://www.nasmedia.co.kr/">나스미디어</a>의 <a href="http://lib.nasmedia.co.kr/file/534f5d4242381">2014년 NPR (Netizen Profile Research)</a></li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/62/">Machine Learning 스터디 (6) Information Theory</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-08-20T00:20:00+09:00" pubdate data-updated="true">Aug 20<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Information Theory는 섀년이라는 걸출한 천재가 이룩해낸 매우 뛰어난 이론이다. 이 이론 덕분에 우리는 이렇게 인터넷도 할 수 있고, 무선통신도 할 수 있는 것이다. 이 이론 덕분에 불안정한 noisy한 channel에서도 유한한 시간 안에 우리가 전달하고 싶은 정보를 전부 전달할 수 있다는 것을 확신할 수 있고, 이론적인 한계값까지 도출이 가능한 엄청난 이론이다. Machine Learning에서도 이런 information theory 측면에서 문제를 바라보는 경우가 종종 있는데, Entropy, Mutual Information, KL-divergence 등이 그것이다. 이 글에서는 그런 Machine Learning의 관점에서 많이 쓰이는 기초적인 정보이론의 개념들을 짚고 넘어가볼까 한다.</p>


<h5>Entropy</h5>


<p>엔트로피는 &#8216;정보&#8217;의 단위라고 할 수 있다. 어떤 distibution p(x)에서 generate되는 discrete random variable x가 있다고 해보자. 이 random variable x가 전달할 수 있는 정보량은 어떻게 계산할 수 있을까. 여기에서 &#8216;정보&#8217;란 얼만큼의 bit가 있어야 x에 대한 정보를 완벽하게 얻을 수 있는가로 정의해보자. 예를 들어서 fair한 동전 던지기의 정보량은 1이다. 한 비트만 있으면 반드시 그 동전 던지기의 distribution을 서술할 수 있다. 그러나 만약 fair coin이 아니라면 한 면이 나올 확률이 다른 면이 나올 확률보다 상대적으로 더 크기 때문에 한 비트보다도 더 적은 정보를 사용해 값을 맞추는 것이 가능해진다. 이런 정보의 양을 <a href="http://en.wikipedia.org/wiki/Entropy_(information_theory)" target="new">Entropy</a>라는 것으로 정의하게 되는데, 간단하게 생각하면 열역학2법칙의 그 엔트로피와 동일하다. 즉, 엔트로피가 커질수록 불확실성이 높아지고 정보량은 더 많아진다. Entropy는 \(H(x) = - \sum_x p(x) log_2 p(x) \)로 정의가 되며, 만약 p(x)가 0으로 가면 \(\log_2 p(x)\)는 음의 무한으로 발산하지만, p(x)가 0이 되는 속도가 더 빠르기 때문에 엔트로피는 0이 된다.</p>


<p>그럼 왜 엔트로피는 이런 꼴을 하게 되는 것일까. 만약 우리가 전체 N개의 object들이 있고, 이 object들이 K개의 bin으로 나뉘어져있다고 해보자. 그리고 i번째 bin에 들어갈 수 있는 object의 개수를 \(n_i\)라고 했을 때, object들이 bin에 들어갈 수 있는 permutation의 개수는 \(W = \frac{N!}{\prod_i n_i!}\)와 같으며 이를 multiplicity라고 한다. 엔트로피란 이 multiplicity에 비례하는, 정확히는 log를 취한 값을 엔트로피라고 하게 된다. 즉 Entropy H는 multiplicity W에 대해 다음과 같이 표현된다.</p>


<p>\[H = \frac{1}{N}\ln W = \frac{1}{N}\ln N! - \frac{1}{N}\sum_i \ln n_i ! \]</p>


<p>이때 \(\lim N \to \infty \) 라고 해보자, 그러면 우리는 <a href="http://en.wikipedia.org/wiki/Stirling's_approximation" target="new">Stirling 근사</a>를 할 수 있는데 이는 \(\ln N! \simeq N \ln N - N\)으로 주어진다. 이를 대입해서 잘 정리해보면 아래와 같은 식을 얻을 수 있다.</p>


<p>\[H = -\lim_{N \to \infty} \sum_i \left( \frac{n_i}{N} \right) \ln \left( \frac{n_i}{N} \right) = - \sum_i p_i \ln p_i \]</p>


<p>이는 위에서 정의한 엔트로피의 값과 일치한다.</p>


<p>그런데 이 값은 discrete한 random variable에 대해 정의된 값이고 continous한 random variable x에 대해서는 <a href="http://en.wikipedia.org/wiki/Differential_entropy" target="new">differencial entropy</a>라는 정의할 수 있다. <a href="http://en.wikipedia.org/wiki/Mean_value_theorem" target="new">평균값 정리</a>에 의해서 우리는 다음을 만족하는 value \(x_i\)를 반드시 찾을 수 있다</p>


<p>\[ \int_{i\Delta}^{(i+1)\Delta} p(x) dx = p(x_i) \Delta\]</p>


<p>엔트로피는 discrete한 random variable에 대한 값이었는데, 위 식을 통해 continous variable x를 위의 식을 만족하는 \(x_i\)로 치환하는 방식으로 quantize할 수 있다. 또한 이런 경우 각 \(x_i\)를 관측할 확률이 \(p(x_i)\Delta\)로 계산되므로, 이렇게 했을 경우 엔트로피는 아래와 같이 계산할 수 있다.</p>


<p>\[H_\Delta = -\sum_i p(x_i) \Delta \ln ( p(x_i) \Delta ) = - \sum_i p(x_i) \Delta p(x_i) - \ln \Delta \]</p>


<p>이때, 오른쪽 term은 x에 대한 값이 아니니까 일단 먼저 무시하고, \(\lim \Delta \to 0\)를 취해보자. 이렇게 계산할 경우 아래 식이 얻어진다.</p>


<p>\[\lim_{\Delta \to 0} H_\Delta = \lim_{\Delta \to 0} -\sum_i p(x_i) \Delta \ln ( p(x_i) \Delta ) = -\int p(x) \ln p(x) dx\]</p>


<p>이때, 맨 오른쪽 term을 differencial entropy라고 정의한다. 즉, differencial entropy는 다음과 같이 정의된다.</p>


<p>\[H(x) = -\int p(x) \ln p(x) dx\]</p>


<p>마지막으로 random variable이 x,y 두 개가 있고 이 둘의 joint distribution p(x,y)가 있다고 해보자. 우리가 알고 있는 정보는 x의 value라고 했을 때 우리는 y의 information의 양을 계산할 수 있을까? 이를 <a href="http://en.wikipedia.org/wiki/Conditional_entropy" target="new">Conditional Entropy</a>라고 하는데 이때 y에 대해 필요한 additioanl information은 \(p(y|x)\)이며, x와 y의 확률은 p(x,y)이므로 Conditional Entropy는 아래와 같이 정의된다.</p>


<p>\[H(y|x) = - \int \int p(y,x) \ln p(y|x) dy dx\]</p>


<p>이 값은 다음과 같은 chain rule을 항상 만족시킨다.</p>


<p>\[H(x,y) = H(y|x) + H(x)\]</p>


<h5>KL divergence</h5>


<p>어떤 probability distribution p(x)와 p(y)가 있다고 했을 때 이 둘의 차이, 혹은 distance를 정의할 수는 없을까. 예를 들어 p(x)라는 우리가 모르는 unknown distribution이 있을 때, 우리가 추측한 \(p(\hat x)\)와 true distribution p(x)가 얼마나 차이나는지를 계산할 수 있는 방법은 없을까. 만약 우리가 q(x)를 사용해서 x를 transmitting하는 coding scheme을 construct했다고 해보자. 그리고 true distribution을 p(x)였다고 했을 때, q(x)를 사용하였을 때 얼마나 더 많은 정보량이 필요할 것인지 measure할 수 있을 것이다. 이를 <a href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" target="new">Kullback-Leibler divergence</a> 혹은 KL divergence라고 하며 수식은 아래와 같다.</p>


<p>\[KL(p\|\|q) = - \int p(x) \ln q(x) - \left( -\int p(x) \ln p(x) dx \right) &#92;&#92; = -p(x) \ln \left[ \frac{q(x)}{p(x)} \right] dx \]</p>


<p>정확히 얘기하면 이 값은 &#8216;distance&#8217;가 될 수는 없다. 왜냐하면 distance, 혹은 metric은 symmetric해야하는데 KL divergence는 \(KL(p\|\|q) \neq KL(q\|\|p)\) 이기 때문이다.</p>


<p>KL divergence는 언제나 0 보다 크거나 같은데, 같은 경우는 오직 p(x)와 q(x)가 일치하는 경우 뿐이다. 이를 증명하기 위해서는 convexity 컨셉과 Jensen&#8217;s inequality를 도입하면 쉽게 증명이 가능하지만, 여기에서는 생갹하도록 하겠다.</p>


<p>중요한 점은, KL divergence는 두 distribution의 차이를 define할 수 있는 좋은 수단 중 하나라는 것이며, 다시 말해 원래 true distribution p(x)와 우리가 estimate한 q(x)가 얼마나 비슷한지를 measure할 수 있는 수단이라는 점이다.</p>


<h5>Mutual Information</h5>


<p><a href="http://en.wikipedia.org/wiki/Mutual_information" target="new">Mutual Information</a>은 두 random variable들이 얼마나 mutual dependence한지를 measure하는 방법을 의미한다. 만약 random variable x와 y가 independent하다면 joint distribution p(x,y) 는 p(x,y) = p(x)p(y) 로 주어지게 될 것이며, 만약 둘이 dependent한 경우에는 두 값이 달라질 것이다. 그렇다면 만약 true distribution을 p(x,y)라고 했을 때, 새롭게 우리가 x와 y가 independent하다고 estimate하고 구한 p(x)p(y)와의 KL-divergence를 구할 수 있지 않을까? 당연히 이 값은 x와 y가 independent할 때만 0이고 그 이외에는 항상 0보다 크다. 즉, 두 random variable이 얼마나 mutually dependent한가, 얼마나 Mutual하게 information을 많이 가지고 있느냐를 측정할 수 있는 도구가 되므로 이를 Mutual information이라 한다. 수식으로 표현해보면 아래와 같다.</p>


<p>\[I(x,y) = KL(p(x,y)\|\|p(x)p(y) &#92;&#92; = - \int \int p(x,y) \ln \left( \frac{p(x)p(y)}{p(x,y)} \right) dx dy\]</p>


<p>위의 값을 Mutual Information이라 하며, 이 값은 항상 다음과 같은 관계를 만족시킨다.</p>


<p>\[I(x,y) = H(x) - H(x|y) = H(y) - H(y|x)\]</p>


<h5>Machine Learning and Information Theory</h5>


<p>Entropy는 주어진 bin에 얼마나 비슷한 element들이 들어있는지를 측정하는 척도로 쓰일 수 있으며, decision tree를 learning하는 알고리듬 등에서도 사용할 수 있다. 또한 KL-divergence는 두 distribution과의 거리를 의미하므로, density estimation 관점에서 바라봤을 때 우리가 estimate하는 distribution과 원래 true distribution이 얼마나 유사한지, 우리가 얼마나 잘 density estimation을 했는지 evaluation을 하는 용도 등으로 쓰일 수 있다. 마지막으로 Mutual information을 Bayes perspective에서 바라보게 된다면, 만약 우리가 어떤 데이터 x의 prior p(x)를 관측하고, 새로운 데이터 y를 관측해 얻은 posterior distribution p(y|x)가 있다고 했을 때, Mutual information은 이전 관측 x를 통해 새로운 관측 y의 uncertainty가 얼마나 reduction 되는지를 의미하게 되는 것과 동일하다는 것을 알 수 있다.</p>


<p>정보이론 자체는 Machine Learning과 크게 관계가 없어보이지만, 그 개념들은 생각보다 꽤 많은 부분에서 사용되게 되므로 좀 간략하게 다루게 되었다.</p>


<p>추가: 정보이론이 어떻게 머신러닝에 유용하게 쓰일 수 있는가에 대한 lecture와 book link들 <a href="http://www.inference.phy.cam.ac.uk/itprnn_lectures/">http://www.inference.phy.cam.ac.uk/itprnn_lectures/</a>, <a href="http://www.inference.phy.cam.ac.uk/mackay/itila/book.html">http://www.inference.phy.cam.ac.uk/mackay/itila/book.html</a></p>




<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li>Convex Optimzation</li>
<li>Classification Introduction (Decision Tree, Naïve Bayes, KNN)</li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Graphical Model</li>
<li>Hidden Markov Model</li>
<li>Clustering (K-means, Gaussian Mixture Model)</li>
<li>EM algorithm</li>
<li>Feature Extraction</li>
<li>Matrix Completion</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>And others.. (Reinforcement Learning, Boosting, Model Selection)</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/61/">Machine Learning 스터디 (5) Decision Theory</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-08-19T18:13:00+09:00" pubdate data-updated="true">Aug 19<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>그 어떤 좋은 알고리듬을 선택하더라도, 최종적으로 특정 문제에 대해 inference를 하기 위해서는 decision making을 해야만 한다. 그렇다면 decision은 어떻게 내릴 수 있을까? 라는 질문이 자연스럽게 들 수 있는데, decision theory는 그런 decision을 어떻게 내릴 것인가에 대해 다루는 영역이라 할 수 있다. 내가 지금 결정한 parameter는 적당한 parameter인가? 예를 들어서 내가 임의의 데이터를 가장 잘 설명할 수 있는 1차함수를 그려야하는 상황이라고 했을 때, 나는 그 &#8216;가장 잘 설명할 수 있는&#8217; parameter를 어떻게 decide할 수 있을까, 어떻게 decision making을 할 수 있을까. 혹은 Classification problem에서 해당 data가 어떤 class에 속하는지 어떤 방식으로 decision을 내려야할까?</p>


<h5>Decision rule with prior only</h5>


<p>다시 <a href="58#58-1-Bayes" target="new">Bayes Rule</a>로 돌아가보자.</p>


<p>\[ p(C|X) = {p(X|C) p(C) \over p(X)} \]</p>


<p>이전 글에서 prior라는 것에 대해 언급했었다. 예를 들어 우리가 어떤 classification을 하는 상황이라 해보자. 만약 주어진 데이터가 class A인지 B인지 구분해야하는 상황이라고 가정을 해보자. 우리가 아는건 prior P(C) 밖에 모르는 상황이라고 해보자. 그렇다면 우리가 내릴 수 있는 가장 합리적인 판단은 무엇일까? 이 상황에서의 가정은 우리가 아는 정보는 오직 prior밖에 없으며, incorrect classification에 대한 cost는 모두 동일하다고 가정한다. 그렇다면 당연히 reasonable한 decision rule은 가장 높은 확률을 가지는 class를 선택하는 것일 것이다. 이유는 가장 확률이 높은 클래스를 C1이라 하면, 언제나 \(P(C1) > P(C2)\) 라는 사실을 알 수 있기 때문이다. 즉, 언제나 C1을 고르는 것이 가장 best하다. 그렇다면 여기에서 문제가 발생하는데, 만약 우리가 모든 decision을 동일하게 내리게 된다면 당연히 좋은 결과가 나올리가 없다는 점이다. 예를 들어 C1이 60%, C2가 40% 존재하는 상황이면, 언제나 error는 0.4가 될 것이며, 언제나 classification result는 C1이 될 것이기 때문이다. 그러나 일단 우리가 prior만 가지고 있다고 가정하고 있기 때문에 이런 상황에서는 언제나 이것이 best가 될 것이다. 그렇다면 이 이외의 다른 정보를 가지고 있다면 어떨까?</p>


<h5>Decision rule with Likelihood</h5>


<p>Observation, 혹은 Likelihood에 대한 정보를 가지고 있다면 분명 상황은 더 나아질 수 있다. 확률로 표시하자면 이 값은 \(P(X|C)\), 즉 주어진 클래스에 대해 관측되는 데이터가 된다. 그리고 당연하게도, 우리가 이 값을 가지고 있다면, Bayes rule에서부터 P(C|X), 혹은 posterior를 계산할 수 있게 된다. 즉, prior와 likelihood를 알고 있으므로, \(C = argmax P(C|X) = argmax {P(X|C) P(C) \over \sum_i P(X|C_i) P(C_i) } \) 를 통해 decision을 내릴 수 있게 된다. 그렇다면 이렇게 선택하는 경우 error는 어떻게 나타나게 될까? 여기에서 error는 classification이 틀린 경우를 의미한다 (number of misclassification). 일단 class가 2개 밖에 없다고 해보자. 그럼 error가 발생하는 경우는 단 두가지인데,</p>


<p>\[P(error|x) = \begin{cases} P(C1|X) \text{ if we decide C2} &#92;&#92; P(C2|X) \text{ if we decide C1} \end{cases} \]</p>


<p>이렇게 두 가지가 될 것이다. 즉, 우리가 P(C|X)를 maximize하는 C를 선택하는 decision rule을 가지고 있다면, P(error)는 간단하게 다음과 같이 계산된다</p>


<p>\[P(error) = \int P(error|X) P(X) dX \]</p>


<p>가 될 것이며, 이 결과를 최소화하는 decision making rule이 우리가 원하는 decision rule이 될 것이다. (당연히 우리는 결과의 error가 최소화되는 것을 원할테니까.) 결론만 놓고 얘기하자면 prior와 likelihood를 모두 알고 있다면 위와 같이 posterior를 maximize하는 것이 가장 이 값을 \(P(error|X) = min[P(C_1|X), &#8230;, P(C_k|X)]\) 로 최소화 시킬 수 있다. (이유는 조금 생각해보면 간단하게 알 수 있다.) 즉, 모든 class의 posterior를 계산하여 주어진 데이터에 대해 얻어질 확률이 가장 큰 class를 선택하는 것과 정확히 같다는 의미이다. (참고로 만약 prior에 대한 정보가 없어서 uniform한 prior를 가정하게 된다면 결국 likelihood만을 놓고 계산한 값과 정확히 일치하게 된다.)</p>


<h5>Loss function</h5>


<p>앞서 설명한 예제는 &#8220;misclassification number&#8221;를 minimize하는 예제였다. 그러나 실제 많은 application들에서 이런 방식 이외의 다른 approach를 요구하게 된다. 예를 들어서 값이 틀렸을 때 0과 1로 error를 정의하는 것이 아니라, 원래 target data와 우리가 계산한 estimated data의 차이의 제곱의 합들로 표현을 할 수도 있고, 제곱이 아니라 절대값의 합으로 표현할 수도 있다. 즉, 보다 더 generalized된 접근법이 필요한데, 가장 formal하게 많이 쓰이는 decision criteria 중 하나로 <a href="http://en.wikipedia.org/wiki/Loss_function" target="new">lost function</a> 혹은 cost function이 있다. Cost function은 여러가지로 정의할 수 있겠지만, 나는 Cost function을 이렇게 정의한다. 우리가 목표로 하는 가장 좋은 결과와 지금 내가 선택한 결과와의 차이. 즉, 내 결과가 optimal한 결과보다 좋지 않으면 않을수록 cost function은 커지고, 당연히 optimal한 결과를 가지게 됐을 때 Cost function의 값이 가장 작아질 것이다. 다만, 그 차이는 여러가지 방법으로 정의할 수 있는데, 앞서 misclassification number와 같은 binary한 차이가 될 수도 있고, 또 앞서 내가 예로 들었던 원래 값과 예상 값의 차이의 제곱의 합.. 등 굉장히 다양하게 cost function을 정의하는 것이 가능하다. 그리고 이런 함수는 true value가 변하지 않고, parameter에 따라 estimated value가 변하게 되므로, loss function은 parameter에 대한 함수로 나타나게 된다. 이때, Loss function은 \(L(\theta, \hat \theta(X))\)로 표기되며, 우리가 찾고자하는 true parameter를 \(\theta\), 주어진 data X에 대해 estimate한 parameter를 \(\hat \theta(X)\)라 하자. 우리의 목표는 가장 적절한 parameter \(\hat \theta(X)\)를 찾는 것이다.</p>


<h5>Minimize Bayes Risk</h5>


<p>자 다시 Decision rule로 돌아가보자. 우리가 minimize하고 싶은 것은 Loss function을 minimize하는 것이지만, 그 값 자체가 true value에 dependent하기 때문에 정확한 값을 구하는 것이 불가능하다. 따라서 주어진 데이터 X에 대해 expectation을 계산하여 이를 해결하게 된다. 주어진 데이터들에 대한 loss function의 expectation은 \(R = \int \int L (\theta, \hat \theta(x)) p(\theta, x) dx d \theta \) 로 표현이 되는데, 이 값은 사실 posterior의 risk, 혹은 conditional risk라고 알려진 \(R = \int L (\theta, \hat \theta(x)) p(\theta | x) d \theta \) 값을 minimize하는 것과 일치한다. Expected Loss, 혹은 Bayes risk를 전개해보면</p>


<p>\[R = \int \int L (\theta, \hat \theta(x)) p(\theta, x) dx d \theta &#92;&#92; = \int \int L (\theta, \hat \theta(x)) p(\theta | x) p(x) dx d \theta &#92;&#92; =  \int \left( \int L (\theta, \hat \theta(x)) p(\theta | x) d \theta \right) p(x)dx  \]</p>


<p>이때, \(\theta\)에 대한 적분 구간이 정확하게 conditional risk와 같으며, x에 대해 summation하는 것은 parameter에 영향을 주지 않으므로 둘이 동일함을 알 수 있다. 이렇게 구해진 expectation loss, Bayes risk (혹은 이와 같은 posterior risk, conditional risk) 를 minimization시키는 방법으로 \(\hat \theta\)를 estimate하는 estimator를 Bayes estimator라고 한다.</p>


<p>그러면 다양한 loss function들에 대해 이 Bayes risk와 Bayes estimator로 얻어지는 parameter를 계산해보자.</p>


<p>간단한 예로 zero-one loss의 expected loss를 구해보자. Zero-one loss는 아래와 같이 주어진다. 이 경우는 class를 구하는 것이므로 \(\theta\)가 아니라 \(C_k\)로 작성하였다.</p>


<p>\[L(C_k, \hat C_k(x)) = \begin{cases} 1 \text{ if } C_k = \hat C_k(x) &#92;&#92; 0 \text{ otherwise } \end{cases} \]</p>


<p>따라서 expectation loss 혹은 그와 동일한 conditional risk \(R = \sum_j L (C_j, \hat C_j(x) p(C_j | x) \) 는 (이 경우는 discrete하므로 integral이 아니라 summation이다.)</p>


<p>\[R = \sum_j L (C_j, \hat C_j(x) p(C_j | x) = \sum_{j \neq i} P(C_j | X) = 1-P(C_i|X) \]</p>


<p>와 같이 얻어지게 된다. 따라서 zero-one loss를 decision rule로 삼게 되면 아래와 같은 결과를 얻게 된다.</p>


<p>\[C_i = argmin R = argmin_{C_k} 1 - P(C_k|X) = argmax_{C_k} P(C_k|X) \]</p>


<p>즉, 0-1 loss를 사용하게 되면 Bayes estimator가 MAP (maximum a posterior)와 같아진다는 사실을 알 수 있다.</p>


<p>이번에는 다른 Loss function을 사용해서 bayes risk를 계산해보자. 만약 우리가 \(L (\theta, \hat \theta(x)) = (\theta - \hat \theta)^2 \) 이라 한다면 어떻게 될까. 먼저 conditional risk는 아래와 같다.</p>


<p>\[R = \int (\theta - \hat \theta)^2 p(\theta | x) d \theta p(x) \]</p>


<p>위의 식을 \(\hat \theta\)에 대해 미분해보면,</p>


<p>\[ \frac{\partial}{\partial \hat \theta} \left[ \int (\theta - \hat \theta)^2 ) p(\theta | x) d\theta \right] &#92;&#92; = \int \frac{\partial}{\partial \hat \theta} \left[ (\theta - \hat \theta)^2 ) p(\theta | x) d\theta \right] &#92;&#92; = -2 \int (\theta - \hat \theta) ) p(\theta | x) d\theta\]</p>


<p>이 derivation을 0으로 만드는 \(\hat \theta\)는 간단하게 \(\hat \theta = \int \theta p(\theta | x) d \theta = E[\theta|x]\)라는 결과를 얻게 된다. 즉, Bayes risk를 가장 minimize하는 \(\hat \theta\)는 주어진 데이터에 대한 parameter의 expectation인 \(E[\theta|x]\)라는 사실을 알 수 있다. 그리고 이를 다시 conditional risk에 대입을 해보면</p>


<p>\[R = \int (\theta - E[\theta|x]^2 p(\theta|x) d\theta = \sigma^2_{\theta|x}\]</p>


<p>즉, risk가 random variable의 variance와 정확히 같다는 것을 알 수 있다. 또한 따라서 Bayes risk가 절대로 0으로 수렴하지 않음도 알 수 있는데, 우리가 구한 결과에 따르면 이 값은 항상 \(\theta|x\)라는 random variable의 variance와 같기 때문에 이 값이 0이라는 얘기는 더 이상 \(\theta|x\)가 random variable이 아니라 deterministic하다는 의미가 되기 때문이다. 따라서 이 값은 항상 0이 아님을 알 수 있다.</p>


<h5>Inference and decision</h5>


<p>다시 Classification problem으로 돌아가보자. 이 classification은 크게 두 가지 step으로 나눌 수 가 있는데 하나가 inference stage이고, 또 하나가 decision stage이다. Inference stage에서는 training data를 사용하여 \(p(C_k|x)\)를 계산하기 위한 model을 learning한다. 그리고 그에 따르는 다음 step인 decision stage에서는 앞서 inference stage에서 계산한 posterior probability를 사용하여 실제 class assignment decision을 내리게 된다. 이런 과정 없이 단순하게 input x에 directly decision을 mapping하는 function을 생각할 수도 있는데, 이런 function은 discriminant function이라 한다.</p>


<p>이런 inference와 decision stage로 classification을 구분하는 approach를 취하게 되면 크게 두 가지 방법으로 decision problem을 접근하는 것이 가능해진다. <a href="http://en.wikipedia.org/wiki/Generative_model" target="new">Generative model</a>과 <a href="http://en.wikipedia.org/wiki/Discriminative_model" target="new">Discriminative model</a>이 바로 그것이다.</p>


<p>Generative model은 input에서부터 distribution을 직접적으로 혹은 간접적으로 얻어내고 output 역시 마찬가지 방법으로 얻어내게 된다. 조금 더 구체적으로 들어가보자. Generative model은 가장 먼저 inference problem, 정확히는 각각의 class 별로 가지게 되는 class conditional density \(p(x|C_k)\)를 결정하는 inference prblem을 풀게 된다. 또한 class prior probability \(p(C_k)\)도 infer를 하게 된다. 이 두 가지 정보를 사용하여 Bayes rule을 적용하여 posterior probability \(p(C_k|x)\)를 계산하게 된다.</p>


<p>\[ p(C_k|x) = {p(x|C_k) p(C_k) \over p(x)} \]</p>


<p>이때, \(p(x)\)는 단순히 normalize를 해주는 것으로 무시할 수 있다. (자세한건 <a href="58#58-1-Bayes" target="new">이전 글</a>에서 설명했으므로 생략.) 따라서 우리가 assume해야하는 값은 \(p(x|C_k)\), 그리고 \(p(C_k)\)인데, 결국 이 둘을 assume하는 것은 \(p(C_k, x)\)를 assume하는 것, 혹은 modeling하는 것과 같다. 즉, generative model은 joint probability를 modeling 하여 sample들을 해당 distribution으로 &#8216;generate&#8217; 한 결과를 사용하여 decision을 내리는 것이다.</p>


<p>이런 Generative model의 예로는 Gaussian Mixture Model (GMM), Hidden Markov Model (HMM), Naïve Bayes, Restricted Boltzmann Machine (RBM) 등이 존재한다.</p>


<p>이에 반해 Discriminative model 은 inference problem에서 posterior class probability \(p(C_k|x)\)를 직접 계산한다. 그리고 decision stage에서 이 posterior probability를 직접 사용하여 decision을 내리게 된다. 즉, 새로 들어온 input x에 대해 모든 class들의 posterior를 계산하여 가장 probability가 높은 class를 assign하는 방식으로 classification을 하게 된다. 위애서 길게 설명했던 Generative model과의 가장 큰 차이는 Generative model은 joint distribution \(p(x, C_k)\)를 계산하여 inference와 decision을 하는데에 반해 Discriminative model은 그것을 직접 계산하여 inference를 한다는 점이 다르다.</p>


<p>Discriminative model의 예는 Logistic regression, Linear discriminant analysis (LDA), Support Vector Machines (SVM), Boosting, Conditional Random Fields (CRF), Linear Regression, Neural Networks 등이 존재한다.</p>


<p>Generative model 과 Discriminative model의 차이점은 아래 그림에서 간단하게 정리되어있다. (<a href="http://sens.tistory.com/408" target="new">출처</a>)</p>


<p><img src="/images/post/61-1.jpg" width="600"></p>

<p>즉 데이터 x와 그 데이터들의 class y가 주어졌을 때, Classification을 위해서 필요한 값은 결국 \(p(y|x)\)로 같지만, generative model은 먼저 \(p(x|y), p(y)\)를 modeling하고 이 값들을 learning한 이후에 \(p(y|x) \propto p(x|y) p(y)\)를 통해 데이터 x의 class y의 확률을 계산하게 된다. 반면 discriminative model은 model 자체가 \(p(y|x)\)를 바로 learning하기 때문에 이 값을 바로 사용하면 된다. 따라서 discriminative model은 어떤 식으로 class가 분포해 있는지 사전 정보를 알 필요가 전혀 없지만, generative model을 사용하기 위해서는 이 값을 내가 미리 assume해야만 한다. 간단하게 생각하면 SVM은 대표적인 discriminative model 중 하나인데, SVM의 그 어떤 과정도 주어진 class들이 특정 형태로 분포해야한다는 가정이 전혀 들어있지 않다. 반면 generative model 중 하나인 GMM은 모든 cluster들이, 혹은 class들이 Gaussian의 mixture 형태로 주어진다고 가정하게 된다. 즉, 이 경우는 데이터와 class의 joint probability를 계산하게 되는 것이다.</p>


<p>정리해보면 Generative model은 joint distribution에서부터 sample을 &#8216;generative&#8217;하는 반면, Discriminative model은 주어진 데이터 x에 대해서만 model을 구하게 된다. 따라서 일반적으로 generative model이 훨씬 더 flexible한 결과를 보인다. 그러나 joint distribution을 직접 계산하는 것은 매우 computation cost가 높은, 즉 complexity가 높은 작업인 경우가 대다수인 반면, posterior probability를 계산하는 것은 상대적으로 더 저렴한 경우가 많다. 그 뿐 아니라, joint distribution을 modeling  하는 것도 대부분 쉽지 않다. 주어진 데이터들이 어떤 joint distribution으로 분포했는지는 modeling을 하지 않고서는 알 수 없기 때문이다. 반면 \(p(y|x)\)는 우리가 관측하는 likelihood 등을 사용하여 바로 계산하는 것이 가능하기 때문에 대부분의 discriminant model은 아무래도 조금 더 데이터가 sparse하게 존재하는 경우라거나, 전체 우리가 그 joint distribution에 대해 감조차 잡을 수 없는 경우에 해야하는 classification에 적합한 결과를 내놓는 경우가 많다고 한다.</p>


<h5>Decision process</h5>


<p>정리하자면, 최종적으로 decision을 내리기 위해서는 (1) Find parameter by minimizing risk (2) Decision by Model 이라는 과정을 거치게 된다. 먼저 minimize risk는 위에서 서술한 bayes risk를 minimization하는 부분으로, 이 부분에서 우리는 parameter들을 learning하게 된다. 이때 Loss function을 어떻게 정의하냐에 따라 parameter의 값이 결정되게 되며, 나중에 다루겠지만, 단순히 loss function을 정의하는 것으로 끝나는 것이 아니라, 이 optimization 문제를 polynomial algorithm을 통해 계산해내어야한다. 실제로 많은 algorithm들이 global optimum으로 수렴하지 않고 local optimum만을 찾아주는 경우가 많다. 이렇게 parameter를 learning한 이후에는 parameter를 사용해 posterior를 계산하게 된다. 이때 Model에 따라 inference를 하는 방법이 달라지게 되는데 discriminative model은 parameter를 사용해 directly하게 posterior를 계산하게 되고, generative model은 joint distribution을 learning하여 posterior를 indirectly하게 유추하게 된다.</p>




<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li>Convex Optimzation</li>
<li>Classification Introduction (Decision Tree, Naïve Bayes, KNN)</li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Graphical Model</li>
<li>Hidden Markov Model</li>
<li>Clustering (K-means, Gaussian Mixture Model)</li>
<li>EM algorithm</li>
<li>Feature Extraction</li>
<li>Matrix Completion</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>And others.. (Reinforcement Learning, Boosting, Model Selection)</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/60/">Machine Learning 스터디 (4) Algorithm</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-08-10T21:17:00+09:00" pubdate data-updated="true">Aug 10<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>내가 많은 책이나 lecture를 들어본 것은 아니지만, 보통 일반적인 Machine Learning과 관련된 책이나 강의 등에서 Algorithm을 따로 다루거나 하는 경우는 본 적이 없기는 하다. 그럼에도 불구하고 알고리듬을 중요하게 다루고자 하는 이유는, 결국 Machine Learning에 대해 다루기 위해서는 알고리듬이라는 것에 대해 이해가 필요하고, 어떤 알고리듬이 좋은 것이고 어떤 알고리듬이 나쁜 것인지에 대한 구분이 이뤄져야지만 향후 논의하게 될 많은 주제들에 대해 얘기하기 쉬워질 것이라고 생각해서이다.</p>


<p><a href="57" target="new">이전 글</a>에서 머신러닝에서 알고리듬이란 어떤 의미가 있는지를 얘기했었다. 쉽게 생각하면, 우리가 원하는 형태로 모델을 정의한 이후에 그 모델을 어떻게 learning할 것인가, 즉, 어떤 알고리듬을 사용하여 model을 learning할 것인가에 대한 얘기를 하기 위해서는 알고리듬에 대해 반드시 짚고 넘어가야만 한다. 사실 내 생각에 대부분의 머신러닝 렉쳐나 교재에서 알고리듬에 대해 깊게 다루지 않는 이유는 알고리듬이 전산학에서 매우 기초적인 학문이기 때문이기 때문에 당연히 알고 있을 것이라고 가정하기 때문이 아닐까하지만.. 그래도 아무튼 알고리듬 부분에서 반드시 짚고 넘어가야할 부분은 (1) Big O notation (2) P and NP (3) Reduction (4) NP Complete (5) Approximation Algorithm 정도가 아닐까한다.</p>


<h5 id="60-1-bigO">Algorithm, Big O notation</h5>


<p>먼저 algorithm이란 무엇인지에 대해 생각해보자. 알고리듬이란 것의 정확한 정의는 <a href="http://en.wikipedia.org/wiki/Algorithm" target="new">위키</a>를 참고하면 되고, 알고리듬에 있어서 중요한 몇 가지를 꼽자면, 먼저 input이 정의가 되어야하며 output을 가져야한다. 즉, 알고리듬은 특정 데이터에 대해 동작해야하며, 해당 데이터에 대한 알고리듬의 결과를 출력해야만한다. 그리고 알고리듬은 반드시 어떤 &#8216;목적&#8217;을 가지고 있다. 즉, 내가 만약 특정 지점부터 다른 특정 지점으로 이동하는 가장 짧은 path를 찾는 알고리듬을 작성해야만한다면 해당 알고리듬의 목적은 shortest path를 찾는 것이고, input은 임의의 graph와 시작점, 그리고 끝점이 될 것이다. 마지막으로 출력값은 shortest path가 될 것이다. 이런 것을 행할 수 있는 일종의 procedure가 알고리듬이라고 할 수 있다. 하지만 우리는 그냥 임의의 알고리듬이 필요한 것이 아니라 &#8216;좋은&#8217; 알고리듬이 필요하다. 예를 들어서 Algorithm A는 shortest path를 찾는데 1시간이 걸리고, Algorithm B는 4초가 걸린다면 당연히 B를 사용해야할 것이다. 그렇다면 알고리듬의 좋다 혹은 나쁘다는 무엇으로 구분하느냐, <a href="http://en.wikipedia.org/wiki/Big_O_notation" target="new">Big O notation</a>의 역할이 바로 그것을 구분하는 역할을 하는 것인데, 이 notation은 해당하는 알고리듬이 &#8216;주어진 input의 크기에 대해&#8217; 계산량이 얼마나 필요하느냐를 indicate하는 notation이다. 표기는 O(n) 와 같은 꼴로 표시하게 된다. n은 input의 크기이다. 예를 들어 shortest path면 전체 graph의 node의 개수가 될 것이다. O notation은 일종의 upper limit로, 아무리 최악의 상황에서도 계산량이 O 안에 있는 양보다 적게 걸린다는 의미이다. 또한 만약 소요 시간이 2n 이거나 n+1 이거나 10000000000000000n 이어도 이 알고리듬들은 모두 O(n)이 된다. 이 정도 얘기는 조금만 구글링해도 많이 나오는 얘기니 여기까지만 적고, 진짜 중요한건 &#8216;polynomial time&#8217;일 것이다. 무슨 얘기이냐하면, 알고리듬의 실행시간이 input의 크기가 늘어나는 것에 대해 polynomial scale로 증가하는 알고리듬이 좋은 알고리듬이라는 뜻이다. 당연히 input에 대해 최대한 적게 증가하는 알고리듬이 좋기는 하지만, \( O(e^n) \) 보다는 \( O(n^4) \) 이 훨씬 더 좋다는 얘기이다. Exponential time이 소요되는 알고리듬은 사실상 거의 무한대의 시간이 걸린다고 봐도 될 정도로 절망적인 computation time을 의미하며, 제대로 활용 가능한 알고리듬이 되려면 그 알고리듬의 computation time은 반드시 polynomial time이어야한다.</p>


<p>Expotentially increase라는 말에는 정말 어마어마한 파괴력이 있다. 이것이 왜 절망적이냐하면, 우리가 linear한 10n 알고리듬을 가지고 있을 때 input의 size가 1, 2, 3 의 순으로 증가하더라도 여전히 computation time은 10, 20, 30이지만, exponential time이 필요한 경우에는 예를 들어 10^n이라고 한다면 10, 100, 1000만큼의 시간이 필요하다. 즉 input이 3배 증가했을 뿐인데 두 알고리듬은 1000/30 = 33.33 배 만큼의 성능차이가 나는 것이다. 만약 input size가 100이라면? \(10^{97}\) 만큼의 차이가 난다. Exponential이라는 것에는 이만큼의 파괴력이 있다. 그러나 polynomial time안에 풀 수 있다면, 100배가 증가했을 때, n과 \(n^2\)의 차이는 100에 불과하다. 이 때문에 polynomial time algorithm은 풀 수 있는 문제로 취급되고, exponential algorithm은 실제로 쓸 수 없는 알고리듬으로 취급받는 것이다. <a href="/59#59-3-ms">이전 글의 model selection part</a>에서 &#8216;그리고 데이터가 많아지면 그런 validation set이 엄청나게 많아진다. 정확히는 exponential로 늘어나기 때문에 마냥 모든 데이터에 대해 cross-validation을 하는 것은 불가능하다.&#8217; 라는 표현을 했을 때 exponential 로 증가하는 validation이 불가능하다는 표현을 했던 것이다.</p>


<h5 id="60-2-np">P and NP</h5>


<p>P problem이란 해당하는 문제를 polynomial time안에 풀 수 있는 알고리듬을 제시할 수 있는 문제를 의미한다. 예를 들어 우리에게 주어진 데이터의 개수를 sorting하는 알고리듬은 \(n log n\) 의 시간이 필요하므로 P problem이라 할 수 있다. NP problem은 올바르지는 않지만 진짜 진짜 간단하게, 표현하면, &#8216;polynomial time안에 풀 수 없는 엄청나게 어려운 문제&#8217; 라고 할 수 있다. 하지만 이것은 올바르지 않은 정의이며, 심지어 정말 polynomial time안에 풀 수 없는지 조차 아직 확실하지 않다. NP problem의 정확한 정의는 &#8216;problem이 주어지고 해당 problem에 대해 어떤 suggested solution이 주어졌을 때 polynomial time안에 그 solution이 맞는 solution인지 아닌지 구분할 수 있는 문제&#8217;라고 할 수 있다. 당연히 정확한 답을 polynomial time안에 풀 수 있는 P는 NP의 subset이다. 즉, NP는 P를 포함하는 set이라고 할 수 있다. 그렇다면 NP는 반드시 P보다 크다고 할 수 있을까? 이 문제를 얘기하려면 먼저 Reduction에 대해 다뤄야한다.</p>


<h5 id="60-3-red">Reduction</h5>


<p>Problem X에서 Y로의 Reduction이란 만약 우리가 Problem Y를 풀 수 있는 Algorithm을 가지고 있을 때, 이 algorithm을 사용해 problem X를 풀 수 있는 algorithm을 찾을 수 있다는 것을 의미한다. 즉, 우리가 problem X를 풀기위해서는 problem Y를 풀기만 하면 된다. 즉, 간단히 생각하면 문제 Y가 X보다는 더 어려운 문제라고 생각하면 된다. 만약 우리가 problem Y 를 풀기위한 algorithm 중에서 P인 algorithm을 가지고 있다면, 그리고 reduction을 polynomial time안에 할 수 있다면 우리는 반드시 problem X를 polynomial time안에 풀 수 있을 것이다.</p>


<h5 id="60-4-npc">NP Complete</h5>


<p>NP Complete problem은 모든 NP problem이 해당 problem으로 reduction될 수 있는 문제를 의미한다. 즉, 내가 그 어떤 NP problem을 제시하더라도 반드시 어떤 NP complete problem으로 reduction시키는 것이 가능하다. 그리고 <a href="http://en.wikipedia.org/wiki/Cook%E2%80%93Levin_theorem" target="new">Cook-Levin Theorem</a>에서 Boolean SAT problem이 NP problem이라는 것을 증명한다. 그렇다면 당연히 SAT problem을 통해서 다른 NP complete problem들을 찾을 수 있다. 우리가 많이 사용하는 NP complete problem들은 <a href="http://en.wikipedia.org/wiki/Independent_set_problem" target="new">Independent set problem</a>, <a href="http://en.wikipedia.org/wiki/Clique_problem" target="new">Clique problem</a>, <a href="http://en.wikipedia.org/wiki/Vertex_cover_problem" target="new">Vertex Cover problem</a>, <a href="http://en.wikipedia.org/wiki/Set_cover" target="new">Set Cover problem</a>, <a href="http://en.wikipedia.org/wiki/Subset_sum_problem" target="new">Subset Sum problem</a> <a href="http://en.wikipedia.org/wiki/Hamiltonian_path_problem" target="new">Hamiltonian path problem</a>, <a href="http://en.wikipedia.org/wiki/Travelling_salesman_problem" target="new">Travelling salesman problem</a>, <a href="http://en.wikipedia.org/wiki/Graph_coloring_problem" target="new">Graph Coloring problem</a> 등이 있다. 해당 문제들의 전체 목록은 <a href="http://en.wikipedia.org/wiki/NP-complete#NP-complete_problems" target="new">위키</a>에서도 볼 수 있다.</p>


<p>그렇다면 당연히 필연적으로 할 수 있는 질문은, &#8216;NP complete problem을 polynomial time안에 풀 수 있는가?&#8217; 라는 질문이 되겠다. 당연히 위에 서술한 그 어떤 문제 중에서 단 하나라도 polynomial solution을 제시할 수 있다면 모든 NP 문제들을 P로 풀 수 있을 것이다. 이 질문이 그 유명한 <a href="http://en.wikipedia.org/wiki/P_versus_NP_problem" target="new">P=NP?</a> 문제가 되겠다. 그리고 또 안타깝게도 이 문제는 <a href="http://en.wikipedia.org/wiki/Millennium_Prize_Problems" target="new">Millennium Prize Problems</a>라고 해서 엄청나게 어려운, 상금이 걸려있는 문제 중 하나이다. 즉, 아직도 결론이 나지 않은 문제이다. 하지만 그럼에도 대부분의 사람들이 NP complete는 polynomial time안에 풀 수 없다고 생각하고 있으며, 그 때문에 현재 우리가 사용 중인 모든 보안 알고리듬들은 이 NP completeness에 기반하여 만들어져있다. (정확히는 숫자를 곱하는 것은 쉬우나, 주어진 숫자가 소수인지아닌지 구분하는 것은 NP hard problem이라는 특성을 사용한다. - NP hard는 NP complete만큼 어렵거나 그보다 더 어려운 문제를 의미.) 따라서 일단 해당 문제를 reduction했더니 NP complete problem이 튀어나온다면 그 문제는 polynomial안에 답을 낼 수 없는 문제가 되겠다.</p>


<h5 id="60-4-aa">Approximation Algorithm</h5>


<p>그렇다고 이 문제는 NPC problem이니까 풀지말자! 라고 넘기기에는 세상에 너무나 많은 문제들이 NP complete problem이다. 그래서 정확하지는 않지만 NP complete problem을 풀기위한 여러가지 방법들이 존재한다. (<a href="http://en.wikipedia.org/wiki/NP-complete#Solving_NP-complete_problems" target="new">위키</a> 참고) 그 중에서도 approximation algorithm은 정확한 답을 구하는 것이 아니라 approximated solution을 polynomial안에 얻어내는 알고리듬을 의미한다. 즉, 원래 알고리듬이 x라는 답을 줬을 때, \(\alpha\)-approximation algorithm은 \(\alpha\)x 라는 답을 주게 된다. 자세한 점은 <a href="http://en.wikipedia.org/wiki/Approximation_algorithm" target="new">위키</a> 참고. 즉, NPC problem이 절망적으로 어려운 문제인 것은 맞지만 마냥 절망만 하고 있을 필요는 없다는 의미이며, approximation 말고도 NPC를 해결하는 방법은 여러 방법들이 존재한다. 하지만 일단 가장 중요한 개념 중 하나라고 할 수 있다.</p>


<p>수 많은 경우, Machine Learning 문제를 해결하다보면, 해당 문제가 NP complete problem인 경우가 많이 존재한다. 따라서 절대적인 값을 구하는 것이 불가능하여 어쩔 수 없이 local optimum을 구하는 경우도 있고, 혹은 해당 문제를 정확히 일치하지는 않지만 polynomial time안에 구할 수 있는 문제로 바꾸어 문제를 해결하는 방법도 존재한다. 즉, Machine learning에 대해 공부하기 위해서는 algorithm에 대한 이해가 매우매우 필수적이라고 할 수 있을 것이다.</p>




<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li>Convex Optimzation</li>
<li>Classification Introduction (Decision Tree, Naïve Bayes, KNN)</li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Graphical Model</li>
<li>Hidden Markov Model</li>
<li>Clustering (K-means, Gaussian Mixture Model)</li>
<li>EM algorithm</li>
<li>Feature Extraction</li>
<li>Matrix Completion</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>And others.. (Reinforcement Learning, Boosting, Model Selection)</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/59/">Machine Learning 스터디 (3) Overfitting</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-08-03T16:33:00+09:00" pubdate data-updated="true">Aug 3<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Machine Learning Algorithm을 design하고 실제 구현을 하다보면 Overfitting이라는 문제가 꽤나 머리를 아프게 하는 경우가 많다. 아니, Algorithm 자체가 문제 없이 실행이 된다면 대부분의 경우 overfitting이 가장 큰 문제라고 단언해도 좋을 것 같다. 물론 좋은 Algorithm을 design하고 못하고의 문제는 또 다른 문제이기는 하다. 다음 글은 Algorithm에 대해서 써볼까.. 아무튼 이번 글에서는 Overfitting에 대해 좀 다뤄보도록 하겠다.</p>


<h5 id="59-1-overfitting">Overfitting</h5>


<p>overfitting이란 문자 그대로 너무 과도하게 데이터에 대해 모델을 learning을 한 경우를 의미한다. 지금 현재에 대해 잘 설명하면 되는 것 아닌가? 싶을 수 있지만, 우리가 사실 원하는 정보는 기존에 알고 있는 데이터에 대한 것들이 아니라 새롭게 우리가 알게되는 데이터에 대한 것들을 알고 싶은 것인데, 정작 새로운 데이터에 대해서는 하나도 못맞추고, 즉 제대로 설명할 수 없는 경우라면 그 시스템은 그야말로 무용지물이라고 할 수 있을 것이다. 조금 더 자세한 설명은 <a href="/14#Overfitting" target="new">이전에 적은 포스트</a>로 대체하겠다.</p>


<h5 id="59-2-reg">Regularization</h5>


<p>이런 문제를 해결하기위해 여러가지 시도를 할 수 있다. 먼저 Overfitting이 일어나는 이유는 무엇인가에 대해서 한 번 생각해보자. 먼저 overfitting의 가장 간단한 예시를 하나 생각해보자.</p>


<p><img src="/images/post/59-1.png" width="500"></p>

<p>위 그림에서도 알 수 있 듯, 만약 우리가 주어진 데이터에 비해서 높은 complexity를 가지는 model을 learning하게 된다면 overfitting이 일어날 확률이 높다. 그렇다면 한 가지 가설을 세울 수 있는데, &#8216;complexity가 높을 수록 별로 좋은 모델이 아니다.&#8217; 라는 가설이다. 이는 <a href="http://en.wikipedia.org/wiki/Occam%27s_razor" target="new">Occam&#8217;s razor</a>, 오컴의 면도날이라 하여 문제의 solution은 간단하면 간단할수록 좋다라는 가설과 일맥상통하는 내용이다. 하지만 그렇다고해서 너무 complexity가 낮은 model을 사용한다면 역시 부정확한 결과를 얻게 될 것은 거의 자명해보인다. 그렇기 때문에 우리는 원래 cost function에 complexity와 관련된 penalty term을 추가하여, 어느 정도 &#8216;적당한&#8217; complexity를 찾을 수 있다. 이를 regularization이라 한다. 이 이외에도 다양한 설명이 있을 수 있기에 <a href="http://en.wikipedia.org/wiki/Regularization_(mathematics)" target="new">위키 링크</a>를 첨부한다.</p>


<p>그리고 이를 Bayesian 관점에서 설명을 할 수도 있다.</p>


<p>\[ p(Y|X) = {p(X|Y) p(Y) \over p(X)} \]</p>


<p><a href="58#58-1-Bayes" target="new">이전 글</a>에서도 설명했던 것 처럼, 만약 우리가 어떤 사전지식, 혹은 prior knowledge가 존재한다면 단순히 observation만 하는 것 보다는 훨씬 더 잘 할 수 있을 것이다. 그리고 다시 Overfitting 문제로 돌아와서, overfitting이 생기는 가장 큰 이유는 너무 지금 데이터, 즉 observation에만 충실했던 것이 그 원인이다. 그러면 당연히 prior가 있으면 이를 해결할 수 있지 않을까? 라는 질문을 던질 수 있을 것이다. 즉, 우리의 prior는 high complexity solution은 나오지 않을 것이다. 어느정도 complexity가 높아지는 것 까지는 용인하지만, (표현할 수 있는 영역이 더 넓어지니까) 하지만 너무 그 complexity가 높아지면 문제가 생길 수 있다. 즉, 그런 high complexity를 가지는 solution이 나올 확률 자체가 매우 낮다. 라는 prior가 있다면 이를 간단하게 해결 할 수 있을 것이며, 이것이 결국 앞에서 봤었던 penalty와 동일하다는 것을 알 수 있다.</p>


<h5 id="59-3-ms">Model Selection</h5>


<p>그런데 제 아무리 우리가 좋은 prior를 넣고, 좋은 penalty term을 design하더라도 만약 우리가 제대로 되지 않은 데이터들을 이용해 learning을 한다면 문제가 생길 수 있다. 마치 장님 코끼리 만지듯 전체 데이터는 엄청나게 많이 분포해있는데 우리가 가진 데이터가 아주 일부분에 대한 정보라면, 혹은 갑자기 그 상황에서 갑자기 노이즈가 팍 튀어서 데이터가 통채로 잘못 들어온다면? 아마 그런 데이터로 learning을 했다가는 sample bias가 일어나게 되어 크게 성능이 저하되게 될 것이다. 사실 위에 complexity라는 말도 결국에는 &#8216;Data point 대비 높은 complexity&#8217;가 더 정확한 말이다. 이를 최대한 피하기 위하여 우리는 <a href="http://en.wikipedia.org/wiki/Generalization" target="new">generalization</a> 이라는걸 하게 되는데, 다시 말해서 우리의 solution이 specific한 결과만을 주는 것이 아니라 general한 결과를 주도록 하려는 것이다. 이를 위한 여러 방법이 있을 수 있지만, 가장 많이 사용하는 방법은 validation set이라는 것을 사용하는 것이다. 즉, 모든 data를 전부 training에 사용하는 것이 아니라, 일부만 training에 사용하고 나머지를 일종의 validation을 하는 용도로 확인하는 것이다. 만약 우리의 모델이 꽤 괜찮은 모델이고, validation set이 잘 선택이 되었다면 training set에서만큼 validation set에서도 좋은 결과가 나올 수 있을 것이다.</p>


<p>보통 전체 데이터 중에서 training과 validation의 비율은 8:2로 하는 것이 일반적이다. 하지만 만약 validation set이 너무 작다면, 이 마저도 좋은 결과를 내기에는 부족할 수 있다. 이를 해결할 수 있는 컨셉 중에서 cross-validation이라는 컨셉이 있는데, validation set을 하나만 가지는 것이 아니라 여러개의 validation set을 정해놓고 각각의 set에 대해서 learning을 하는 것이다. 예를 들어 우리가 데이터가 X={1,2,3,4,5,6,7,8,9,10} 이 있을 때, 첫 번째 learning에서는 {1,..,8}을 사용해 learning하고 그 다음에는 {2,..,9}까지 learning하는 식으로 모든 permutation에 대해서 learning을 할 수 있을 것이다. 그리고 당연히 이런 방식으로 여러번 learning을 하게되면 그 때 얻어지는 model parameter는 그때그때 달라질텐데, cross-validation은 그 값들을 적당히 사용하여 가장 적절한 parameter를 얻어내는 방식이다. average로 해도 되고, median으로 해도 되고, 여러 방법이 있을 수 있다. cross-validation의 단점은 algorithm의 running time이 데이터의 크기 뿐 아니라 validation을 하기 위한 그 여러 set들에 dependent하다는 것이다. 그리고 데이터가 많아지면 그런 validation set이 엄청나게 많아진다. 정확히는 exponential로 늘어나기 때문에 마냥 모든 데이터에 대해 cross-validation을 하는 것은 불가능하다.</p>


<p>그렇기 때문에 실제로 cross-validation을 할때는 모든 데이터를 사용하지는 않고, 적당히 몇 개의 set을 골라서 여러 번 model parameter를 &#8216;적당히&#8217; 구하는 방법을 사용한다. 물론 이론적으로 AIC, BIC 등의 개념이 존재하여 이에 맞춰서 모델을 고르는 방법도 존재하지만 (AIC는 Akaike Information Criterion이고 BIC는 Bayesian Information Criterion으로, 둘 다 어떤 &#8216;information criteria&#8217;를 사용하느냐에 대한 내용이다.) 지금 내가 다루고자 하는 내용에서 좀 벗어나기 때문에 나중에 여유가 되면 이에 대한 글을 작성해보도록하겠다.</p>


<h5 id="59-4-cd">Curse of dimension</h5>


<p>그러나 이게 끝이 아니다. 우리가 싸워 이겨내야할 문제들은 complexity, number of data 뿐 아니라 dimension of data 역시 존재한다. 즉, 우리가 1차원의 데이터를 다루는 것과 10000차원의 데이터를 다루는 것과는 정말 어마어마한 차이가 존재한다는 것이다. 이렇게 차원이 높은 데이터를 다룰 일이 있을까? 하고 약간 막연하게 생각할 수 있지만, 가장 간단한 예로, 100px by 100px 그림은 각각의 픽셀이 하나의 차원이라고 했을 때 10000차원 벡터로 표현이 가능하다. 실제로 머신러닝 분야에서 이미지를 다룰 때는 이런 식으로 처리를 하게 된다. 이 이외에도 high dimensioanl space 상에 존재하는 데이터를 다룰 일은 매우 많이 존재한다.</p>


<p>그렇다면 이런 high dimensional data가 왜 우리가 learning한 system의 성능을 나쁘게 만들까? 정말 간단하게 생각해보자. 만약 우리가 주어진 공간을 regular cell로 나눴다고 가정해보자. 그리고 각각의 cell에 가장 많이 존재하는 class를 그 cell의 class로 생각하여 무조건 그 cell에 존재하는 데이터는 그 class라고 하는 logic을 생각해보자. 당연히 cell의 개수를 무한하게 가져가게 된다면, 그리고 데이터가 무한하다면 이 logic은 반드시 truth로 수렴하게 될 것이다. 이 알고리듬이 제대로 동작하려면 각각의 cell, 혹은 bin이 반드시 차있어야한다. 즉, 비어있는 empty cell이 존재해서는 안된다. 따라서 데이터는 아무리 적어도 cell의 개수만큼은 존재해야한다. 그런데 이렇게 cell을 만들게 될 경우 그 cell의 개수는 dimension이 증가함에 따라 exponential하게 늘어나게 되는 것이다. 예를 들어 우리가 1차원상에서 3개의 bin을 가지고 있다고 하면, 이는 2차원상에서는 9개, 3차원상에서는 27개.. 이렇게 exponentially grow하게 되는 것을 알 수 있다. 이 모델의 parameter들이 exponentially 증가하는 것이다. (아래 슬라이드(<a href="http://cssanalytics.wordpress.com/2013/10/06/random-subspace-optimization-rso/" target="new">출처</a>) 참고)</p>


<p><img src="/images/post/59-2.png" width="600"></p>

<p>따라서 당연히 각각의 bin이 비어있지 않도록 ensure해줄 수 있는 data의 개수 역시 exponentially 하게 늘어나게 되고, 즉 차원이 증가하게 되면 필요한 데이터가 exponentailly하게 늘어나게 된다는 것을 의미한다. 그러나 당연히 우리가 3차원 데이터보다 100000차원 데이터를 exponential하게 더 많이 가지고 있으리라는 법은 없고, 이로 인해 문제가 발생하게 되는 것이다.</p>


<p></p>

<p>그리고 또 문제가 되는 것은 high dimensional space에서 정의되는 metric들로, 특히 2-norm 혹은 euclidean distance의 경우는 그 왜곡이 매우 심하여, 실제 멀리 떨어진 데이터보다 별로 멀리 떨어져있지 않고 각 dimension의 방향으로 약간의 noise가 섞여있는 데이터에 더 큰 distance를 부여하는 등의 문제가 존재한다.</p>


<p>조금 다른 예를 들어보자. 만약 D-dimensional space에서 엄청나게 얇은 구각을 만들었다고 생각해보자. 여기에서 &#8216;구&#8217; 라는 것은 한 점에 대해 거리가 동일하게 떨어져있는 모든 점 내부의 영역을 의미한다는 것은 당연한 것이고.. 이 구의 부피는 \(V_D(r)=K_D r^D\) 가 될 것이며, \(K_D\)는 그냥 D에 대한 상수라고 생각하면 된다. 그럼 반지름이 1이고 두께가 \(\epsilon\)인 구각의 부피와 반지름이 1인 구의 부피의 비율은 \({V_D(1) - V_D(1-\epsilon) \over V_D(1)} = 1-(1-\epsilon)^D\) 가 될 것이다. 놀랍게도, 만약 very very high dimension D에서는 이 값이 1로 수렴하게 된다. 즉, 매우 얇은 구각의 부피가 구의 부피와 같다는 의미. 혹은 대부분의 부피가 거의 surface에 가까운 엄청나게 얇은 그 shell에 존재한다는 희한하고 요상한 의미가 된다.</p>


<p>즉, high dimension은 (1) model의 complexity도 증가시키며 (2) 필요한 데이터의 양도 exponentially 하게 늘어나게 하고 (3) 우리가 기존에 사용하던 metric이 제대로 동작하지 않는 그야말로 끔찍한 환경이라 할 수 있다. 그래서 이런 high dimensional space에서 일어나는 여러 문제점들을 통틀어 Curse of dimension이라 한다.</p>


<p>이를 해결하기 위해서는 결국 feature extraction 등의 기술을 사용하여 dimension을 가장 적절하게 낮추는 것이 바람직하다고 할 수 있다.</p>


<h5 id="59-5-bvt">Bias-variance Trade-off</h5>


<p>    <a href="http://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" target="new">Bais-variance trade-off</a>   </p>


<h5 id="59-6-robust">Overfitting and Robustness</h5>


<p>마지막으로 Robustness라는 개념에 다루고 글을 마치도록 하겠다. 지금까지 overfitting에 대한 설명을 읽어보면 알 수 있듯, overfitting이라는 것은 </p>




<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li>Convex Optimzation</li>
<li>Classification Introduction (Decision Tree, Naïve Bayes, KNN)</li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Graphical Model</li>
<li>Hidden Markov Model</li>
<li>Clustering (K-means, Gaussian Mixture Model)</li>
<li>EM algorithm</li>
<li>Feature Extraction</li>
<li>Matrix Completion</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>And others.. (Reinforcement Learning, Boosting, Model Selection)</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/58/">Machine Learning 스터디 (2) Probability Theory</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-08-03T14:18:00+09:00" pubdate data-updated="true">Aug 3<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>지난 글에서 Machine Learning을 일종의 function 처럼 묘사했었는데, 사실 Machine Learning을 Probability density의 관점에서 보는 것도 가능하다. 이 얘기를 하려면 먼저 Probability density를 포함한 전반적인 probability theory에 대해 먼저 다뤄야할 것 같아서 그 주제로 먼저 글을 써보기로 했다. 일단 엄청 기본적인 내용들, 예를 들어서 조건부 확률이 무엇이고, 이런 얘기들은 일단 생략을 하도록 하겠다. 너무 basic한 얘기이고 \(p(X) = \sum_Y p(X,y) \) 이런거나 \(p(X,Y) = p(Y|X) p(X) \) 이런건 너무나도 기초적인 얘기들이니까. 만약 조건부확률을 잘 모른다면 구글링을 통해 먼저 간단한 지식을 습득하고 오기를 권한다.</p>


<p>다만 그 중에서도 약간 중요하게 다룰만한 주제가 있는데, 그게 바로 Bayes&#8217; theorem이다. 이 Theorem 자체는 그냥 간단하게 \(p(X|Y) \)와 \(p(Y|X) \)와의 관계를 표현한 것임에 불과하지만, 그 안에 숨겨진 의미가 매우매우 중요하다.</p>


<h5 id="58-1-Bayes">Bayes&#8217; Theorem</h5>


<p>\[ p(Y|X) = {p(X|Y) p(Y) \over p(X)} \]</p>


<p>식의 모양은 위와 같다. 이 식이 중요한 이유는 무엇이냐면, 실제 우리가 관측하는 데이터와 실제 일어나는 현상과의 관계를 이어주는 연결고리가 되기 때문이다.</p>


<p>우리가 실제로 관측할 수 있는 데이터와 현상의 관계는 어떻게 되느냐 하면 &#8216;이런 현상이 나타났을 때 데이터의 분포&#8217; 를 보는 것이다. 무슨 얘기냐, 만약 데이터를 X, 현상을 Y라고 해보자. 그럼 우리가 당연히 얻고 싶은 것은 주어진 데이터 X에 대한 현상 Y일 것이다. 즉 \( p(Y|X) \) 를 우리는 실제로 계산하고 싶은 것이다. 그런데 우리가 확인할 수 있는 데이터는 무엇이냐 하면, 어떤 주어진 현상 Y에 대해 존재하는 데이터 X들의 분포 즉, \( p(X|Y) \) 만을 관측할 수 있다. 예를 들어보자. 만약 어떤 질병에 대한 검사를 하는 상황이라고 가정해보자. 우리가 확인할 수 있는 것은 해당 검사에 대해 양성 판정을 받았는지 아닌지 밖에 확인할 수 없다. 만약 이 검사가 완벽하지 않다면 (즉, 정확도가 90% 정도라면) 실제 우리가 관측하는 검사 결과와 그 사람의 질병 보유 상황이 다를 수 있는 것이다. 즉, 검사 결과를 X라고 하고 실제 병에 걸렸는지 아닌지를 Y라고 한다면 우리가 최종적으로 확인하고 싶은 것은 \( p(Y|X) \), 즉 검사 결과를 보고 이 사람이 진짜 질병을 가질 확률을 알고 싶은 것이지만, 실제 우리가 확인할 수 있는 데이터는 \( p(X|Y) \), 즉 이 사람이 실제 병에 걸렸을 때 제대로 검사가 될 확률 (아까 90%라고 했었던) 뿐이 가지고 있지 않다. 더 자세한 것은 <a href="http://musicetc.wikidot.com/bayes-theorem#toc3" target="new">링크</a>를 참조하길 바란다.</p>


<p>중요한 것은 무엇이냐 하면, 진짜 우리가 관측할 수 있는 데이터만 가지고는 우리가 원하는 추론을 하는 것이 어렵다는 점이다. 이때, 주어진 현상에 대해 나타나는 데이터의 분포 \( p(X|Y) \), 즉 우리의 observation을 일컬어 Likelihood라고 한다. 만약 우리가 아무런 정보도 가지고 있는 상황이 아니라면 언제나 이 값을 최대로 만드는 작업을 통해 가장 optimized된 현상을 찾을 수 있는데 이를 maximum likelihood라 한다. (<a href="http://en.wikipedia.org/wiki/Maximum_likelihood" target="new">위키</a>) 즉, 우리가 관측한 정보만을 가지고, 그 정보가 전부라고 가정한 이후에 그 안에서 모든 optimization을 거쳐 가장 좋은 something을 얻어내는 과정이라 할 수 있다. 이를 Maximum Likelihood Estimation 혹은 MLE라 한다. 이 녀석은 Machine learning을 하면서 정말 많이 나오는 용어이고, 실제 이 방법을 사용해 풀어내는 문제들이 많기 때문에 반드시 숙지해야하는 개념이다. (또한 이 녀석이 좋은 이유는 간단함도 있지만, unbiased solution을 얻을 수 있다는 점인데, 이 부분은 나중에 설명할 수 있도록 하겠다.)</p>


<p>그런데, 앞서 설명했던 예시와 같이, 항상 MLE가 능사는 아니다. 극단적으로 생각해서, 만약 우리가 동전 던지기를 해서 10번 던져서 10번 tail이 나오면 &#8216;이 동전은 tail이 100%로 나오는 동전이다&#8217; 라고 예측하는 것이 바로 MLE인 것이다. 이 방법이 잘 될 떄도 많지만, 방금처럼 데이터가 부족한 경우 등에는 좋은 결과를 얻지 못할 수 있다. 만약 우리가 &#8216;동전 던지기를 하면 head, tail이 50:50 으로 나온다.&#8217; 라는 것을 알고 있다면 조금 더 나은 추론을 하는 것이 가능하지 않을까? 이런 생각에서 나오는 것이 바로 Maximize a posterior, 혹은 MAP이다. Posterior는 앞에서 설명했던 주어진 데이터에 대한 현상의 확률, 즉 \( p(Y|X) \)이다. 간단히 생각해서 Likelihood는 내가 본 데이터에 대한 관측값 만을 의미하는 것이고, Posterior는 관측값과 다른 결과들을 조합하여 나온 조금 더 추론하기에 알맞은 형태? 라고 보면 될 것 같다.</p>


<p>앞서 Bayes&#8217; theorem에서 계산했듯, Observation, 혹은 Likelihood를 알고 있을 때 Posterior를 계산하기 위해서는 \(p(X), p(Y)\)가 필요하다. 이때 \(p(Y)\)는 어떤 현상에 대한 사전 정보이다. 즉, 아까 동전 던지기에서 동전을 던졌을 때 head tail이 나올 확률이 0.5라는 것에 대한 사전 정보이다. 이를 prior 라고 한다. 만약 이 값을 알고 있다면 observation이 잘못되어도 이 값이 약간의 보정을 해주는 역할을 할 수 있게 되는 것이다. 그리고 여기에서 데이터의 분포 \(p(X)\)는 일종의 normalization 을 해주는 역할을 하며, 실제 모든 데이터에 대해 \(p(X|Y) p(X)\) 를 계산한 뒤 그 값들을 noralization하는 것과 동일한 효과이기 때문에 이 값에 대해 알 필요는 없다.</p>


<p>정리하자면, Bayes&#8217; theorem은 observation(likelihood), 현상에 대한 사전정보 (prior), 주어진 데이터에 대한 현상의 확률 (posterior) 의 관계를 define하는 중요한 역할을 한다고 할 수 있겠다.</p>




<h5 id="58-2-pd">Probability densities</h5>


<p>Probability density, 우리 말로 하면 확률밀도가 되겠다. 간단히 생각하면 주어진 domain에 대해 확률이 어떻게 분포하고 있는지를 나타내는 일종의 function이라 할 수 있겠다. 아마 이것도 고등학교 수학시간에 배우는 것으로 기억하는데.. 그만큼 아주 간단한 개념이다. 자세한건 위키를 <a href="http://en.wikipedia.org/wiki/Probability_density_function" target="new">참고</a>하면 될 것 같다. 그럼 이게 실제로 어떤 의미가 있으며 맨 처음에 probability density 관점에서 machine learning을 볼 수 있다는 것의 의미는 무엇인가?</p>


<p>Probaiblity density라는 녀석은 결국 주어진 데이터들이 어떤 방식으로, 어떤 확률로 분포해있는지를 알려주는 녀석이라 할 수 있다. 예를 들어보자. 만약 우리가 스팸필터를 만들었는데 &#8216;광고&#8217; 라는 단어가 포함이 되면 해당 메일이 스팸일 확률이 80%이고, &#8216;구매&#8217; 라는 단어가 포함이 되면 90%, &#8216;Machine Learning&#8217; 이라는 단어가 포함되면 스팸일 확률이 10%.. 이런식으로 모든 단어, 모든 domain에 대해 스팸일 확률을 알고 있다면, 혹은 그런 probability density를 찾을 수 있다면, 더 정확히 말하면 probability density function을 찾아낼 수 있다면 우리는 매우 좋은 inference를 할 수 있게 될 것이다.</p>


<p>이제 Machine Learning과의 연계를 지어보자. 어떤 우리가 모르는 probability density function을 가지는 데이터들에 대해, 그 데이터들을 사용해 probability density function을 찾아내는, estimate하는 과정을 일컬어 Density estimation이라 부른다. 이전에는 데이터들을 통해 &#8216;함수&#8217;를 찾아낸 것이고, 지금은 그 함수가 density function이라는 점이 다른 점이다.</p>




<p>Bayes&#8217; theorem 이나 probability density 등 이외에도 probability theory 쪽에서 언급해야할 얘기들이 없는 것은 아니다. 예를 들어서 expectation이라거나.. 하지만 내 생각에 이번 글에서 언급한 두 개는 약간 기본적인 probability theory와는 다르게 조금 머신러닝적인 insight가 필요한 부분이 아닐까해서 조금 강조해서 언급해보았다.</p>




<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li>Convex Optimzation</li>
<li>Classification Introduction (Decision Tree, Naïve Bayes, KNN)</li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Graphical Model</li>
<li>Hidden Markov Model</li>
<li>Clustering (K-means, Gaussian Mixture Model)</li>
<li>EM algorithm</li>
<li>Feature Extraction</li>
<li>Matrix Completion</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>And others.. (Reinforcement Learning, Boosting, Model Selection)</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/57/">Machine Learning 스터디 (1) Machine Learning이란?</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-08-02T18:48:00+09:00" pubdate data-updated="true">Aug 2<span>nd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Machine learning이라는 것을 접한지 어느새 거의 1년 반이 넘는 시간이 지났다. 계속 여러 종류의 <a href="/blog/categories/machine-learning/" target="new">Machine learning과 관련된 글들</a>을 써왔지만, 항상 중구난방이고 제대로 정리가 되지 않은 느낌을 받아서 근래에 다시 머신러닝에 대해 공부를 하는 김에 싹 몰아서 정리해보기로 했다. 8월에 연구실에서 머신러닝 스터디를 하기로 했지만, 그것과는 조금 다르게 내가 생각했을 때 이런 순서로 정리를 하면 되겠다.. 하는 느낌으로 정리를 해볼 생각이다. Bishop 책을 많이 참고했으면 하고.. 특히 이번 ICML에서 느낀거지만, Machine Learning에는 정말 많은 분야가 있는데, 많은 Lecture들에서 어쩔 수 없이 그것들을 전부 커버하지 못하는 점이 너무 아쉬웠다. 그래서 일단 내가 할 수 있는데까지는 정리해보는게 좋지 않을까.. 하는 생각으로 글을 써보려 한다.</p>


<p>시작하기 전에 재미있는 짤방을 하나 보고 가자. 여러 사람들이 생각하는 Machine Learning이란?</p>


<p><img src="/images/post/57-1.jpg" width="600"></p>

<p>난 이걸 보고 정말 재미있다는 생각을 했는데, Machine Learning이라는 말 자체가 기계를 학습시킨다, 가르친다라는 의미이기 때문에 마치 기계들을 모아놓고 수업을 하는 것 같은 모습을 society에서는 연상하기 쉽고, 내 친구들 그러니까 다른 공학이나 과학을 전공하는 친구들 입장에서 봤을 때는 로봇 AI를 하는 사람인 것 같고 조금 더 Hardware에 focus된 것처럼 느끼는 경우가 많다. 부모님은 뭔지는 모르겠는데 애가 맨날 컴퓨터하고 서버 얘기하니까 IDS에서의 저런 모습을 생각하고 ㅋㅋㅋㅋ 다른 프로그래머들은 뭔가 일반적인 프로그래밍과는 다르게 수학적으로 엄청 어려운 무언가를 하는 것 처럼 보이고 이상한 식들 막 적어놓고 &#8216;뭐야 저거 무서워&#8217; 이런 느낌으로 바라보기 마련이다. (저 식은 뭔지 모르겠는데 error function 관련된 식이 아닐까 싶네). 그리고 나는 내가 하는 일이 진짜 멋있는 일이라고 생각하지만 실제로 내가 하는건 남들이 만들어놓은 library를 import해서 사용하는게 전부라는 짤이다 ㅋㅋㅋ</p>


<p>이 하나의 짤방에서 참 많은 얘기들을 할 수 있을 것 같은데.. 일단 내가 앞으로 얘기할 Machine Learning이라는 것은 위의 그림에서 찾자면 what other programmers think I do와 거의 흡사하다. 이유는 내가 하려는 부분이 알고리듬과 관련된 부분이 많고 모델링 등등 수학적인 무언가를 요구하고 저런 계산들을 통해 이론적으로 각 알고리듬이나 모델들의 무언가를 도출하는&#8230; 그런 과정들을 다루려는 것이기 때문이다. 자세한 얘기는 조금 더 뒤에서 할 수 있도록 하자.</p>


<h5 id="57-1-WhatMLE">What is Machine Learning? - Easy Answer</h5>


<p>자 그러면 본론으로 들어가서 Machine Learning은 과연 무엇일까. 여러가지로 설명을 할 수 있겠지만 내가 예전 <a href="/3" target="new">Andrew Ng. 교수의 Machine Learning Lecture를 들으며 정리했던 글</a>에 정의했던바에 따르면, &#8216;머신러닝은 그 관계를 알 수 없는 수 많은 데이터들 사이에서 관계를 찾아내주는 마법과 같은 기술이다.&#8217; 라는 얘기를 했었다.</p>


<p>마법과 같은 기술이라는 용어가 조금 유치하기는 하지만, 기본적인 Machine learning의 철학을 잘 반영하는 표현이라고 생각한다. Machine Learning은 컴퓨터에게 우리가 직접 명시적으로 무언가를 지시하지 않아도 데이터를 통해 컴퓨터가 자동으로 판별을 해 performance를 향상시킬 수 있도록 하는 무언가를 의미한다고 할 수 있다. 무슨 얘기이냐하면 예를 들어 우리가 이메일에 들어가는 스팸필터를 만든다고 생각해보자. 가장 간단하게 생각할 수 있는 방법은 blacklist를 만드는 방법이 있다. 사용자들에게 많이 report가 된 나쁜 email들을 모아서 blacklist에 지정하는 것이다. 그런데 이런 방법은 회피방법이 명확하다. 보낸 사람을 이상하게 바꿔 보내면 된다. 그러면 이제 메일의 제목이나 안에 들어가는 내용을 사용해 필터링을 해야하는데, 역시 가장 간단한 방법은 blacklist이다. 광고, 싸게, 이런 단어들이 들어가면 일단 차단을 시키는 방법이다. 그런데 이 방법은 우회하기도 쉬우며 (광.고. 라고 쓴다거나) 이런 방식으로 쓰이는 모든 단어를 추가할 수도 없으며, 일상 생활에서도 쓰일 수 있는 표현이 있을 수 있기 때문에 멀쩡한 사람의 email을 spam이라고 인식하게 되는 끔찍한 일이 벌어질 수 있다. 즉, 이런 식으로 일일이 blacklist를 조정하는 방식으로 프로그래밍을 하는 것을 &#8216;명시적으로 무언가를 지시한다&#8217; 라고 표현한 것이다. Machine Learning 적인 접근 방법으로 이 문제를 바라보게 되면, 컴퓨터에게 스팸인 email과 스팸이 아닌 email들을 주고, 스팸인 email들이 왜 스팸인지 &#8216;Learning&#8217;을 시켜서 &#8216;데이터를 통해 컴퓨터가 자동으로 판별을 해&#8217; 스팸을 걸러내는 방식을 취하는 것이다. 그리고 데이터를 통해 배우는 것이기 때문에 데이터가 많아질 수록 performance역시 증가하게 될 것이다. 이런 모든 것이 바로 Machine Learning이라고 할 수 있는 것이다.</p>


<h5 id="57-2-WhatMLD">What is Machine Learning? - Modeling View</h5>


<p>그러면 Machine Learning을 조금 더 수학적으로 정의해보자. 수학적으로 Machine Learning problem을 기술해보면 아래와 같은 얘기를 할 수 있다.</p>


<ul>
<li>Experience E를 Learning할 Computer Program</li>
<li>그리고 각각의 E에 대응되는 class of task T</li>
<li>Task의 Performace Measure P</li>
<li>Machine Learning이란 Experience E를 사용하여 (Learning하여) task T의 performance P가 개선이 되도록 하는 program (Algorithm)</li>
</ul>


<p>위에서 기술한 Machine Learning이라는 것은 일종의 Modeling Problem으로 생각할 수 있다. 무슨 얘기냐? 머신러닝이란 &#8216;주어진 데이터&#8217;에 대해 &#8216;현상&#8217;을 &#8216;가장 잘 설명할 수 있는 관계&#8217;를 찾아내는 것이라 했었는데, 이 말을 조금 수학적으로 풀어내면 주어진 &#8216;데이터&#8217; \(X = (x_1, x_2, x_3, \ldots, x_n)\) 이 있을 때 이 데이터와 실제 &#8216;현상&#8217; \(Y = (y_1, y_2, \ldots, y_n) \)에 대한 &#8216;관계&#8217; function \(f\)를 찾아야한다. 당연히 우리가 정확한 함수 \(f\)를 찾아낼 수는 없으므로 &#8216;최대한 잘 설명할 수 있는&#8217;, 함수 \(f&#8217;\)을 찾아내야 한다. 이를 Hypothesis라고 한다. 즉, 이 모든 과정을 일종의 Modeling process로 생각이 가능하다는 뜻이다. 다만 우리의 새로운 process는 for given data에 대해 dependent한 model을 만들어낸다는 점이 독특한 것이다.</p>


<p>그렇다면 Machine Learning은 어떻게 진행이 될까. 먼저 problem setting이 필요하다. 다음과 같은 setting이 필요한데, (1) Set of possible instances (domain) X (2) Output Y (3) Unknown target function \(f:X\to Y\) (4) Set of function hypothesis space \(H \in \{ h| h: X\to Y \} \). 이는 곧 앞서 대략적으로 설명했던 function, hypothesis 등등에 관련된 설명을 조금 더 수학적으로 풀어낸 것이다. 여기에서 주목할 것은 네 번째 set of function hypothesis space인데, 이는 우리가 모든 function들을 확인할 수가 없기 때문에 그럴 것이다 라고 추측할 수 있는 function들의 set으로만 한정을 짓겠다는 의미가 되는 것이다. 이런 problem setting이 완료되고 나면 learning을 하기 위한 input data가 필요한데 이를 training data라고 한다. training data는 \(\{ \langle x_i, y_i \rangle &#92;}\) 식으로 주어지는데, 이때 supervised learning은 class 혹은 label이 주어지는 경우를 의미하고, unsupervised learning은 이 y가 존재하지 않는 경우이다. 마지막으로 Machine Learning의 output으로 \(h\in H\) 인 h 중에서 target function f와 가장 유사한 hypothesis를 고르게 되는데, 고르는 방법은 performance measure를 했을 때 가장 좋은 performance를 가지는 hypothesis를 선택하는 방식으로 고르게 된다.</p>


<p>이를 조금 더 보기 쉽게 기술해보자.</p>


<p>먼저 problem setting</p>


<ul>
    <li>Set of possible instance(domain): X</li>
    <li>Output: Y</li>
    <li><p>Unknown target function \(f:X \to Y\)</p></li>
    <li><p>Set of hypothesis function space \(H \in \{h|h:X \to Y\}\)</p></li>
</ul>


<p>Input</p>


<ul><li><p>Traing example \(\{ \langle x_i, y_i \rangle &#92;}\)</p></li></ul>


<p>Output</p>


<ul><li><p>\(h\in H\) that best approximates target function f with some performance measure</p></li></ul>


<p>위에서 설명한 얘기를 그림으로 설명하면 아래와 같은 그림을 그릴 수 있다.</p>


<p><img src="/images/post/57-2.png" width="600"></p>

<p>다시 한 번 스팸필터를 생각해보자. 데이터 X는 메일들이다. 우리가 받는 메일 하나하나가 데이터가 될 수도 있고, 그 메일 안에 있는 단어 하나하나가 될 수도, 혹은 아예 알파벳 하나하나가 될 수도 있다. 그것은 우리가 정하기 나름이니까. 그럼 현상 Y는 무엇일까? 각각의 메일이 스팸인지, 아니면 일반 메일인지 구분하는 구분자, indicator, 혹은 Label, Class가 될 것이다. 마지막으로 가장 잘 설명할 수 있는 함수는 이런 데이터들을 가지고 어떻게 Learning을 할 것인지에 대한 얘기가 될 것이다. 예를 들어 Naïve Bayes라던가, KNN, SVM도 있고, 요새 핫한 Deep learning도 있을 수 있다.</p>


<h5 id="57-3-WhyML">Why Machine Learning?</h5>


<p>그러면 이런 Machine Learning은 도대체 왜 사용하는걸까, 왜 이렇게 핫한걸까? 다시 말해서 Modeling view에서 했었던 표현을 그대로 사용해보자면, Machine Learning에서 찾아낸 Hypothesis로 우리는 무엇을 하고 싶은걸까? 단순히 데이터와 현상의 관계를 함수로 나타내는 것이 무슨 의미가 있지? 이것이 의미가 있는 이유는 우리가 새로 주어진 데이터, 혹은 test data에 대해 새로운 추론, inference를 하는 것이 가능하기 때문이다. 이 메일은 스팸인가? 이런 쇼핑 목록을 가진 사람은 또 뭘 사고 싶어할까? 이런 날씨에는 고속도로가 막힐까 막히지 않을까? 이런 질문들에 대해 앞서 우리가 정의한 방식대로 Machine Learning problem을 풀어 새로운 Hypothesis를 통해 우리는 inference를 내릴 수가 있다.</p>


<p>또한 최근 들어서 Machine Learning이 급부상하고 있는 가장 큰 이유 중 하나는 &#8216;빅데이터&#8217; 라는 것이 등장했기 때문이다. 즉, 이전과는 비교할 수 없을 정도로 데이터의 크기가 급격하게 증가하게되었고, 그 어마어마한 데이터에서 어떤 inference를 뽑아낼 수 있다면 그것이 엄청난 효과를 거두게 할 수 있지 않을까라는 생각을 사람들이 하게 된 것이다. 그런데 이걸 explicit하게 일일이 해주기에는 솔직히 너무 힘들고, 기계가 데이터를 읽으면 알아서 inference를 내렸으면 좋겠다라는 needs가 커지게 되었고, 이에 Machine Learning을 사람들이 많이 요구하게 된 것이다. 사실 Machine Learning이 AI의 엄청 오래된 분야임에도 최근 들어서 뜬 가장 큰 이유 중 하나가, 이론적으로 Machine Learning이 아무리 훌륭해도 input data가 없으면 좋은 performance를 내고 싶어도 낼 수 없기 때문인데 최근에는 지천에 널린게 데이터이다보니 Machine Learning이라는 것에 대해 사람들이 많이 중요하게 생각을 하는 것 같다.</p>


<p>조금 더 구체적인 예를 들어보자. 아까 예를 들었던 스팸 필터를 예로 들어보자면, 일반적으로 &#8216;머신러닝이 아닌&#8217; 스팸필터를 생각해보자. 가장 간단한 방법으로는 Black list가 있을 것이다. 해당하는 계정이 보낸 메일은 스팸으로 처리하는 방법이 있다. 하지만 이렇게 rule을 정해버릴 경우 그것을 우회하는 방법은 무수히 많다. 계정은 무한하게 생성 가능하니까. 그걸 보완하는 방법으로 White list가 있다. 허용하는 이메일만 accept를 하는 것이다. 하지만 이 역시 완전하지는 않다. 우리는 언제나 새로운 사람과 연락을 해야하는 경우가 있으니까. 즉, Machine Learning이 아닌 접근 방법은 어떤 deterministic한 rule을 통해서 동작하게 되며, 그것을 개선시키는 것은 온전히 사람의 몫이다. 그러나 머신러닝을 적용한 스팸필터는 우리가 특정 모델을 정의하고 난 이후에는, 예를 들어서 지금은 단어마다 그 단어가 포함되면 스팸일 확률을 계산해서 최종적인 확률을 계산하는 방식을 도입했다고 해보자. (naïve bayes) 처음에는 완벽하지 않겠지만, 데이터가 늘어나면 늘어날수록 이 모델의 정확도는 높아지게 될 것이다. 사람이 따로 룰을 정할 필요가 없이 machine이 스스로 알아서 improve가 되는 것이고, 더 나은 것을 learning하게 되는 것이다.</p>


<p>하지만 물론 Machine Learning이 항상 능사는 아니고 단점도 존재한다. 같은 예를 계속 얘기해보면, 스팸이 아닌데 스팸으로 취급한 경우에 과연 머신러닝으로 접근한 방법은 디버깅을 어떻게 해야할까? 사람이 따로 rule을 정할 필요가 없다는 말은 반대로 말하면 사람이 rule에 미칠 수 있는 영향력이 크지않다는 의미도 된다. (나중에 decision theory에서 보면 알 수 있겠지만 항상 그런 것은 아니다.) 즉, 언제나 machine learning에는 error가 존재하는데, 이 error가 optimal한 point까지 도달하고 나면 debug할 수 있는 방법이 없다는 것이다. 반면 머신러닝이 아닌 방법은 특정 사람이 스팸필터에 걸리면 그때그때 룰을 수정해서 디버깅을 할 수 있다. 그리고 computation power에 대한 문제도 있을 수 있다. 머신러닝은 많은 데이터에서부터 모델을 learning해야하기 때문에 당연히 그냥 deterministic한 방법보다 계산량이 많아지게 되는 것이다. 이런 여러가지 장단이 있기 때문에 머신러닝이 항상 능사는 아니라고 할 수 있을 것이다.</p>


<p>하지만 그럼에도 머신러닝이 최근에 많이 쓰이는 이유는 위에서 말한 문제점들이 더 이상 문제점이 아니기 때문이다. 문제점은 크게 두 가지였는데, 하나는 error였고, 또 하나는 computation이었다. Machine learning의 많은 모델들은 이론적으로 데이터가 무한하게 존재하는 경우 가장 이론적으로 작은 error를 생산해낸다. 그리고 그 뿐 아니라, 최근에는 사람이 눈으로 데이터의 rule을 정하기에는 데이터가 상상이상으로 많기 때문에 (아까 언급했던 빅데이터) 사람이 직접 룰을 정하는 것에 무리가 생기는 경우가 많다. 즉, 사람이 rule을 결정하기가 점점 어려워지고 있는 것이다. 스팸 필터가 좋은 예인데, 사람이 아무리 좋은 룰을 만들어내도 새로운 스팸이 계속 생겨나게 된다. 그러나 우리가 모든 스팸메일을 가지고 있다면 machine learning approach는 더 나은 결과를 return 할 수 있을 것이다. 그리고 두 번째 문제는 최근에 하드웨어의 성능이 엄청나게 빠른 속도로 좋아지고 있을 뿐 아니라, 알고리듬의 측면에서도 여러가지 분산처리 알고리듬이 많이 개발이 되고 있어 계산량을 급격하게 감소시켜 빠르게 계산을 처리하는 것이 가능해졌다. 이런 이유들로 최근 머신러닝이 급부상하고 있는 것이 아닐까한다. 거기에다 이런 이유들, 데이터의 폭발적인 증가, 하드웨어의 개선, 분산처리 알고리듬의 개발 등은 지금 한순간 반짝하는 것들이 아니라 앞으로도 계속 발전이 될 것으로 기대가 되는 상황에서 Machine Learning은 매우 훌륭한 도구가 될 수 있다.</p>


<h5 id="57-4-ClassML">Class of Machine Learning</h5>


<p>앞서 설명한 대로 Machine Learning을 정의하게 되면 완전히 raw한 데이터를 다루는 과정, 예를 들면 Dimensionality reduction, Metric Learning 등의 과정에서부터 시작해서, 어떻게 Learning할 것이냐, model이 무엇이냐, 조금 더 구체적으로 얘기하면 어떤 Algorithm을 사용해 이 model을 learning할 것이냐라는 문제를 풀어내고, 마지막으로 어떻게 결정을 내릴 것이냐, decision making을 할 것이냐 하는 등의 모든 여러 과정들이 Machine Learning의 종류라고 할 수 있다.</p>


<p>하지만 일반적으로 Machine Learning의 class를 나누는 방법은 Supervised Learning, Unsupervised Learning, Reinforcement Learning으로 나뉜다. 쉽게 생각해서 Supervised Learning, Unsupervised Learning의 차이점은 데이터에 Label이 있느냐 없느냐의 차이이다. <a href="/3" target="new">이전 글</a>에 내가 전에 설명한 적이 있으니 이에 대해 궁금한 점이 있다면 읽어보기를 권한다.</p>


<p>Reinforcement Learning은 &#8216;action&#8217;을 learning하는 것인데, 어떤 환경에서 내가 action을 취할 때 마다 다른 reward를 받는다고 할 때, 내가 어떻게 action을 취해야 reward를 maximize할 수 있는가를 Learning하는 학문이다. 이 부분도 cover하고 싶고 나도 관심이 있는 부분이지만 아마 이 스터디에서는 다루지 못하지 않을까싶다.</p>


<h5 id="id-57-5-aboutStudy">About This Machine Learning Study</h5>


<p>이 스터디는 앞으로 내가 틈이 나는 대로 계속 글을 작성할 예정이다. 앞서 말한대로 주로 Bishop을 중심으로 작성하게 될 것 같으며, 필요하면 다른 책이나 논문을 참고해서 글을 작성해보려 한다. 이 스터디에 내가 작성한 다른 글들을 읽고 싶으면 아래 리스트에서 원하는 항목을 찾아 읽으면 될 것 같다.</p>




<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li>Convex Optimzation</li>
<li>Classification Introduction (Decision Tree, Naïve Bayes, KNN)</li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Graphical Model</li>
<li>Hidden Markov Model</li>
<li>Clustering (K-means, Gaussian Mixture Model)</li>
<li>EM algorithm</li>
<li>Feature Extraction</li>
<li>Matrix Completion</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>And others.. (Reinforcement Learning, Boosting, Model Selection)</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/55/">2014 ICML 후기</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-06-26T16:16:00+09:00" pubdate data-updated="true">Jun 26<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>이번에 <a href="icml.cc/2014/" target="new">ICML 2014</a>를 다녀왔다. 내 첫 해외 학회이기도 했고, 처음으로 Machine Learning과 관련된 연구를 하는 사람들의 talk을 듣고, 그 사람들이 직접 하는 일들을 많이 볼 수 있어서 개인적으로 많이 고무된 상태로 학회에 참여했었다. 첫 학회를 다녀온 기념으로 학회에서 내가 느낀 점들을 간단하게 정리해보고자 한다. 대충 보자면 아래 리스트 정도가 될 것 같다.</p>


<ul>
<li>항상 열정을 가지고 있고 열심인 사람들</li>
<li>어떤 식으로 연구를 해야겠다라는 생각</li>
<li>Machine Learning이라는 학문의 방대함</li>
<li>Neural Network와 Deep Learnig의 강세</li>
<li>Real Industry와 Machine Learning</li>
</ul>


<p>먼저 사람들. 개인적으로 내 자신에게 살짝 아쉬운 점이라면 학회에서 만난 사람들에게 먼저 다가가서 이야기를 걸거나 할 베짱이 많이 없었다는 것이다. 사실 내가 그렇게 사람들에게 먼저 다가가고 얘기를 나누기에는 내가 알고 있는 지식이 많이 부족함에도 원인이 있기는 하지만 그래도 다들 같은 분야에 관심을 가지고 (세부 관심사는 조금씩 다를 수 있지만) 나와 비슷한 입장을 가진 사람들도 있을 수 있었을텐데 내가 조금 적극적이지 못했던 부분이 있다. 학기 중에 윤준보교수님 수업에서 학회를 가면 그 사람들과 이야기를 많이 나누어보라는 얘기를 해주셨는데 막상 내게 그런 기회가 생기니 할 수 있는 말이 많이 없더라. 조금 더 정진해서 그런 대화에 두려움이 없을 정도의 지식을 쌓아야할텐데. 그런 개인적인 아쉬움은 잠시 넘겨서 생각을 해보자면, ICML에서 만난 사람들은 정말 열정있는 사람들이었다. 고작 15분에서 20분짜리 talk조차 이해하지 못하고 허덕이고 있는 나와는 다르게, 정말 발표자의 talk을 이해하고 그들과 communication하면서 질문하는 모습이 멋져보였다. 1시간 가까이 되는 invited talk이나 key note talk에서도 많은 부분을 놓치지 않으려 노력하는 모습도 멋졌다고 생각한다. 나도 그런 멋지다고 생각한 모습에 한 단계 더 다가가야할텐데.</p>


<p>그리고 그 다음은 역시 연구였다. 내가 대학원생이 되었고, 연구가 나에게 가장 중요한 비중을 차지하게 된 이상, 어떤 연구를 할 것이며 어떻게 연구를 할 것이며.. 혹은 왜 연구를 해야하는 것이냐 등의 물음은 나에게 굉장히 중요한 물음이다. 약간 어느 정도는 간접적으로 그 질문들에 대한 답을 얻을 수 있었던 것 같은데, 어떤 공명감으로 연구를 한다는 느낌보다는 이 문제를 풀어야하겠다는 그런 근본적인 호기심? 같은게 영향을 미치는게 아닌가 싶다. 사실 명확하게 이거다! 싶은 느낌은 잘 들지 않았지만 앞서 말했듯이 다들 열정적으로 임하고 질문 하나하나가 날카롭게 들어가는 모습을 보면서 이런 학회에 publish를 하는 사람들은 어떤 생각으로 다른 사람들의 talk을 듣는지 조금이나마 간접적으로라도 체험할 수 있지 않았나 싶다. 아무튼 진짜 열정적으로 해야한다. 그게 진짜 큰 것 같다.</p>


<p>또 학회에서 놀라웠던 점이라면 Machine Learning이라는 분야 자체가 생각보다도 훨씬 더 방대했다는 점이다. 전체 Track이 6개가 parallel 하게 돌아가면서 전체 다 합쳐서 거의 300개 가까이 되는 talk이 진행이 됐으니까.. (<a href="http://icml.cc/2014/index/article/12.htm" target="new">스케쥴</a>) 단순히 accept된 paper만 많은 것이 아니라 각 track의 주제 또한 너무나도 다양하였다. Networks and Graph-Based Learning, Reinforcement Learning, Bayesian Optimization and Gaussian Processes, Supervised Learning, Neural Networks and Deep Learning, Graphical Models, Bandits, Monte Carlo, Statistical Methods, Structured Prediction, Deep Learning and Vision, Matrix Completion and Graphs, Learning Theory, Clustering and Nonparametrics, Active Learning, Optimization, Large-Scale Learning, Latent Variable Models, Online Learning and Planning, Clustering, Metric Learning and Feature Selection, Optimization, Neural Language and Speech, Graphical Models and Approximate Inference, Online Learning, Monte Carlo and Approximate Inference, Method-Of-Moments and Spectral Methods, Boosting and Ensemble Methods, Matrix Factorization, Nonparametric Bayes, Manifolds, Kernel Methods, Unsupervised Learning and Detection, Crowd-Sourcing, Manifolds and Graphs, Regularization and Lasso, Nearest-Neighbors and Large-Scale Learning, Topic Models, Sparsity, Neural Theory and Spectral Methods, Features and Feature Selection, Time Series and Sequences&#8230;. 와 진짜 많다. 물론 이 전체를 또 잘 묶으면 더 줄어들 수 있겠지만 그래도 일단 각각의 Track들이 서로 다른 주제를 가지고 이렇게 많이 있다는 사실이 놀라웠다. 글쎄, 그래도 굳이 크게 나누자면, (1) Learning for Graphical Model (2) Traditional Machine Learning Problems (Bayesian, Supervised Learning&#8230;), (3) Optimization (4) Monte Carlo (5) Unsupervised Learning (Clustering, Metric Learning&#8230;) (6) Neural Network (7) Others 정도가 아닐까. 모르겠다 너무 많고 내가 모르는 분야가 너무 많아서. 아무튼 정말 Machine Learning이 어마어마하게 큰 분야라는 것을 다시 한 번 느끼게 되었다. 나는 저 많은 Track 중에서 어느 분야에 기여를 할 수 있을까?</p>


<p>꼭 그런건 아니었지만, 전반적으로 Deep learning 과 관련된 talk들. 심지어 &#8216;Deep&#8217; 이라는 이름이 들어가기만 해도 컨퍼런스 룸이 터질듯한 것을 볼 수 있었다. 정말 요즘 이게 핫하긴 핫하다. 근데 난 이상하게 정말 Deep learning이 싫은데.. 이유를 잘 모르겠다. 가장 practical하게 powerful해서 그렇겠지? 중국에서 해서 그런지는 모르겠지만 Deep learning세션은 중국인들이 바글바글 몰려서 진짜 산만했었다. 그만큼 가장 핫하다는 뜻이고, 중국인들이 이런 실용적인 것들에 무지 관심이 많다는 것을 느꼈다. 이론쪽보다는 확실히 그런 practical 한 세션에 중국인들이 압도적으로 많았다. Deep learning 관련 시스템 쪽도 사람 엄청 많았고.. 진짜 그야말로 Deep Learning의 시대라고 봐도 무방할 정도. 대단하더라.</p>


<p>마찬가지 맥락에서, 굉장히 많은 기업들이 ICML을 찾았다. 구글, Facebook, 아마존, MS, 야후 같은 글로벌 기업은 물론이고 바이두, 알리바바 같은 중국 기업들도 엄청 많았다. 그만큼 머신러닝을 전공한 사람들의 힘이 필요하다는, 그런 사람들에 대한 수요가 확실하구나.. 라는 그런 생각이 들더라. 기업 연구소 특히 MS나 구글 연구소 등에서도 많은 논문들이 나오는걸 보고, 저런 연구소에서 일하는 것도 생각보다는 나쁘지 않을 수도 있다는 그런 생각도 들고 그랬다.</p>


<p>ICML에서 여러모로 많은 자극을 받았다. 재미도 있었고. 내년 ICML은 내가 intivation 되서 갔으면 좋겠다! 나도 좋은 논문을 쓸 수 있었으면.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/52/">Network Science - Scale Free Network (Barabasi-Albert Network)</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-04-23T15:33:00+09:00" pubdate data-updated="true">Apr 23<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h5 id="52-1-before">들어가기 전에</h5>


<p>이 글은 <a href="/47" target="new">2014년 KAIST Network Science 수업</a> 중 Scale Free Network 내용을 요약한 글이다. 이 렉쳐에서는 Scale Free Network라는 concept에 대해 다루게 된다.</p>


<h5 id="52-2-scalefreenetwork">Scale Free Network</h5>


<p>이전 글들에서 <a class="red tip" title="따로 글로 정리를 하지는 않았지만, Watts-Strogatz를 설명하면서 다뤘던 부분이다.">Regular Network</a>, <a href="/50" target="new">Random Network</a>와 <a href="/51" target="new">Small world Network</a>에 대해 다뤘던 것들 중 Path length, Clustering coefficient, 그리고 Degree distribution 부분을 정리해보자.</p>


<p>먼저 Path length이다. 우리가 관측하는 대부분의 network들은 Path length가 그 크기의 logarithm function으로 표현된다는 것을 알 수 있다. 조금 더 구체적으로 표현하자면 \(l_{rand} \approx {\log N \over \log \bar k}\)로 표현이 된다. 먼저 Regular Network의 path length는 \(l \approx N^{1/D}\)로 표현이 된다. 우리가 원하는 log 와는 다른 형태임을 알 수 있다. 그렇다면 Random Network와 Small world Network는 어떨까? 이전 결과들을 통해 확인할 수 있듯 \(l_{rand} \approx {\log N \over \log \bar k}\)로 표현이 된다는 사실을 알 수 있다. 즉, Erdös-Rényi Network와 Watts-Strogatz Network는 일반적으로 우리가 관측하는 네트워크와 비슷한 Path length를 지니고 있고 Regular Network는 그렇지 않음을 알 수 있다.</p>


<p>Clustering coefficient는 어떠한가? 대부분의 실제 네트워크의 clustering coefficient는 그 크기에 무관하게 항상 상수로 표현된다. 즉, \(C \sim const \)로 표현이 된다. Regular network와 small world network가 이 값이 상수임에 반해, Random network는 이 값이 \(C = p = {\bar k \over N}\)으로 표현이 된다. 즉, 크기가 커질수록 이 값이 감소하는 경향을 보이는데 이 부분은 실제 네트워크와 큰 차이가 있는 부분이다. 즉, Random network는 실제 네트워크보다 뭉침 현상이 덜 하고, Regular Network와 Small world network는 실제 네트워크와 그 뭉침 정도가 비슷하다는 것을 알 수 있다.</p>


<p>그렇다면 지금까지의 결론을 보면 Small world Network만 Path lenth, 그리고 Clustering의 두 가지 측면에서 실제 네트워크와 유사함을 알 수 있다. 그렇다면 마지막 Degree distribution은 어떠한가? 실제 네트워크에서 나타나는 degree distribution은 power law distribution으로 표현이 된다. 즉, \(P(k) \sim k^{-\gamma}\)로 표현이 된다. 그런데 Regular Network의 degree distribution은 \(P(k) = \delta (k-k_d)\)이며 Random Network는 \(P(k) = e^{-\bar k} {\bar k ^k \over k!}\)로 표현이 된다. 그리고 Small world network의 degree 역시 exponential function으로 표현이 된다. 즉, 지금까지 우리가 살펴본 그 어떤 네트워크도 실제 네트워크와 유사한 degree distribution을 보이지 않음을 알 수 있다.</p>


<p>이러한 문제점, 즉, degree distribution이 잘 맞지않는다는 문제점으로 인하여 새로운 Scale-Free network라는 개념이 등장하게 된다. Scale-Free network란 degree를 \(k\)라 했을 때 degree sequence \(g&#8217;\)이 power-law function \(h(k) \sim k^{-q}\)로 표현이 되는 네트워크를 의미한다. 이 때 exponent \(q\)의 값은 보통 2에서 3 사이로 결정이 된다. 수학적이지 않은 관점에서 바라본다면 scale-free network는 적은 숫자의 high degree node가 있고 그 이외의 많은 node들은 엄청 작은 degree를 가지는 네트워크를 의미한다. 그리고 이런 degree가 높은 node를 일컬어 hub라고 부르게 되며, 다시 말하자면 Scale-Free Network란 hub가 존재하는 네트워크를 의미하게 된다. 이 현상은 사실 생각해보면 우리 주변에도 많이 발생하는데, <a class="red tip" title="영어 단어의 분포는 그 단어의 빈도의 순위의 역수로 표현된다. 즉, 상위 일부가 전체 대다수를 차지한다.">Zipf의 법칙</a>나 <a class="red tip" title="상위 20%가 80%의 부를 가져간다는 법칙. 보통 2:8의 법칙으로 불린다">Pareto의 법칙</a> 등의 관측도 존재하고, 실제 social network에서도 친구가 엄청나게 많은 일부의 사람들이 존재하고 나머지 사람들은 그보다는 적은 사람의 친구를 가지는 등, 이미 hub라는 현상은 우리가 자연스럽게 받아들일 수 있는 개념이라는 것이다.</p>


<p>그렇다면 degree가 exponential인 것과 power-law인 것이 정말 크게 차이가 날까? 만약 그게 아니라면 우리는 충분히 Watts-Strogatz의 결과물을 사용할 수 있을 것이다. 아래 그 둘을 비교한 그림이 있다.</p>


<p><img src="/images/post/52-1.png" width="400"></p>

<p>이 그림을 통해 알 수 있듯, exponential과 power-law는 그 기울기의 감소 정도가 매우 많이 차이가 난다는 것을 알 수 있고, 우리는 degree distribution이 power-law를 가지는 새로운 network가 필요하다는 것을 알 수 있다. 이런 Scale-Free Network는 1999년 Alber, <a class="red tip" title="KAIST 물리과 정하웅 교수님">Jeong</a>, Barabasi에 의해서 처음 연구가 되었으며, 이런 네트워크를 만드는 과정을 Barabasi-Albert Procedure라고 부른다. 그렇다면 Scale-Free라는 이름은 왜 생긴 것일까? Small-world라는 말이 diameter의 증가 정도가 네트워크의 증가 속도보다 훨씬 느리기 때문에 붙은 알이라면, Scale-Free는 degree가 증가하는 정도와 실제 distribution이 같은 속도로 증가함을 의미한다. 수식으로 나타내자면 \(h( \alpha k = \beta h(k)\)로 표현이 된다. 즉, x-axis로 factor \(\alpha\) 만큼 scaling을 한 결과는 y-axis에 factor \(\beta\) 만큼 scaling을 한 것과 같다는 것이다. 따라서 이 power-law curve를 factor \(\alpha\)로 scaling을 하더라도 그 모양은 단순히 위아래로 움직이기만하는 형태로 표현이 된다는 것이다. 즉, 그 우리가 Scaling을 하더라도 그 형태가 변하지 않는 Scale-Free한 Network라는 것이다.</p>




<h5 id="conclusion">Conclusion</h5>


<p>Scale-Free Network를 한 번 정리하고 넘어가보자. 먼저 Scale-Free란 degree distribution이 power-law로 표현되는 network이며, 토폴로지 관점에서 봤을 때 Small-world와 Random network 사이 쯤에 존재하는 네트워크이다. 아래 그림을 보면 엔트로피와 Clustering Coefficient, Average path length, hub degree를 모두 비교해본 결과인데 이 결과를 보면 다른 네트워크와 비교했을 때 다른 값들은 대체로 높지만 상대적으로 뭉침 정도가 약함을 알 수 있다.</p>


<p><img src="/images/post/52-10.png" width="500"></p>

<p>Scale-free network의 entropy는 \(I(G) \sim O( \log_2 ( \Delta m) = O( \log_2 (density(n/2)))\)임을 알 수 있다. 이는 small-world network의 \(I(G) \sim O( \log_2 p )\)와 비슷한 결과이며, 따라서 엔트로피의 관점에서 봤을 때 random network보다는 small-world network에 가까움을 알 수 있다.</p>


<p>Path length는 fixed n에 대해 \(l = A - B k_{hub} \sim O({ \log (n) \over \log (n) + \log (density)}) \)으로 표현이 된다. 그리고 cost-effectiveness라는 것도 정의가 되는데, \(E = {1-\bar {l(density)} \over m}\)으로 표현이 되며 Density는 \(2 \frac {m} {n(n-1)}\)으로 표현이 된다. ========</p>


<p></p>




<h5>KAIST Network Science</h5>


<p>다른 요약글들 보기 (<a href="/blog/categories/network-science/" target="new">카테고리로 이동</a>)</p>


<ul>
    <li>Lecture 1: <a href="/47" target="new">Introduction</a></li>
    <li>Lecture 2: <a href="/48" target="new">Graph Theory</a></li>
    <li>Lecture 3: <a href="/49" target="new">Measures and Metric</a></li>
    <li>Lecture 4: <a href="/50" target="new">Random Network</a></li>
    <li>Lecture 5: <a href="/51" target="new">Small world Network</a></li>
    <li>Lecture 6: <a href="/52" target="new">Scale free Network</a></li>
</ul>

</div>
  
  

<hr>
    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/archives">Blog Archives</a>
    
  </div>
</div>
<!--
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/79/">새로운 Front Framework Webplate에 대한 소견</a>
      </li>
    
      <li class="post">
        <a href="/77/">모바일 시대 Platform에 대한 고찰</a>
      </li>
    
      <li class="post">
        <a href="/62/">Machine Learning 스터디 (6) Information Theory</a>
      </li>
    
      <li class="post">
        <a href="/61/">Machine Learning 스터디 (5) Decision Theory</a>
      </li>
    
      <li class="post">
        <a href="/60/">Machine Learning 스터디 (4) Algorithm</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/SanghyukChun">@SanghyukChun</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'SanghyukChun',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>
//&#8211;>
    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Sanghyuk Chun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=182012898639519&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
