
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Machine learning 스터디 (2) Probability Theory - README</title>
  <meta name="author" content="Sanghyuk Chun">

  
  <meta name="description" content="내 멋대로 정리해보는 Machine Learning. 기본적인 Background Knowledge 중 하나인 Probability Theory">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://SanghyukChun.github.io/58">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/layout480.css" media="only screen and (max-width : 500px)" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="README" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
	<script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/bootstrap.js" type="text/javascript"></script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">



<script>
$(function() {
	$('.tip').attr('data-toggle','tooltip');
	$('.tip').attr('data-placement','top');
	$('.tip').tooltip();
});
</script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42711199-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  
	<div id="fb-root"></div>
	<script>(function(d, s, id) {
	  var js, fjs = d.getElementsByTagName(s)[0];
	  if (d.getElementById(id)) return;
	  js = d.createElement(s); js.id = id;
	  js.src = "//connect.facebook.net/ko_KR/all.js#xfbml=1&appId=182012898639519";
	  fjs.parentNode.insertBefore(js, fjs);
	}(document, 'script', 'facebook-jssdk'));</script>
  
  <div id="main">
  	<header role="banner"><hgroup>
  <h1><a id="blog-title" href="/">README</a>
  
    <span>&nbsp;&nbsp; SanghyukChun's Blog</span>
  
  </h1>
</hgroup>

</header>
  	<nav role="navigation"><ul class="main-navigation list-inline">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="http://sanghyuk.kaist.ac.kr/aboutMe/">About Me</a></li>
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
</ul>

</nav>
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Machine Learning 스터디 (2) Probability Theory</h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-08-03T14:18:00+09:00" pubdate data-updated="true">Aug 3<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>지난 글에서 Machine Learning을 일종의 function 처럼 묘사했었는데, 사실 Machine Learning을 Probability density의 관점에서 보는 것도 가능하다. 이 얘기를 하려면 먼저 Probability density를 포함한 전반적인 probability theory에 대해 먼저 다뤄야할 것 같아서 그 주제로 먼저 글을 써보기로 했다. 일단 엄청 기본적인 내용들, 예를 들어서 조건부 확률이 무엇이고, 이런 얘기들은 일단 생략을 하도록 하겠다. 너무 basic한 얘기이고 \(p(X) = \sum_Y p(X,y) \) 이런거나 \(p(X,Y) = p(Y|X) p(X) \) 이런건 너무나도 기초적인 얘기들이니까. 만약 조건부확률을 잘 모른다면 구글링을 통해 먼저 간단한 지식을 습득하고 오기를 권한다.</p>


<p>다만 그 중에서도 약간 중요하게 다룰만한 주제가 있는데, 그게 바로 Bayes&#8217; theorem이다. 이 Theorem 자체는 그냥 간단하게 \(p(X|Y) \)와 \(p(Y|X) \)와의 관계를 표현한 것임에 불과하지만, 그 안에 숨겨진 의미가 매우매우 중요하다.</p>


<h5 id="58-1-Bayes">Bayes&#8217; Theorem</h5>


<p>\[ p(Y|X) = {p(X|Y) p(Y) \over p(X)} \]</p>


<p>식의 모양은 위와 같다. 이 식이 중요한 이유는 무엇이냐면, 실제 우리가 관측하는 데이터와 실제 일어나는 현상과의 관계를 이어주는 연결고리가 되기 때문이다.</p>


<p>우리가 실제로 관측할 수 있는 데이터와 현상의 관계는 어떻게 되느냐 하면 &#8216;이런 현상이 나타났을 때 데이터의 분포&#8217; 를 보는 것이다. 무슨 얘기냐, 만약 데이터를 X, 현상을 Y라고 해보자. 그럼 우리가 당연히 얻고 싶은 것은 주어진 데이터 X에 대한 현상 Y일 것이다. 즉 \( p(Y|X) \) 를 우리는 실제로 계산하고 싶은 것이다. 그런데 우리가 확인할 수 있는 데이터는 무엇이냐 하면, 어떤 주어진 현상 Y에 대해 존재하는 데이터 X들의 분포 즉, \( p(X|Y) \) 만을 관측할 수 있다. 예를 들어보자. 만약 어떤 질병에 대한 검사를 하는 상황이라고 가정해보자. 우리가 확인할 수 있는 것은 해당 검사에 대해 양성 판정을 받았는지 아닌지 밖에 확인할 수 없다. 만약 이 검사가 완벽하지 않다면 (즉, 정확도가 90% 정도라면) 실제 우리가 관측하는 검사 결과와 그 사람의 질병 보유 상황이 다를 수 있는 것이다. 즉, 검사 결과를 X라고 하고 실제 병에 걸렸는지 아닌지를 Y라고 한다면 우리가 최종적으로 확인하고 싶은 것은 \( p(Y|X) \), 즉 검사 결과를 보고 이 사람이 진짜 질병을 가질 확률을 알고 싶은 것이지만, 실제 우리가 확인할 수 있는 데이터는 \( p(X|Y) \), 즉 이 사람이 실제 병에 걸렸을 때 제대로 검사가 될 확률 (아까 90%라고 했었던) 뿐이 가지고 있지 않다. 더 자세한 것은 <a href="http://musicetc.wikidot.com/bayes-theorem#toc3" target="new">링크</a>를 참조하길 바란다.</p>


<p>중요한 것은 무엇이냐 하면, 진짜 우리가 관측할 수 있는 데이터만 가지고는 우리가 원하는 추론을 하는 것이 어렵다는 점이다. 이때, 주어진 현상에 대해 나타나는 데이터의 분포 \( p(X|Y) \), 즉 우리의 observation을 일컬어 Likelihood라고 한다. 만약 우리가 아무런 정보도 가지고 있는 상황이 아니라면 언제나 이 값을 최대로 만드는 작업을 통해 가장 optimized된 현상을 찾을 수 있는데 이를 maximum likelihood라 한다. (<a href="http://en.wikipedia.org/wiki/Maximum_likelihood" target="new">위키</a>) 즉, 우리가 관측한 정보만을 가지고, 그 정보가 전부라고 가정한 이후에 그 안에서 모든 optimization을 거쳐 가장 좋은 something을 얻어내는 과정이라 할 수 있다. 이를 Maximum Likelihood Estimation 혹은 MLE라 한다. 이 녀석은 Machine learning을 하면서 정말 많이 나오는 용어이고, 실제 이 방법을 사용해 풀어내는 문제들이 많기 때문에 반드시 숙지해야하는 개념이다.</p>


<p>그런데, 앞서 설명했던 예시와 같이, 항상 MLE가 능사는 아니다. 극단적으로 생각해서, 만약 우리가 동전 던지기를 해서 10번 던져서 10번 tail이 나오면 &#8216;이 동전은 tail이 100%로 나오는 동전이다&#8217; 라고 예측하는 것이 바로 MLE인 것이다. 이 방법이 잘 될 떄도 많지만, 방금처럼 데이터가 부족한 경우 등에는 좋은 결과를 얻지 못할 수 있다. 만약 우리가 &#8216;동전 던지기를 하면 head, tail이 50:50 으로 나온다.&#8217; 라는 것을 알고 있다면 조금 더 나은 추론을 하는 것이 가능하지 않을까? 이런 생각에서 나오는 것이 바로 Maximize a posterior, 혹은 MAP이다. Posterior는 앞에서 설명했던 주어진 데이터에 대한 현상의 확률, 즉 \( p(Y|X) \)이다. 간단히 생각해서 Likelihood는 내가 본 데이터에 대한 관측값 만을 의미하는 것이고, Posterior는 관측값과 다른 결과들을 조합하여 나온 조금 더 추론하기에 알맞은 형태? 라고 보면 될 것 같다.</p>


<p>앞서 Bayes&#8217; theorem에서 계산했듯, Observation, 혹은 Likelihood를 알고 있을 때 Posterior를 계산하기 위해서는 \(p(X), p(Y)\)가 필요하다. 이때 \(p(Y)\)는 어떤 현상에 대한 사전 정보이다. 즉, 아까 동전 던지기에서 동전을 던졌을 때 head tail이 나올 확률이 0.5라는 것에 대한 사전 정보이다. 이를 prior 라고 한다. 만약 이 값을 알고 있다면 observation이 잘못되어도 이 값이 약간의 보정을 해주는 역할을 할 수 있게 되는 것이다. 그리고 여기에서 데이터의 분포 \(p(X)\)는 일종의 normalization 을 해주는 역할을 하며, 실제 모든 데이터에 대해 \(p(X|Y) p(X)\) 를 계산한 뒤 그 값들을 noralization하는 것과 동일한 효과이기 때문에 이 값에 대해 알 필요는 없다.</p>


<p>정리하자면, Bayes&#8217; theorem은 observation(likelihood), 현상에 대한 사전정보 (prior), 주어진 데이터에 대한 현상의 확률 (posterior) 의 관계를 define하는 중요한 역할을 한다고 할 수 있겠다.</p>




<h5 id="58-2-pd">Probability densities</h5>


<p>Probability density, 우리 말로 하면 확률밀도가 되겠다. 간단히 생각하면 주어진 domain에 대해 확률이 어떻게 분포하고 있는지를 나타내는 일종의 function이라 할 수 있겠다. 아마 이것도 고등학교 수학시간에 배우는 것으로 기억하는데.. 그만큼 아주 간단한 개념이다. 자세한건 위키를 <a href="http://en.wikipedia.org/wiki/Probability_density_function" target="new">참고</a>하면 될 것 같다. 그럼 이게 실제로 어떤 의미가 있으며 맨 처음에 probability density 관점에서 machine learning을 볼 수 있다는 것의 의미는 무엇인가?</p>


<p>Probaiblity density라는 녀석은 결국 주어진 데이터들이 어떤 방식으로, 어떤 확률로 분포해있는지를 알려주는 녀석이라 할 수 있다. 예를 들어보자. 만약 우리가 스팸필터를 만들었는데 &#8216;광고&#8217; 라는 단어가 포함이 되면 해당 메일이 스팸일 확률이 80%이고, &#8216;구매&#8217; 라는 단어가 포함이 되면 90%, &#8216;Machine Learning&#8217; 이라는 단어가 포함되면 스팸일 확률이 10%.. 이런식으로 모든 단어, 모든 domain에 대해 스팸일 확률을 알고 있다면, 혹은 그런 probability density를 찾을 수 있다면, 더 정확히 말하면 probability density function을 찾아낼 수 있다면 우리는 매우 좋은 inference를 할 수 있게 될 것이다.</p>


<p>이제 Machine Learning과의 연계를 지어보자. 어떤 우리가 모르는 probability density function을 가지는 데이터들에 대해, 그 데이터들을 사용해 probability density function을 찾아내는, estimate하는 과정을 일컬어 Density estimation이라 부른다. 이전에는 데이터들을 통해 &#8216;함수&#8217;를 찾아낸 것이고, 지금은 그 함수가 density function이라는 점이 다른 점이다.</p>




<p>Bayes&#8217; theorem 이나 probability density 등 이외에도 probability theory 쪽에서 언급해야할 얘기들이 없는 것은 아니다. 예를 들어서 expectation이라거나.. 하지만 내 생각에 이번 글에서 언급한 두 개는 약간 기본적인 probability theory와는 다르게 조금 머신러닝적인 insight가 필요한 부분이 아닐까해서 조금 강조해서 언급해보았다.</p>




<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
</ul>

</div>

<hr>
  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Sanghyuk Chun</span></span>

      








  


<time datetime="2014-08-03T14:18:00+09:00" pubdate data-updated="true">Aug 3<span>rd</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/machine-learning/'>Machine-Learning</a>, <a class='category' href='/blog/categories/machine-learning-study/'>Machine-Learning-Study</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://SanghyukChun.github.io/58/" data-via="SanghyukChun" data-counturl="http://SanghyukChun.github.io/58/" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="380" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/57/" title="Previous Post: Machine learning 스터디 (1) Machine Learning이란?">&laquo; Machine learning 스터디 (1) Machine Learning이란?</a>
      
      
        <a class="basic-alignment right" href="/59/" title="Next Post: Machine learning 스터디 (3) Overfitting">Machine learning 스터디 (3) Overfitting &raquo;</a>
      
    </p>
  </footer>
</article>


  <section>
    <h1>Comments</h1>
    <div id="facebook_comments" aria-live="polite">
      <div class="fb-comments" data-href="http://SanghyukChun.github.io/58/" data-width="400" data-num-posts="10"></div>
    </div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/60/">Machine Learning 스터디 (4) Algorithm</a>
      </li>
    
      <li class="post">
        <a href="/59/">Machine Learning 스터디 (3) Overfitting</a>
      </li>
    
      <li class="post">
        <a href="/58/">Machine Learning 스터디 (2) Probability Theory</a>
      </li>
    
      <li class="post">
        <a href="/57/">Machine Learning 스터디 (1) Machine Learning이란?</a>
      </li>
    
      <li class="post">
        <a href="/55/">2014 ICML 후기</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/SanghyukChun">@SanghyukChun</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'SanghyukChun',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Sanghyuk Chun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=182012898639519&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
