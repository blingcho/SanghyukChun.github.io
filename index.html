
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>README</title>
  <meta name="author" content="Sanghyuk Chun">

  
  <meta name="description" content="Machine Learning 스터디 (13) Clustering (K-means, Gaussian Mixture Model) Mar 25th, 2015 | Comments 들어가며 첫 번째 글에서 설명했던 것 처럼 Machine Learning은 크게 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://SanghyukChun.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/layout480.css" media="only screen and (max-width : 500px)" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="README" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
	<script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/bootstrap.js" type="text/javascript"></script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">



<script>
$(function() {
	$('.tip').attr('data-toggle','tooltip');
	$('.tip').attr('data-placement','top');
	$('.tip').tooltip();
});
</script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42711199-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  
  <div id="main">
  	<header role="banner"><hgroup>
  <h1><a id="blog-title" href="/">README&nbsp;&nbsp; </a>
  
    <span style="white-space:nowrap;">SanghyukChun's Blog</span>
  
  </h1>
  <div class="clear"></div>
</hgroup>

</header>
  	<nav role="navigation"><ul class="main-navigation list-inline">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="/search">Search</a></li>
  <li><a href="http://sanghyuk.kaist.ac.kr/">Homepage</a></li>
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
</ul>
</nav>
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/69/">Machine Learning 스터디 (13) Clustering (K-means, Gaussian Mixture Model)</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2015-03-25T03:20:00+09:00" pubdate data-updated="true">Mar 25<span>th</span>, 2015</time>
        
         | <a href="/69/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h5>들어가며</h5>


<p><a href="57-4-ClassML">첫 번째 글</a>에서 설명했던 것 처럼 Machine Learning은 크게 Supervised Learning, Unsupervised Learning 그리고 Reinforcement Learning으로 구분된다. 앞서 이미 그 중 <a href="/64">Supervised Learning</a>을 간략하게 다룬 글이 있었고, 이 글에서는 그 중 Unsupervised Learning의 가장 대표적인 예시인 Clustering 대해 다룰 것이며 가장 대표적이고 간단한 두 가지 알고리즘에 대해서 역시 다룰 것이다.</p>


<h5>What is Clustering?</h5>


<p><a href="http://en.wikipedia.org/wiki/Cluster_analysis">Clustering</a>은 <a href="http://en.wikipedia.org/wiki/Unsupervised_learning">Unsupervised Learning</a>의 일종으로, label 데이터 없이 주어진 데이터들을 가장 잘 설명하는 cluster를 찾는 문제이다. 왜 클러스터링이 필요할까? Classification을 하기 위해서는 데이터와 각각의 데이터의 label이 필요하지만, 실제로는 데이터는 존재하지만 그 데이터의 label이나 category가 무엇인지 알 수 없는 경우가 많기 때문에 classfication이 아닌 다른 방법을 통해 데이터들을 설명해야하는 경우가 발생한다. 아래 그림은 클러스터링이 어떤 것인지 잘 보여주는 그림이다.</p>


<p><img src="/images/post/69-1.png" width="500"></p>

<p>우리에게 처음 주어진 것은 왼쪽 파란 데이터이다. 각각의 데이터에 대한 정보는 아무 것도 없는 상태에서 주어진 데이터들을 가장 잘 설명하는 클러스터를 찾아내는 것이 클러스터링의 목적이다. 따라서 클러스터링은 대부분 Optimization 문제를 푸는 경우가 많다. 이는 클러스터링 뿐 아니라 다른 많은 unsupervised learning에서도 역시 마찬가지이다.</p>


<p><a href="/57">첫 번째 글</a>과 <a href="/64">이전 글</a>에서 머신러닝 문제는 먼저 주어진 데이터에 대한 가정을 하고, 해당 가정을 만족하는 best hypothesis를 찾는 문제라고 언급한 적이 있다. Clustering 문제 역시 Machine Learning 문제이므로 데이터에 대한 가정을 먼저 해야하고, best hypothesis를 찾는 과정을 거친다. 따라서 각각의 서로 다른 clustering algorithm들은 서로 다른 assumption을 가지고 있으며, 해당 assumption을 가장 잘 만족하는 function parameter를 계산하는 과정이다. 앞으로 설명하게 될 알고리즘들에 대한 설명을 읽을 때 데이터에 대해 어떤 가정을 하였는지 꼼꼼히 확인하면서 읽으면 알고리즘을 이해하기 한결 수월할 것이다.</p>


<h5>K-means</h5>


<p>클러스터를 정의하는 방법에는 여러 가지가 있을 수 있지만, 가장 간단한 정의 중 하나는 클러스터 내부에 속한 데이터들이 서로 &#8216;가깝다&#8217;라고 정의하고, &#8216;가장 가까운&#8217; 내부 거리를 가지는 클러스터를 고르는 것이다. <a href="http://en.wikipedia.org/wiki/K-means_clustering">K-means</a>는 같은 클러스터에 속한 데이터는 서로 &#8216;가깝다&#8217; 라고 가정한다. 이때 각각의 클러스터마다 &#8216;중심&#8217;이 하나씩 존재하고, 각각의 데이터가 그 중심과 &#8216;얼마나 가까운가&#8217;를 cost로 정의한다. K-means는 이렇게 정의된 cost를 가장 줄이는 클러스터를 찾는 알고리즘이다. 수식으로 적으면 다음과 같다.</p>


<p>$$ \min_{b,w} \sum_i^n \sum_j^k w_{ij} \| x_i - b_j \|_2^2 \text{ s.t. } \sum_j w_{ij} = 1, \forall j$$</p>


<p>데이터는 \(n\)개 있으며 클러스터는 \(k\)개 있다고 가정했다. 이때, \(b_j\)는 \(j\) 번째 클러스터의 &#8216;중심&#8217;을 의미하며, \(w_{ij}\)는 \(i\) 번째 데이터가 \(j\) 번째 클러스터에 속하면 1, 아니면 0을 가지는 binary variable이다. 또한 뒤에 붙는 조건은 반드시 각 데이터 별로 한 개의 클러스터에 assign이 되어야한다는 constraint이다.</p>


<p>이 문제는 풀기 쉬운 문제가 아니다. Binary variable \(w_{ij}\) 때문에, 모든 cluster 조합을 하나하나 확인해야만 optimal한 값을 구할 수 있다. 즉, jointly optimize하는 것이 매우 어렵다. 그러나 재미있게도 \(b\)와 \(w\) 둘 중 하나를 고정하고 나머지 하나를 update하는 것은 매우 간단하다. 나머지 값이 고정되었을 때 \(b_j\)의 optimal값은 \(j\) 번째 클러스터의 &#8216;mean&#8217;을 계산하는 것이다 (이 때문에 &#8216;\(k\)&#8217; 개의 &#8216;mean&#8217;을 찾는다고 해서 k-means 알고리즘이다). \(w_{ij}\)의 optimal 값은 모든 데이터 i에 대해, 각각 모든 클러스터 중에서 \(x_i - b_j\)가 가장 작은 클러스터에 assign하는 것이 optimal한 solution이다. 이렇듯 만약 다른 변수 하나를 정확하게 알고 있다고 생각하면 아주 간단한 방법으로 alternative optimization이 가능하다. 사실 이 개념은 예전에 적은 <a href="/63">convex optimization</a>글에서 잠깐 언급했던 coordinate descent 방법과 거의 유사하다. K-means 알고리즘은 이렇게 \(b\)와 \(w\)를 alternative하게 계속 update하면서 \(b\)와 \(w\)가 더 이상 바뀌지 않을 때 까지 계산을 반복하는 알고리즘이다. 안타깝게도 K-means는 global optimum에 수렴하지 않고 local한 optimum에 수렴하므로 initialization에 매우매우 취약하다는 단점이 존재한다.</p>


<p>또한 여담으로 K-means objective function에 사용한 \(\ell_2\) norm의 제곱이 outlier 혹은 noise에 매우 취약하기 때문에 조금 더 outlier에 덜 sensitive한 &#8216;robust한&#8217; norm을 사용하는 방법도 존재한다. 예를 들어 \(\ell_2\) norm의 제곱을 \(\ell_1\) norm으로 바꾸면 &#8216;mean&#8217; 대신에 &#8216;median&#8217;을 찾는 문제로 바뀌게 된다. 이를 <a href="http://en.wikipedia.org/wiki/K-medians_clustering">k-median</a>이라고 부른다. 그 밖에도 k-means의 robustness를 개선하기 위한 다양한 방법들이 개발이 되어있지만 이 글에서는 다루지 않도록 하겠다.</p>


<h5>Gaussian Mixture Model</h5>


<p>K-means algorithm의 key idea는 &#8216;alternative update&#8217;이다. 즉, coordinate wise로 다른 변수들을 고정한 채로 &#8216;alternative&#8217;하게 변수들을 update함으로써 jointly optimization을 할 수 없는 문제를 푸는 것이다. 비록 그 결과가 global하지 않은 local에 converge하더라도, 찾지 못하는 것보다는 훨씬 낫기 때문에 실제로 이런 방법이 많이 쓰인다. 이번 섹션에서는 이런 방법을 사용하는 또 다른 알고리즘을 하나 소개하도록 하겠다.</p>


<p>Gaussian Mixture Model, Mixture of Gaussian, GMM, 혹은 MoG는 데이터가 &#8216;Gaussian&#8217;의 &#8216;Mixture&#8217;로 구성이 되어있다고 가정한다. 보통 GMM이라고 많이 부르며, 이 글에서 다루는 GMM은 가장 optimal한 GMM을 찾는 알고리즘을 의미한다. 즉, 데이터가 \(k\)개의 gaussian으로 구성되어있다고 했을 때, 가장 데이터를 잘 설명하는 \(k\)개의 평균과 covariance를 찾는 알고리즘이다. 아래 그림은 3개의 gaussian으로 구성되어있다고 가정하고 그 gaussian 분포들을 찾은 결과이다.</p>


<p><img src="/images/post/69-2.png" width="500"></p>

<p>모든 machine learning 문제는 &#8216;performance measure&#8217;를 가진다고 예전에 얘기한 적이 있다. GMM의 performance measure는 log likelihood function이다. 즉, 주어진 paramter에 대해 데이터 X의 확률을 가장 크게 만드는 parameter를 찾는 것이 목표가 된다. log likelihood는 \(\ln p(X|\theta)\)로 정의가 된다. 우리가 찾아야하는 parameter \(\theta\)는 각각의 gaussian의 평균 \(\mu_j\), covariance \(\Sigma_j\), 그리고 마지막으로 각각의 데이터가 각각의 gaussian에 속할 확률 \(\pi_j\)로 구성된다. 따라서 주어진 \(\mu_j, \Sigma_j\)에 대한 \(x_i\)의 multinomial gaussian distribution을 \(N(x_i|\mu_j, \Sigma_j)\)라고 정의한다면 log likelihood function은 다음과 같이 기술할 수 있다.</p>


<p>$$ \ln p(X|\pi, \mu, \Sigma) = \sum_i^n \ln \sum_j^k \pi_j N (x_i | \mu_j, \Sigma_j) $$</p>


<p>그러나 역시 이 문제도 jointly update가 매우매우 어려운 문제이다. 그러나 K-means와 비슷하게도 \(\pi\)를 고정하고 \(\mu, \Sigma\)를 계산하는 것은 쉬우며, 그 반대 역시 쉽다. 따라서 비슷하게 alternative update를 통해 문제를 해결하는 알고리즘을 어렵지 않게 디자인 할 수 있다. 역시 이 알고리즘도 global로 수렴하지 않고 local로만 수렴하게 된다. GMM을 풀기 위해서 사용되는 알고리즘 중 가장 유명한 알고리즘으로는 <a href="http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">&#8216;EM&#8217; 알고리즘</a>이 존재한다. 이 알고리즘에 대해서는 <a href="/70">다음 글</a>에서 더 자세하게 설명하도록 하고, 이 글에서는 EM 알고리즘이라는 것을 알고 있는 상태에서 어떻게 각 step을 해결할 수 있는지에 대해서만 다루도록 하겠다. E-step에서는 현재 주어진 \(\mu, \Sigma, \pi\)들을 사용해 가장 &#8216;expectation&#8217;이 높은 latent variable의 값을 찾아내며, M-step에서는 새로 estimate된 latent variable을 사용해 그 값을 maximize하는 \(\mu, \Sigma, \pi\)를 찾는다. EM 알고리즘은 E-step과 M-step이 계속 번갈아 진행되며, 더 이상 값이 변하지 않을 때 까지 반복된다. K-means를 이런 관점으로 바라보게 된다면, cluster information \(w_{ij}\)를 update하는 과정이 E-step, \(b\)를 update하는 과정을 M-step이라고 할 수 있다. (그러나 K-means을 푸는 알고리즘은 엄밀하게 말하면 EM 알고리즘이 아니다)</p>


<p>사실 엄밀하게 설명하면 GMM을 푸는 EM에서 E-step 때 update하는 것은 정확하게 \(\pi\)와 같은 것은 아니다. EM으로 이 문제를 풀기 위해서 우리는 새로운 &#8216;latent&#8217; variable을 introduce해야한다. latent variable은 쉽게 생각하면 graphical model에서 hidden variable에 해당하는 값이다. 다음에 EM 알고리즘에 대해 자세히 다룰 때 다시 설명하겠지만, 이렇게 latent variable을 설정하는 이유는 어떤 특정 variable의 marginal distribution을 optimize하는 것은 어려울 때, latent variable을 사용해 그 variable과 latent variable의 joint distribution을 다루는 것은 간단할 수 있기 때문이다. GMM에서는 latent variable \(z\)를 introduce하게 된다. \(z\)는 \(k\)-ary variable로, \(z\)의 \(j\) 번째 dimension인 \(z_j\)는 Binary random variable이며, \(p(z_j=1) = pi_j, \) where \(\sum_j z_j = 1\) and \(\sum_j \pi_j = 1\) 이라는 조건을 가지고 있다. \(z\)의 marginal probability는 \(p(z) = \prod_j \pi_j^{z_j}\)로 어렵지 않게 계산할 수 있으며, 비슷하게 주어진 데이터 \(x\)에 대한 conditional distribution 역시 간단하게 다음과 같이 표현된다. \(p(x|z) = \prod_j N(x|\mu_j, \Sigma_j)^{z_j}\).</p>


<p>따라서 앞선 식들로부터 joint distribution을 얻을 수 있고, 그 값을 marginalize해 다음과 같은 결과를 얻을 수 있다.</p>


<p>$$ p(x) = \sum_z p(x,z) = \sum_z p(z)p(x|z) = \sum_j \pi_j N(x|\mu_j, \Sigma_j) $$</p>


<p>정리하자면, 각각의 data point \(x_i\) in GMM의 graphical representation은 다음과 같이 표현할 수 있다.</p>


<p><img src="/images/post/69-3.png" width="300"></p>

<p>위의 결과들을 토대로 이제 간단하게 EM algorithm을 돌릴 수 있다. 먼저 E step에서는 \(p(z_j = 1|x)\)를 계산할 것이다. 각 데이터에 대해 \(j\) 번째 클러스터에 속할 확률, 혹은 posterior를 계산하는 과정이다. 이 값은 Bayes rule을 통해 간단하게 다음과 같이 계산할 수 있다.</p>


<p>$$ p(z_j = 1|x) = \frac{p(z_j=1)p(x|z_j=1)}{\sum_j^k p(z_j=1)p(x|z_j=1)} = \frac{\pi_j N(x|\mu_j, \Sigma_j)}{\sum_j^k \pi_j N(x|\mu_j \Sigma_j)} $$</p>


<p>다음으로 \(z\)를 fix했을 때 다음과 같이 나머지 paramter를 계산할 수 있다.</p>


<p>$$ \mu_j = \frac{1}{\sum_i p(z_j=1|x)} \sum_i p(z_{ij}=1|x) x_i$$</p>


<p>$$ \Sigma_j = \frac{1}{\sum_i p(z_j=1|x)} \sum_i p(z_{ij}=1|x) (x_i-\mu_j) (x_i-\mu_j)^\top$$</p>


<p>$$ \pi_j = \frac{\sum_i p(z_j=1|x)}{N}$$</p>


<p>정리하자면, GMM을 풀기 위한 EM 알고리즘은, 먼저 각각의 데이터가 어느 클러스터에 속할지에 대한 정보를 update해 (\(z\)를 업데이트 하여) expectation을 계산하고, 다음으로 업데이트 된 정보들을 사용해 나머지 값들로 가장 log likelihood를 최대화하는 parameter들을 (\(\mu, \Sigma, \pi\)를) 찾아낸다. 알고리즘을 돌리면 아래처럼 iteration이 지날 때 마다 점점 좋은 값을 찾아준다. (출처: <a href="http://kipl.tistory.com/64">Geometry & Recognition :: Gaussian Mixture Model & K-means</a>)</p>


<p><img src="/images/post/69-4.gif" width="500"></p>

<p>EM 알고리즘에 대한 심도있는 이해 없이 이 글을 이해하는 것은 조금 어려울 수 있다. 이 글이 잘 이해가 되지 않는다면 먼저 EM 알고리즘에 대해 설명한 <a href="/70">다음 글</a>을 읽어본 다음 다시 읽어보기를 권한다.</p>


<h5>정리</h5>


<p>Clustering은 unsupervised learning 분야에서 가장 활발히 연구되는 분야 중 하나이다. 이 글에서는 여러 종류의 클러스터링 알고리즘 중에서 optimization function을 (1) 거리 기반으로 세우고 그것을 푸는 알고리즘과 (2) 확률과 확률분포를 기반으로 세우고 그것을 푸는 알고리즘을 소개하였다. 특히 GMM은 다음 글에서 다룰 주제인 EM algorithm과 밀접하게 관련되는 내용이므로 한 번 쯤은 책이나 렉쳐노트를 정독하는 것을 권한다.</p>




<h5>변경 이력</h5>


<ul>
<li>2015년 3월 25일: 글 등록</li>
<li>2015년 6월 14일: EM 알고리즘 링크 추가 및 설명 변경</li>
</ul>


<h5>Reference</h5>


<ul>
<li>Bishop, Christopher M. Pattern recognition and machine learning. Vol. 4. No. 4. New York: springer, 2006. Chapter 9</li>
<li><a href="http://kipl.tistory.com/64">Geometry &amp; Recognition :: Gaussian Mixture Model &amp; K-means</a></li>
</ul>


<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li><a href="/63">Convex Optimzation</a></li>
<li><a href="/64">Classification Introduction (Decision Tree, Naïve Bayes, KNN)</a></li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Ensemble Learning (Random Forest, Ada Boost)</li>
<li>Graphical Model</li>
<li><a href="/69">Clustering (K-means, Gaussian Mixture Model)</a></li>
<li><a href="/70">EM algorithm</a></li>
<li>Hidden Markov Model</li>
<li>Dimensionality Reduction (LDA, PCA)</li>
<li>Recommendation System (Matrix Completion, Collaborative Filtering)</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>Reinforcement Learning</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/64/">Machine Learning 스터디 (8) Classification Introduction (Decision Tree, Naïve Bayes, KNN)</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2015-03-25T02:10:00+09:00" pubdate data-updated="true">Mar 25<span>th</span>, 2015</time>
        
         | <a href="/64/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h5>들어가며</h5>


<p><a href="/57#57-4-ClassML">첫 번째 글</a>에서 설명했던 것 처럼 Machine Learning은 크게 Supervised Learning, Unsupervised Learning 그리고 Reinforcement Learning으로 구분된다. 이 글에서는 그 중 Supervised Learning의 가장 대표적인 예시인 Classification에 대해 다룰 것이며 가장 대표적이고 간단한 세 가지 알고리즘에 대해서 역시 다룰 것이다.</p>


<h5>What is Classification?</h5>


<p><a href="http://en.wikipedia.org/wiki/Statistical_classification">Classification</a>은 <a href="http://en.wikipedia.org/wiki/Supervised_learning">Supervised Learning</a>의 일종으로, 기존에 존재하는 데이터와 category와의 관계를 learning하여 새로 관측된 데이터의 category를 판별하는 문제이다. 스팸 필터를 예로 들어들어보자. 스팸 필터의 데이터는 이메일이고, category, 혹은 label, class는 spam메일인지 일반 메일인지를 판별하는 것이 될 것이다. 스팸필터는 먼저 스팸 메일, 그리고 일반 메일을 learning을 한 이후, 새로운 데이터 (혹은 메일)이 input으로 들어왔을 때 해당 메일이 스팸인지 일반 메일인지 판별하는 문제를 풀어야하며, 이런 문제를 classification이라고 한다.</p>


<p><a href="/57">첫 번째 글</a>에서 머신러닝 문제는 먼저 주어진 데이터에 대한 가정을 하고, 해당 가정을 만족하는 best hypothesis를 찾는 문제라고 언급한 적이 있다. Classification 문제 역시 Machine Learning 문제이므로 데이터에 대한 가정을 먼저 해야하고, best hypothesis를 찾는 과정을 거친다. 따라서 각각의 서로 다른 classification algorithm들은 서로 다른 assumption을 가지고 있으며, 해당 assumption을 가장 잘 만족하는 function parameter를 계산하는 과정이다. 앞으로 설명하게 될 알고리즘들에 대한 설명을 읽을 때 데이터에 대해 어떤 가정을 하였는지 꼼꼼히 확인하면서 읽으면 알고리즘을 이해하기 한결 수월할 것이다.</p>


<h5>Decision Tree</h5>


<p><a href="http://en.wikipedia.org/wiki/Decision_tree">Decision Tree</a>는 가장 단순한 classifier 중 하나이다. 이 Decision Tree의 구조는 매우 단순하다.</p>


<p><img src="/images/post/64-1.png" width="600"></p>

<p>위의 그림은 오늘 외출을 할까 말까를 결정하는 decision tree이다. 이렇듯 decision tree는 tree구조를 가지고 있으며, root에서부터 적절한 node를 선택하면서 진행하다가 최종 결정을 내리게 되는 model이다. Decision tree의 가장 좋은 점은 단순하다는 점이다. 누구나 쉽게 이해할 수 있고, 그렇기 때문에 쉽게 디버깅할 수 있다. 예를 들어 위의 예시에서 습도가 높아도 나갈만하다는 생각이 든다면 맨 왼쪽의 No를 Yes로 바꾸기만 하면 간단하게 로직을 바꿀 수 있다. 그러나 다른 모델들은 그런 점들이 비교적 어렵다. Machine Learning에서 말하는 decision tree는 <a href="http://en.wikipedia.org/wiki/Decision_tree_learning">decision tree learning</a>으로, 일일이 node마다 로직을 사람이 써넣어 만드는 것을 의미하는게 아니라, node 개수, depth, 각각의 node에서 내려야하는 결정 등을 데이터를 통해 learning하는 algorithm들을 사용해 만든 decision tree를 의미한다.</p>


<p>많이 쓰이는 알고리즘들로는 <a href="http://en.wikipedia.org/wiki/ID3_algorithm">ID3</a>, <a href="http://en.wikipedia.org/wiki/C4.5_algorithm">C4.5</a>, <a href="http://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees">CART</a>, <a href="http://en.wikipedia.org/wiki/CHAID">CHAID</a>, <a href="http://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines">MARS</a> 등이 있으며, 보통 C4.5를 가장 많이 사용한다.</p>


<p>C4.5는 ID3의 몇 가지 문제점들을 개선한 알고리즘으로, 그 기본 개념은 ID3와 크게 다르지 않다. 추후 이 글 혹은 다른 글에 ID3 알고리즘에 대한 내용을 추가하도록 하겠다.</p>


<h5>Regression Tree and Ensemble method</h5>


<p>Decision tree는 output value가 반드시 binary여야한다는 제약조건이 있기 때문에 스팸 필터 등에서는 사용할 수 있지만, 실제 모든 데이터가 binary만을 output으로 가지지 않으므로 모든 데이터에 사용하려면 변형이 필요하다. <a href="http://en.wikipedia.org/wiki/Decision_tree_learning#Types">Regression tree</a>는 binary가 아니라 real value를 output으로 가지는 모델로, learning하는 방법은 크게 다르지 않다고 한다.</p>


<p>가끔은 하나의 decision tree를 사용하는 것이 아니라 한 번에 여러 개의 decision tree들을 만들어서 각각의 decision tree들이 내리는 결정을 종합적으로 판단하여 (ensemble) 결정을 내리기도 한다. <a href="http://en.wikipedia.org/wiki/Bootstrap_aggregating">Bagging decision tree</a>, <a href="http://en.wikipedia.org/wiki/Random_forest">random forest</a>등이 이에 속한다. 이런 식으로 여러 개의 classifier를 사용해 decision을 내리는 방법을 ensemble method라고 하는데, industry에서는 machine learning algorithm의 성능을 높이기 위해서 여러 개의 알고리즘들을 ensemble method를 사용하여 한 번에 같이 사용하기도 한다. 대표적인 예로 <a href="http://en.wikipedia.org/wiki/AdaBoost">AdaBoost</a> 등이 있다.</p>


<p>Ensemble method에 대해서는 나중에 따로 다시 설명할 예정이므로 그 글을 참고하면 좋을 것 같다. (링크는 추후 추가 예정)</p>


<h5>Naïve Bayes</h5>


<p><a href="http://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naïve Bayes Classifier</a>는 <a href="58-1-Bayes">Bayesian rule</a>에 근거한 classifier이다. Naïve Bayes는 일종의 확률 모델로, 약간의 가정을 통해 문제를 간단하게 푸는 방법을 제안한다. 만약 데이터의 feature가 3개 있고, 각각이 binary라고 해보자. 예를 들어 남자인지 여자인지, 성인인지 아닌지, 키가 큰지 작인지 등의 feature를 사용해 사람을 구분해야한다고 생각해보자. 이 경우 적어도 8개의 데이터는 있어야 모든 경우의 수를 설명할 수 있게 된다. 그런데 보통 데이터를 설명하는 feature의 개수는 이보다 훨씬 많은 경우가 많다. 예를 들어 feature가 10개 정도 있고 각각이 binary라면, 제대로 모든 데이터를 설명하기 위해서는 \(2^{10}\), 약 1000개 이상의 데이터가 필요하다. 즉, 필요한 데이터의 개수가 feature 혹은 데이터의 dimension에 exponential하다. 이런 경우 그냥 Bayes rule을 사용해 분류를 하게 되면 overfitting이 되거나 데이터 자체가 부족해 제대로 된 classification을 하기 어려울 수 있다. Naïve bayes는 이런 문제를 해결하기 위해 새로운 가정을 하나 하게 된다. 바로 모든 feature들이 i.i.d.하다는 것이다. i.i.d는 independent and identically distributed의 준말로, 모든 feature들이 서로 independent하며, 같은 분포를 가진다는 의미이다. 당연히 실제로는 feature들이 서로 긴밀하게 관련되어있고 다른 분포를 가질 것이므로 이 가정은 틀린 가정이 될 수 있다. 그러나 만약 모든 feature가 i.i.d.하다고 가정하게 된다면 우리가 필요한 최소한의 데이터 개수는 feature의 개수에 exponential하게 필요한게 아니라 linear하게 필요하게 된다. 간단한 가정으로 모델의 complexity를 크게 줄일 수 있는 것이다. 때문에 Naïve Bayes 뿐 아니라 많은 모델에서 실제 데이터가 그런 분포를 보이지 않더라도 그 데이터의 분포를 특정한 형태로 가정하여 문제를 간단하게 만드는 기술을 사용한다.</p>


<p>조금 더 엄밀하게 수식을 사용해 설명을 해보자. 우리가 가지고 있는 input data 를 \(x = (x_1, \ldots, x_n)\)이라고 가정해보자. 즉 우리는 총 \(n\)개의 feature를 가지고 있다고 가정해보자 (보통 \(n\)은 데이터의 개수를 의미하지만, wikipedia의 notation을 따라가기 위하여 이 글에서도 dimension을 나타내기 위해 \(n\)을 사용하였다). 그리고 Class의 개수는 \(k\)라고 해보자. 우리의 목표는 \(p(C|x_1, \ldots, x_n) = p(C|x)\)를 구하는 것이다. 즉, 1부터 \(k\)까지의 class 중에서 가장 확률이 높은 class를 찾아내어 이를 사용해 classification을 하겠다는 것이다. Bayes rule을 알고 있으므로 이 식을 bayes rule을 사용해 전개하는 것은 간단하다.</p>


<p>$$ p(C|x) = \frac{p(C) p(x|C)}{p(x)} $$</p>


<p>이 때 분모에 있는 데이터의 확률은 normalize term이기 때문에 모든 값을 계산하고 나서 한 번에 계산하면 되므로 우리는 \(p(x,C) = p(C) p(x|C)\), 다시 말해 prior와 likelihood를 계산해야만한다. 그러나 이 값은 joint probability이므로 데이터에서부터 이 값을 알아내기 위해서는 &#8216;엄청나게 많은&#8217; 데이터가 필요하다. 구체적으로는 앞서 말한 것 처럼 dimension에 exponential하게 많은 데이터 개수를 필요로 한다. 그러나 만약 우리가 x가 모두 indepent하다고 가정한다면 간단하게 다음과 같은 식으로 나타낼 수 있다.</p>


<p>$$ p(C) p(x_1, \ldots, x_n | C) = p(C) p(x_1|C) p(x_2|C) \ldots = p(C) \prod p(x_i|C)$$</p>


<p>따라서 normalize term을 \(Z\)로 표현한다면, 우리가 구하고자 하는 최종 posterior는 \(p(C|x) = \frac{1}{Z} p(C)\prod p(x_i|C)\)로 나타낼 수 있게 된다.</p>


<h5>KNN</h5>


<p><a href="http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">K-Nearest Neighbors algorithm (KNN)</a>은 구현하기 어렵지 않으면서도 비교적 나쁘지 않은 성능을 내는 Classification Algorithm 중 하나이다. KNN은 가까운 데이터는 같은 label일 가능성이 크다고 가정하고 새로운 데이터가 들어오면, 그 데이터와 가장 가까운 k개의 데이터를 training set에서 뽑는다. 뽑은 k개의 데이터들의 label을 관측하고 그 중 가장 많은 label을 새로운 데이터의 label로 assign하는 알고리즘이다 (이런 방식을 majority voting이라고 한다). 이때 &#8216;가까움&#8217;은 Euclidean distance로 측정해도 되고, 다른 metric이나 measure를 사용해도 된다. 이때 distance 혹은 similarity를 측정하기 위해서 반드시 metric을 사용해야하는 것은 아니다. 즉, metric의 세 가지 성질을 만족하지 않는 measure일지라도 두 데이터가 얼마나 &#8216;비슷하냐&#8217;를 measure할 수 있는 measure라면 KNN에 적용할 수 있다. 아래 그림은 KNN이 어떻게 동작하는지 알 수 있는 간단한 예시이다. 아래 그림을 보면 k를 3으로 골랐을 때 초록색 데이터의 label은 빨강이 되고, k를 5로 골랐을 때는 파란색이 됨을 알 수 있다.</p>


<p><img src="/images/post/64-2.png" width="500"></p>

<p>KNN은 구현하기에도 매우 간단하고 (새로 들어온 점과 나머지 점들간의 distance를 측정한 후 sorting하기만 하면 된다) 성능도 보통 크게 나쁘지 않은 값을 보이기 때문에 간단하게 개발할 필요가 있는 경우에 많이 사용하게 된다. 사실 대부분의 머신러닝 툴박스들은 KNN의 다양한 variation까지 built-in function으로 지원한다. Matlab의 knnclassify가 대표적인 예. 또한 KNN은 <a href="http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#Properties">유용한 성질들</a>이 많이 있다. 예를 들어 만약 데이터의 개수가 거의 무한하게 있다면, KNN classifier의 error는 bayes error rate의 두 배로 bound가 된다는 특성이 있다. 즉, 데이터가 엄청나게 많다면, KNN은 상당히 좋은 error bound를 가지게 된다는 것이다. 즉, 단순한 휴리스틱 알고리즘이 아니라 엄밀하게 수학적으로 우수한 알고리즘임을 증명할 수 있는 알고리즘이라는 뜻이다. 또한 distance를 마음대로 바꿀 수 있기 때문에 KNN은 변형하기에도 간단한 편이므로 데이터에 대한 가정을 모델에 반영하여 변형하기에 간편하다는 장점이 있다.</p>


<h5>정리</h5>


<p>가장 간단하게 적용할 수 있는 세 가지 classification algorithm에 대해 훑어보았다. 개인적으로 KNN은 정말 직관적일뿐 아니라 잘 동작하는 알고리즘이기 때문에, 개인적으로 어떤 문제를 해결해야할 때 가장 먼저 이 데이터가 어느 정도 잘 분류되는지 테스트하는 용도로 애용한다. 중요한 점은, 각각의 classification algorithm이 풀려고 하는 &#8216;문제&#8217; 혹은 model은 서로 다른 가정을 가지고 있으며, 그 가정에 따라 문제를 푸는 방법이 아주 많이 바뀐다는 것이다. 즉, 어떤 새로운 classification algorithm을 만들어야 할 때는 (이는 classification 뿐 아니라 모든 알고리즘을 만들어야 할 때도 마찬가지인데) 먼저 어떤 문제를 풀어야하는지 문제를 정의해야하며, 문제를 정의하기 위해 어떤 모델을 가정해야한다는 것이다. 예를 들어 Naïve Bayes는 데이터의 각각의 feature들이 서로 i.i.d하다는 가정을 하고 있고, KNN은 &#8216;가까운&#8217; 데이터와 내가 같은 label을 가지고 있을 확률이 높다는 가정을 하고 있다. 이렇듯 Machine learning algorithm을 개발하는 일에서 가장 중요한 것은 좋은 문제를 먼저 정의하는 것에서부터 시작하는 것이 아닐까 생각한다.</p>




<h5>변경 이력</h5>


<ul>
<li>2015년 3월 25일: 글 등록</li>
</ul>


<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li><a href="/63">Convex Optimzation</a></li>
<li><a href="/64">Classification Introduction (Decision Tree, Naïve Bayes, KNN)</a></li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Ensemble Learning (Random Forest, Ada Boost)</li>
<li>Graphical Model</li>
<li><a href="/69">Clustering (K-means, Gaussian Mixture Model)</a></li>
<li><a href="/70">EM algorithm</a></li>
<li>Hidden Markov Model</li>
<li>Dimensionality Reduction (LDA, PCA)</li>
<li>Recommendation System (Matrix Completion, Collaborative Filtering)</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>Reinforcement Learning</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/86/">블룸버그 폰 인터뷰 후기</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2015-03-14T03:57:00+09:00" pubdate data-updated="true">Mar 14<span>th</span>, 2015</time>
        
         | <a href="/86/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>운이 좋게도, 교수님의 추천을 받아 블룸버그 software internship을 지원하게 되었다. 지원은 작년 12월에 하였고, 인터뷰는 1월 말부터 시간을 계속 조율하다가 오늘에서야 phone interview를 보게 되었다. 블룸버그가 뉴욕에 있다보니 현지 시간으로 2시에 면접인데 나는 새벽 3시.. 그나마 섬머타임이 실행되서 3시였지 안그랬으면 4시였다. 늦은 시간이지만 잠깐 시간을 내서 이 여운이 사라지기 전에 기록을 남겨볼까 한다.</p>


<p>먼저 phone interview는 생각보다도 더 어렵다. 일단 전화라는게 상대방의 말을 명료하게 전달해주지 못하는게 문제가 된다. 안그래도 긴장해서 영어가 잘 안들리는 상황에서 전화 연결 상황까지 안좋으니 더더더 긴장할 수 밖에 없었다. 하지만 이런 상황에도 못알아들었으면 당당하게 다시 말해달라고 하면 인터뷰어가 친절하게 대답해주니까 너무 겁먹을 필요는 없더라. 그리고 내가 phone interview에서 코딩을 위해 사용한 <a href="https://www.hackerrank.com/">HackerRank</a>라는 녀석이 구글 독스처럼 서로 글씨를 적으면 바로바로 상대방이 볼 수 있는 방식이라 말을 하면서 동시에 타이핑을 하는 것으로 충분히 내 부족한 영어를 메꿀 수도 있었다.</p>


<p>맨 처음 전화를 받고나서는 내 resume를 기반으로 몇 가지 질문들이 들어왔다. 너 이런 연구했는데 이거에 대해서 간단하게 설명할 수 있니? 여기에서 한 work은 어떤 work이니? 이 회사에서 일할 때 어떤 일들을 했니? 등의 질문들이었는데 아무래도 내 영어가 길지 못해 충분히 설명하지 못한게 아쉬운 요소였다. 시간을 재본건 아닌데 대충 10분 정도 레쥬메 스캔을 한 것 같다.</p>


<p>레쥬메 스캔이 끝나자마자 바로 코딩 문제로 넘어갔다. 여러 언어를 사용할 수 있는 것 같던데, 나는 Python을 사용해서 코딩을 했다. 내가 가장 멋진 코드를 쓸 수 있는건 (당연히 MATLAB을 제외하면) Ruby이지만, 내가 Ruby를 손에 안잡은지 너무 오래되었기 때문에 그나마 최근에도 가끔 사용하는 Python을 쓰기로 했다. C나 JAVA보다는 Python이 내 장점을 어필하기에 그나마 조금 나을 것 같아서. 그리고 사실 C랑 자바도 까먹었다. 질문은 두 가지 였는데, 하나는 여러 개의 list를 intersection하는 function을 짜라는 문제였고, 또 하나는 캐시를 구현하는거였다. 첫 번째 문제를 듣자마자 그간 코딩을 게을리한 것을 후회하게 되더라. 분명 어렵지 않은 문제인데 갑자기 코딩을 하려니 좋은 방법이 잘 떠오르지 않더라. 구글링을 하면 간단하게 해결할 수 있는 문제지만 그럴 수 있는 상황은 아니니까. 두 번째 문제는 듣자마자 OS에서 배웠던 내용이라 기뻐했는데 막상 어떤 데이터스트럭쳐를 사용해서 어떻게 빠르게 할 수 있는지 설명하려니까 그냥 딕셔너리를 써서 sorting한다는 대답 밖에 할 수 없었다.</p>


<p>첫 번째 문제를 정확하게 기술해보면 Input list들은 [ [1,2,3,&#8230;], [2,3,4,&#8230;], [5,6,7,&#8230;], &#8230; ] 처럼 생긴 list of list로 들어오고, output은 그 list들의 intersection을 구하는 문제였다. 내가 제안한 방법은 functional language 처럼 문제를 푸는 방법이었다. 먼저 두 개의 list를 비교하는 function을 만들고, 그것을 reduce했다. 대략 아래와 같은 느낌</p>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>f = lambda x,y : [a for a in x if a in y]
</span><span class='line'>print reduce(f,L)</span></code></pre></td></tr></table></div></figure>


<p>코드 퀄리티는 아주 만족한다. 처음에 문제를 듣자마자 그냥 for loop으로 일단 돌아가게만 다 풀어버릴까 고민도 했었는데 그래도 그것보다는 이게 훨씬 아름답고 functional한 철학에도 맞고 여러모로 내가 추구하는 이상적인 코드에 가깝다. 문제는 여기까지 가는데에 시간이 너무 오래걸렸다는 것. 처음에 열심히 헤메느라 점수 다 까먹었을 것 같다. List comprehension을 사용하면 Lambda를 금방 정의할 수 있는데 그 생각을 못해서 for loop으로 naive한 것을 먼저 만들고 그걸 lambda로 넣으려고 하고 막 그랬는데.. 암튼 좀 헤메다가 위 처럼 문제를 해결했다. 그런데 저 List comprehension도 내가 naive way라면서 일단 element wise로 다 비교해보자고 하면서 넣은거라 interviewer가 내가 코딩을 끝내자마자 바로 이 방법을 더 좋게 만들 수 없는지 물어보더라. Sorting이 되어있냐고 물어보고, 되어있지 않다고 하길래 일단 각각을 sorting했다고 가정하고 filter를 사용해서 개선할 수 있다고 하고 내가 코드를 적으려고 했는데 시간이 부족하다면서 (이미 여기에서부터 15분 남음) 스킵하고 넘어갔다. 내가 적고 싶었던 솔루션은 아래와 같았다. 진짜 잘 동작하는지모르고, complexity가 진짜 더 낮은지 생각해봐야함. 근데 아마 O(n)이 O(log n)이 되어서 더 빠를거임.</p>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>for l in L:
</span><span class='line'>  l = sort(l)
</span><span class='line'>f = lambda x,y : [a for a in x if a in filter(lambda b : b &gt;= a, y)]
</span><span class='line'>print reduce(f,L)</span></code></pre></td></tr></table></div></figure>


<p>사실 for loop쓴 sorting도 한 줄에 쓸 수 있을 것 같지만 귀찮으니까 넘어가야지. 으 딱 15초만 더 줬으면 바로 타이핑해서 보여줬을텐데. 시간이 많이 부족하다그래서 그냥 넘어갔다.</p>


<p>두 번째 문제는 input이 어떻게 생겼는지 물어보다가 대답이 내가 원하는 대답이 아니라 그냥 내가 stream을 새로 정의했다. S = [1,2,3,4,1,2,1,4,2,1,&#8230;] 같은 list로 들어온다고 가정하고, 내가 할 일은 이 리스트를 앞에서부터 읽으면서 캐쉬에 넣다가, 캐쉬 메모리가 모자라면 가장 오래 전에 마지막으로 사용된 element를 drop하는 algorithm을 짜는거였다. 이런 초 쉬운걸 기억이 안나서&#8230; 일단 내 대답은 dictionary를 만드는거였다. 참고로 이 문제는 시간이 없어서 말로 때움. 스트림별로 key를 가지는 dictionary를 만들고 value는 키에 해당하는 스트림이 들어왔을 때의 시간 값을 넣는다. 그리고 메모리가 모자라면 dictionary를 보고 가장 오래된 시간을 쓰는 녀석을 지워낸다.. 가 내 솔루션이었는데, 가장 오래된 녀석을 찾는게 log라서 그걸 더 빠르게 할 수 없냐는 질문이 들어왔음. (구체적으로 log라고 한건 아니고, 그때그때 찾는게 비싸니까 더 빠르게 할 수 없냐는 질문) 내가 기억하는 O(1)짜리 data structure가 큐랑 스택 밖에 없어서 그걸 사용해서 막 삽질을 하다가 결국 시간도 모자라고해서 거기에서 멈췄다. 솔직히 이건 시간 더 줬어도 내가 명석하게 해결하지 못했을 듯 ㅠㅠ 이런거 안한지 너무 오래됐다..</p>


<p>마지막에 다 끝나고 질문있냐 물어봐서 블룸버그에서 어떤 언어를 쓰냐 물어봤더니 팀마다 다르단다. 본인은 팀에서 C++랑 Javascript를 사용한다고. 파이썬이나 루비를 사용하는 팀도 있다고 한다. 사실 내가 지금 software internship으로 들어가게 되면 도대체 어떤 position으로 들어가게 되는건지 알 수가 없어서 (pure developer인지 researcher인지 어느 정도 level로 코딩하는지..) 내가 어떤 언어를 쓰게 될지는 모르겠지만, 최소한 내가 가서 고를 수 있는 일말의 여지가 있다면 내가 최대한 잘 할 수 있는 팀으로 배정되면 된다는 결론을 내릴 수 있었다. 뭐 될지는 모르겠지만. 결과는 2~3주 뒤에 나온다고 했으니 또 막 메일 왔다갔다하다보면 한 달 예상해본다. Optimal case라면 2주 뒤인 3월 말에 ICML 리뷰를 보고 결과도 대충 알 수 있을거고 블룸버그 결과도 같이 나오는 셈이다. 이번에는 좀 좋은 결과가 있었으면 좋겠는데..</p>


<p>사실 크게 별 생각안하고 코딩하면서 떨지만 않게 적당히 인터넷에서 <a href="https://sites.google.com/site/steveyegge2/five-essential-phone-screen-questions">코딩 인터뷰 관련 글</a>이나 <a href="http://www.bogotobogo.com/python/python_interview_questions.php">문제들</a> 푸는 정도로 몸풀고 인터뷰를 봤는데 굉장히 좋은 경험이 되었다. 영어로 official software engineer job recuiting phone interview라니, 정말 중요한 경험인데 굉장히 어린 나이에 운좋게 경험할 수 있었다. 무엇보다 학위를 마치고 장래에 미국에서 job을 구할 생각을 하고 있는 상황에서 이런 좋은 회사와 phone interview 과정을 겪어보는 것만으로도 진짜 좋은 경험이 되었다. 가서 일을 해보면 훨씬 더 좋은 경험이 될 것 같지만, 그건 내가 결정하는게 아니니 일단은 두고 봐야겠지.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/85/">2015년 02월 27일 새벽 5시 반</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2015-02-27T05:34:00+09:00" pubdate data-updated="true">Feb 27<span>th</span>, 2015</time>
        
         | <a href="/85/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>2월 6일. 드디어 짧게 보면 반 년 넘게, 길게 보면 1년이 넘게 진행해온 연구로 논문을 제출했다. 제출한 학회는 ICML. 처음으로 쓰는 논문이고, 처음으로 내가 1저자가 되어 제출하는 논문인데 처음부터 너무 좋은 학회에 제출하게 되었다. 여러모로 운이 좋았다. Author feedback period는 3월 말이나 되어야하고, 최종 decision notification은 4월 25일이다. 만약 accept이 된다면 7월에 프랑스 Lille에서 내 연구를 수 많은 사람들 앞에서 발표하게 된다. 아직 결과가 나오려면 2달 가까이 남았기 때문에 연구에 대한 압박감은 많이 사라졌다. 다만, 추가적으로 더 해보고 싶은 것들이 있어 추가 실험이나 앞으로 시도해볼 분야의 review paper를 읽어야 하는데, 쉽사리 의욕이 나지 않는다.</p>


<p>Paper를 제출하고, 약 2주 반 정도의 휴가를 다녀왔다. 원래는 블로그에 ML study 포스트도 하루에 한 개씩 올리고, 책도 많이 읽고 Machine Learning 공부를 처음부터 천천히 할 수 있는 가장 좋은 시기라고 생각했었는데, 중간에 설 연휴도 있었고 잠깐 외국도 다녀오고 하니까 그럴 수 있는 시간이 하나도 없었다. 아마 머신러닝 공부, 그리고 관련 포스팅은 전부 학기 중에 수업도 들으면서 동시에 진행하게 될 것 같다.</p>


<p>쉬는 것에도 관성이 있는 것 같다. 어제 다시 학교로 돌아왔는데 아직까지 하루 종일 일이 손에 잡히지 않는다.</p>


<p>1월부터 2월초까지는 논문을 쓰는 것에 내 모든 역량을 쏟아부었다. 그래서 그런지 나에게는 이번 겨울이 너무나 짧게 느껴진다. 논문 쓰느라 한참 바쁘게 지내고 잠깐 외국다녀오니 겨울이 끝나있었다. 마찬가지로 2015년도 너무 급작스럽게 찾아왔다. 벌써 3월을 눈 앞에 두고있다니. 남들은 연말에 하거나 연초에 하는 2015년 계획을 오늘에서야 세우게 되었다. 사실 올해 목표 예년과 크게 다르지 않다. 올해 목표는 딱 두 가지인데, 하나는 체중 감량이고 또 하나는 제2외국어 공부이다. 체중감량은 워낙 오래전부터 내세우던 목표이고 제대로 성공한 적이 한 번도 없기 때문에 이번에는 정말 제대로 해봐야겠다. 혼자 계속 운동하다가 정체기가 오는 것 같으면 바로 PT를 받아볼 생각이다. 바로 PT를 받기에는 학교 헬스장이 워낙 시설이 좋아서 돈이 조금 아깝다. 그리고 내가 운동이나 식이요법을 &#8216;몰라서&#8217; 못하는게 아니라 귀찮거나 의지가 부족해서 안하는 것이기 때문에 의지가 부족해졌다고 느낄 때 쯤에 PT를 받아야겠다. 제2외국어공부는 여러가지를 생각해보았으나 역시 내가 빠른 시간에 금방 배울 수 있는 언어는 일본어이다. 오늘 저녁 먹기 전에 학원에 가서 상담받고 등록해야겠다.</p>


<p>한 번 연구를 해보니까 자신감이 생기기도 하지만 반대로 내가 이런 작업을 또 해낼 수 있을까 두렵기도 하다. 다행히 지금 나는 해야 할 일이 명확하니 내가 해야 할 일에 최선을 다해야겠다.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/82/">블로그에 Disqus 설치</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-12-13T04:58:00+09:00" pubdate data-updated="true">Dec 13<span>th</span>, 2014</time>
        
         | <a href="/82/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>예전부터 블로그 댓글 기능을 제대로 만들어야겠다는 생각을 늘 하고 있었는데, 갑자기 삘이 꽂혀서 disqus를 설치했다. 아예 생각난 김에 트윗이나 라이크 버튼도 기능 테스트를 더 해볼까 싶었는데 그건 그냥 귀찮아서 스킵하기로 했다.</p>


<p>사용 방법은 심플하다. <a href="http://www.disqus.com">http://www.disqus.com</a> 에 접속해서 아이디 만들고, 새로 disqus 하나 만든 다음에, 옥토프레스 _config.yml에 disqus short name만 넣어주면 된다.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/81/">맥 요세미티 업데이트 이후 Homebrew 문제점 Troubleshooting</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-11-30T03:24:00+09:00" pubdate data-updated="true">Nov 30<span>th</span>, 2014</time>
        
         | <a href="/81/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>나는 맥 OS 장비가 두 개 있다. 하나는 연구실에서 사용하는 아이맥이고 또 하나는 연구실 밖에서 사용하는 맥북프로이다. 이번 요세미티 업데이트는 프리뷰 때 부터 기대를 많이 했기에 나오자마자 바로 두 머신 모두 요세미티 설치를 했다. 그리고 그게 내가 이 글을 쓰게 된 시발점이 되었다.</p>


<p>Homebrew는 맥에서 가장 많이 사용하는 패키지 관리 프로그램 중 하나로, 간단히 생각하면 ubuntu의 apt-get과 같은 역할을 (더 fancy하게!) 해준다. 그런데 문제는 이 녀석이 ruby base로 돌아가고, ruby path가 하드코딩되어있는데, 요세미티는 system ruby의 버전을 강제로 업그레이드시켜버리기 때문에 brew의 모든 명령이 깨진다는 것. 참고로 이건 예전 버전의 homebrew에서나 그렇고, 새로 나온 버전은 아무 문제가 없다.</p>


<p>가장 간단한 해결책은 임시로 brew.rb 파일에 있는 path를 current ruby로 바꿔준 다음 brew를 최신 버전으로 다시 내려받는 것이다. 하지만 늘 인생은 쉽지 않지. 쉬운 길을 눈 앞에 두고 돌아가기 마련인데, 두 머신 모두 (약간의 시간 차이를 두고 한 일이지만) brew를 삭제하고, 다시 설치한다음 rvm으로 ruby 버전을 다시 다운로드 받는&#8230; 삽질을 했다.</p>


<p>그런데 이번에 rvm으로 루비 버전을 먼저 내려받다가, brew가 깨져있는 상황에서 실수로 지금 이미 있는 루비조차 날려버리는 최악의 실수를 해버렸다. 다시 말해 ruby 를 입력해도 아무 반응이 없고, rvm list는 비어있는 최악의 상황. 먼저 rvm install 2.0.0 을 실행했는데, 컴파일이 거의 한 시간 정도의 긴 시간이 지나도 끝나지를 않아 찾아보니 xcode 버전이 낮으면 그럴 수 있다더라. 다시 내 xcode를 보니 5버전.. 최신은 6버전이다. 바로 xcode부터 재설치를 했다. 근데 xcode가 보통 무거워야지.. 설치하는데 시간이 꽤 걸렸다.</p>


<p>xcode 재설치를 끝내고 homebrew를 설치하려고 보니 ruby 명령어를 실행해야하는터라, 강제로 system ruby path에 들어가 system ruby로 실행을 시켰다. brew를 제대로 지우지 않은 상황이라면 시키는대로 하면 된다. 설치 후에는 brew doctor 한 번 돌려줘야한다. 꼬여있는 dependency를 정리해야하기 때문.</p>


<p>이제 rvm install 2.0.0, rvm install 1.9.3, rvm install 2.1.5 모두 잘 실행된다. (라고 적었지만 사실 1.9.3은 gcc48설치하는게 너무 오래 걸려서 아직 끝은 안난게 함정&#8230;)</p>


<p>Gitlab도 그렇고, 지금 쓰고 있는 Octopress도 그렇고, 많은 웹에서 쓰는 프레임워크 혹은 어플리케이션들이 rails 기반, 루비 기반인 경우가 많아 이런 문제가 왕왕 생기고는 하는데, 당황하지 않고 천천히 찾아보면 해결하는게 크게 어렵지는 않다. 루비는 sudo user로 설치하는게 아니다보니까 더 쉬운 듯. 가장 중요한건 인내심을 가지는 것. 너무 이상할 정도로 오래걸리는건 생각해볼 필요가 있지만, 대부분의 경우 생각보다 시간이 훨씬 오래 걸린다.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/80/">Gitlab을 깔자</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-11-20T03:05:00+09:00" pubdate data-updated="true">Nov 20<span>th</span>, 2014</time>
        
         | <a href="/80/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>버전관리의 중요성은 몇 번을 강조해도 부족하지 않다. 버전관리를 하기 위한 여러 도구들이 존재하지만, 난 분산 버전 관리 (DVCS) 를 좋아한다. Mercurial 로 처음 버전관리를 공부했고, 지금은 주로 Github에 소스를 올리기 때문에 git 을 많이 쓰고 있다. 콘솔에서는 큰 차이가 있지만, 정작 둘 다 <a href="http://www.sourcetreeapp.com/">SourceTree</a>로만 관리하기 때문에.. 예전에는 맥버전만 있었지만, 이제는 윈도우 버전도 생겨서 다른 사람들도 용이하게 쓸 수 있다. 이런 이유로 최근에는 거의 모든 레포지토리를 git 레포지토리로 만들게 되는데, 연구실에서 내가 쓰고 있는 논문이나 프로젝트용 코드 같은 경우는 공개된 레포지토리로 올려도 곤란하고, 연구실 단위로 관리를 해야할 필요를 느껴서 <a href="https://about.gitlab.com/">GitLab</a>이라는 놈을 깔아보기로 헀다.</p>


<p>Gitlab을 한 마디로 요약하자면 &#8216;개인용 github&#8217; 라고 할 수 있다. 코드를 훑어보니 rails 기반에 nginx를 서버로 사용하고 있어서 내가 친숙한 환경이기도 해서 좋더라. 늘 깔아야지 깔아야지했는데 이게 생각보다 설치가 머리가 아파서.. 나중에 시간이 넉넉해지면 설치하려 했으나 어쩌다보니 갑작스럽게 설치를 하게 되었다.</p>


<p>내 설치환경은 Ubuntu 14.04, <a href="https://about.gitlab.com/downloads/">다운로드 페이지</a>에서 ubuntu 14.04를 선택하는 아래와 같은 명령어를 실행하면 알아서 옴니버스 버전을 깔아준다고 한다.</p>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wget https://downloads-packages.s3.amazonaws.com/ubuntu-14.04/gitlab_7.4.3-omnibus.5.1.0.ci-1_amd64.deb
</span><span class='line'>sudo apt-get install openssh-server
</span><span class='line'>sudo apt-get install postfix # Select 'Internet Site', using sendmail instead also works, exim has problems
</span><span class='line'>sudo dpkg -i gitlab_7.4.3-omnibus.5.1.0.ci-1_amd64.deb</span></code></pre></td></tr></table></div></figure>


<p>난 openssh-server, postfix는 깔려있으니 생략했다.</p>


<p>다음으로는 <code>sudo vim /etc/gitlab/gitlab.rb</code> 를 실행해 <code>gitlab.rb</code> 를 수정해야한다. 다시 한 번 말하지만, gitlab은 rails로 돌아가기 떄문에 rails setting 을 해줘야한다. 원래 레일즈 프로젝트의 설정을 바꾸기 위해서는 yml 파일이나 다른 rb 파일들을 직접 수정해주어야하는데, gitlab 옴니버스 버전에서는 친절하게 이 루비 파일 하나만 바꾸면, 알아서 yml 등을 generate해준다. 아 편하고 좋다! 라고 생각했지만 이것이 그 모든 재앙의 시작이었다..</p>


<p>편하게 해주려고 만든 ruby setting 파일이 왜 문제가 되었느냐, 사실 이 대부분은 문제가 생기지 않는다. 예를 들어서 <code>www.example.com</code> 이라는 도메인을 가지고 있고, gitlab 의 접속 경로를 <code>gitlab.example.com</code> 으로 사용한다면 옴니버스 버전을 바로 사용하면 된다. 하지만 내가 사용하는 서버는 학교 도메인에서 서브도메인을 받아서 사용하기 때문에 <code>sanghyuk.kaist.ac.kr</code> 이런 식의 도메인을 가지고 있다. 따라서 위와 같은 경로를 취하게 되면 <code>gitlab.sanghyuk.kaist.ac.kr</code> 이라는 기괴한 경로가 생기게 되고, 당연하지만 이런 경로는 허용되지 않는다. 따라서 <code>sanghyuk.kaist.ac.kr/gitlab</code> 같은 relative domain을 사용해야한다. nginx에서 이런 서브 도메인을 루트로 삼는 것은 규칙에 위반되지만 사용하는 것이 가능하긴하다. rails에서도 root url을 relative url로 바꾸고 하면 돌릴 수 있지만.. 이건 내가 rails파일을 직접 바꿀 때 얘기였다.</p>


<p>옴니버스 버전에서 이런저런 삽질을 하다가 찾아낸 이슈.. <a href="https://gitlab.com/gitlab-org/omnibus-gitlab/issues/238">옴니버전에서는 Relative URL root를 지원할 계획이 없다</a> 아&#8230; <code>gitlab.rb</code> 에서 삽질을 하고 있었는데 다 쓸데 없는 짓에 불과했던 것이다.</p>


<p>그래서 relative url은 포기하고 다른 쪽으로 알아보니 포트를 바꿔서 접속을 하는 방법이 있더라. 이건 그나마 훨씬 할 만 헀다. <code>/etc/gitlab/gitlab.rb</code> 에서 다음과 같이 설정해준다.</p>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>external_url = 'http://sanghyuk.kaist.ac.kr:1234'</span></code></pre></td></tr></table></div></figure>


<p>아 참고로, 내가 깐 버전은 = 을 안쓰면 에러가 나서 내가 = 을 따로 넣어줬다. 옴니버스 버전별로 다른 모양</p>


<p>이렇게 하고 <code>sudo gitlab-ctl reconfigure</code> 을 실행시켜서 yml 등을 자동으로 generate시키기만 하면 문제 해결! &#8230; 이 아니었다. 아예 접속 자체가 되지를 않아서 이제 여기에서 다시 삽질을 시작했는데, 먼저 netstat으로 포트는 열려있나 봤다. 안타깝게도 아예 포트가 열려있지도 않았다. 돌아버리겠는건 <code>gitlab-ctl status</code> 에서는 잘 실행되는 것으로 나오는 것.</p>


<p>이제 또 한참 삽질을 하다가, 아예 nginx 조차 돌아가는 것 같지 않아서 nginx 세팅을 수동으로 뜯어고치기로 결정했다. 이게 상당히 위험한 짓인데, 나중에 내가 생각없이 또 reconfigure를 때리면 내가 고친 파일들이 새로운 파일들로 덮어씌일 것이기 때문이다. 때문에 이렇게 설정을 시작한다면 reconfigure 대신 <code>gitlab-ctl restart</code> 로 configure 파일을 다시 생성시키지 말고 레일즈랑 nginx 등만 내렸다가 올려야한다. 이제 세팅을 바꿔보자.</p>


<p>가장 먼저 nginx 설정을 찾아봤다. <code>/var/opt/gitlab/nginx/conf/gitlab-http.conf</code> 에 설정 파일이 있는데, listen과 server name이 엉망으로 되어있더라. 당연히 nginx가 설정이 잘못되었으니 서버에 접속도 못하고 포트도 안열려 있던 것. 이 둘을 제대로 바꿔주고 restart를 했다.</p>


<p>드디어 &#8216;페이지를 찾을 수 없습니다&#8217; 창말고 다른 창을 볼 수 있었다. 그러나 여기에서 또 502 에러가 발생했는데, 아마도 내부 rails가 제대로 올라오지 않은 모양인가보다. 그래서 혹시 레일즈 세팅도 이상한가 싶어서 yml 파일을 찾아봤다.</p>


<p><code>/var/opt/gitlab/gitlab-rails/etc/gitlab.yml</code> 을 열어봤더니 여기도 host랑 port가 엉망이었다. 이 부분을 바꿔주고 나서 다시 <code>sudo gitlab-ctl restart</code></p>


<p>아 드디어 잘 실행된다. 기존에 쓰던 다른 레포지토리를 추가해주기 위해서 <a href="http://git-scm.com/book/ko/v1/Git%EC%9D%98-%EA%B8%B0%EC%B4%88-%EB%A6%AC%EB%AA%A8%ED%8A%B8-%EC%A0%80%EC%9E%A5%EC%86%8C">remote</a>를 해주려고 보니 ssh key를 생성해서 넣어줘야 하더라. 이건 <a href="http://git-scm.com/book/ko/v1/Git-%EC%84%9C%EB%B2%84-SSH-%EA%B3%B5%EA%B0%9C%ED%82%A4-%EB%A7%8C%EB%93%A4%EA%B8%B0">이 글</a>을 보면 된다. 이건 예전에 다 등록해뒀던거라서 금방금방했다. 조금 가지고 놀아보니 아직까지는 매우 만족스럽다.</p>


<p>이렇게 일단 주먹구구식으로 깃랩을 돌리는 것에는 성공했지만, 아직 reconfigure를 함부로 하면 안된다. 내가 바꾼 <code>/var/opt/gitlab/gitlab-rails/etc/gitlab.yml</code>, <code>/var/opt/gitlab/nginx/conf/gitlab-http.conf</code> 는 <code>gitlab-ctl reconfigure</code> 를 할 때 자동으로 generate 되는 파일이다. 따라서 내가 바꾼 설정이 저장이 되지 않기 때문에 함부로 reconfigure를 했다가는&#8230; 나중에 시간이 나면 이 부분을 gitlab.rb 만 바꿔서 수정할 수 있는지 알아보자.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/79/">새로운 Front Framework Webplate에 대한 소견</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-10-10T02:30:00+09:00" pubdate data-updated="true">Oct 10<span>th</span>, 2014</time>
        
         | <a href="/79/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>얼마전 <a href="http://getwebplate.com/">Webplate</a>라는 front-end framework를 접하게 되었는데 상당히 좋은 인상을 받아서 블로그에 소개 겸 사용 소감을 남겨보려 한다.</p>


<p>그 동안 내가 웹을 개발하면서 느꼈던 가장 불편한 점은, 디자이너가 없이는 내가 할 수 있는 것들이 상당히 제한된다는 것이었다. 그러던 와중에 <a href="http://getbootstrap.com/">twitter bootstrap</a>을 알게 되었고, 덕분에 상당히 많은 웹 페이지들을 만들 수 있었다. 이 블로그도 그렇고, 내 aboutMe 페이지도 그렇고 홈페이지도 그렇고 요즘 만들고 있는 연구실 홈페이지도 그렇고.</p>


<p>하지만 bootstrap을 사용하면서 불편한 점이 없는건 아니었다. Bootstrap은 매우 훌륭한 디자인 가이드를 제공하고 있기는 하지만, 결국 기본적인 웹 frame조차 내가 처음부터 html 코딩을 해야하는 점은 매우 귀찮은 일이 아닐 수 없었다. 지금은 이것에 어느 정도 익숙해지고 내가 내 나름의 template을 가지게 되었지만 그 이전에는 html부터 코딩을 하는 것이 여간 귀찮은 일이 아니었다. 특히 aboutMe만들 때 생각하면&#8230; 정말 끝없이 고치고 또 고쳤던 기억이 난다.</p>


<p>그러던 와중 webplate를 보게 되었는데, 처음 본 순간 정말 센세이션이었다. 마침 <a href="https://github.com/chrishumboldt/webplate">github</a>도 있길래 fork해서 한 10분 정도 둘러봤는데,</p>


<ol>
<li>Twitter Bootstrap과 비교를 하지 않을 수 없는데, 사실 Webplate에서 가능한건 Bootstrap에서도 다 가능할 뿐 아니라 자유도 역시 Bootstrap이 더 좋다. 하지만 Bootstrap에서는 내가 다 구현을 했어야했던 것들이 Webplate에서는 구현이 되어있다는 것이 좋은 듯. 
한 마디로 Bootstrap은 style에 대한 기본 base느낌이라면 Webplate는 진짜 front framework다</li>
<li>비록 내가 따로 설정을 해줘야하지만, example project에서 기본 글씨체를 Lato로 강제해서 참 좋다. Open Sans 애리얼 헬베티카 꺼졍&#8230;</li>
<li>다시 framework에 대한 얘기인데, pre태그 에서 코드 이쁘게 보여주는 기능을 class로 부르기만 하면 되게 구현이 되어있어서 짱짱 편하다. 내가 라이브러리 찾아서 부를 수도 있지만 귀찮으니까&#8230; </li>
<li>기본적으로 필요한 대부분의 라이브러리가 포함되어있다. response.js를 포함해서! 때문에 반응형으로 만들기도 편하고 호환에 대한 두려움 없이 작업을 하는게 가능하지만 ie에서 완전 호환이 되는지 잘 모르겠다. (아마 되겠지)</li>
<li>이 framework 자체가 vertical UI를 강제하고 있다. 최근 핫한 UI이기는 하지만 (stripe UI같은거) 다른 모양을 원하는 경우에는, 특히 상단 바가 아니라 좌측에 메뉴를 넣고 싶은 경우라면 이 framework을 쓰는게 아니라 따로 만들어야할 것 같다. (하지만 요즘 모든 웹은 다 기본이 vertical UI..)</li>
<li>Service, Product 등의 introduction page를 간단하게 만들 생각이라면 이보다 더 Cool한 web framework는 없어보인다. (전시회 소개나 festival page로도 좋을 것 같네) 그 이외에 어떤 곳에서 이 framework를 사용할 수 있을지 아직은 잘 모르겠다. Vertical UI를 쓸 수 있는 곳이라면 전부 쓸 수 있을 것 같기는 하다.</li>
</ol>


<p>한 마디로 간단하게 만들 수 있는 웹은 이 녀석으로 대략 커버가 가능하다는 점, 그리고 반응형에 대한 이슈를 내가 따로 고민할 필요가 없다는 점이 너무 마음에 들었다. <a href="http://getwebplate.com/documentation">Document</a>링크를 첨부할테니 관심있는 사람들은 한 번 읽어봤으면 좋겠다. 최근 이걸 사용해 따로 개발할 웹이 없어서 정작 내가 사용해볼 수가 없다는게 아쉽기는하다.</p>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/77/">모바일 시대 Platform에 대한 고찰</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-10-10T02:27:00+09:00" pubdate data-updated="true">Oct 10<span>th</span>, 2014</time>
        
         | <a href="/77/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>얼마 전 MS에서 윈도우10의 preview를 발표하였다. <a href="http://www.bloter.net/archives/208421">블로터 기사</a>를 참고하면 알 수 있 듯, 아직 테크니컬 프리뷰 단계이기는 하지만 MS가 어떤 철학을 가지고 이런 운영체제를 디자인했는가는 어렵지 않게 예상할 수 있다. 스마트폰과 태블릿 데스크톱 그리고 콘솔 등에 이르는 수 많은 isolate 되어있는 기기들을 통합으로 관리할 수 있는 하나의 거대한 통합 플랫폼을 만들어내겠다라는 의지가 바로 그것이다. <a class="red tip" title="소문에 의하면 95,98 버전 확인을 windows 9가 포함이 되었느냐 아니냐로 하기 떄문이라고.">왜 8다음에 10이냐는 이슈는 넘어가고</a> 과연 MS의 이런 행보가 어떤 파장을 일으킬 수 있을지에 대해 생각해보고 싶어졌다.</p>


<h5>모바일 모바일 모바일</h5>


<p>그래 바야흐로 모바일의 시대가 도래하였다고 해도 과언이 아니다. 내 블로그에 붙여놓은 google analytics를 보니까 내 블로그는 PC가 약 75%, 모바일이 약 18%, 그리고 태블릿이 약 7% 정도의 접속률을 보이고 있다. 즉, 내 블로그를 읽는 사람들의 행동 양식만 보고 비교를 하자면 아직은 PC로 웹을 보는 사람들이 모바일이나 태블릿 (합쳐서 모바일이라 하자) 으로 웹을 보는 사람들에 비해 약 5배 정도 많다. 그러나 이것은 내 블로그가 특수한 환경에 처한 것이고 (대부분의 유입이 구글 검색이고 키워드가 머신러닝이니까..) 실제 전체 웹을 보게 되면 상황이 많이 달라진다. StatCounter의 <a href="http://gs.statcounter.com/#all-comparison-ww-monthly-201309-201409">global stats page</a>를 참고해보면 모바일의 비중이 거의 30% 가까이를 차지하고 있으며, 태블릿까지 포함하면 약 37~8% 정도에 육박한다는 사실을 알 수 있다.</p>


<p><img src="/images/post/77-1.png" width="500"></p>

<p>이 속도가 엄청나게 빠르게 증가하고 있다는 사실이 바로 그것인데, 불과 1년 사이에 모바일 뷰가 17%에서 거의 30%까지 증가한 것이다. 거의 75% 가까이 증가한 셈이다. 지역을 한국으로 좁혀서 보게 되면 (<a href="http://gs.statcounter.com/#all-comparison-KR-monthly-201309-201409">링크</a>) 우리는 상대적으로 태블릿의 점유율은 엄청 낮은 대신, 모바일의 비중이 매우 높다는 것을 알 수 있다.</p>


<p><img src="/images/post/77-2.png" width="500"></p>

<p>그리고 어느 정도 1년 동안의 변화 정도가 일정한 것을 알 수 있다. 경험적으로 비춰보았을 때, PC를 거의 사용하지 않고 모바일로만 보는 사람들이 그만큼 많아졌다는 뜻이 아닐까라고 생각된다.</p>


<p>그리고 또 이렇게 general하게 전체 웹 view만 보는 것이 아니라 큰 서비스로 시선을 돌리면 또 얘기가 달라진다. <a href="http://www.nasmedia.co.kr/">나스미디어</a>의 <a href="http://lib.nasmedia.co.kr/file/534f5d4242381">2014년 NPR (Netizen Profile Research)</a> 에 의하면, PC 인터넷 이용자의 스마트폰 이용률이 현재 88.1%에 육박하며 이는 전년 대비 11.5% 상승한 결과라고 한다. 그리고 사실 정말 재미있는 지표는 11쪽에 있는 SNS 접속 디바이스인데, 싸이, 미투, 구글플러스와 같은 마이너한 서비스는 제외하고 (심지어 미투데이는 올해 서비스를 종로했다 ㅠㅠ) 아래에서 볼 수 있듯 모바일의 비중이 매우 높다는 것을 알 수 있다.</p>


<p><img src="/images/post/77-3.png" width="600"></p>

<p>즉, 이제 모바일은 절대로 무시할 수 없는 현실이라는 것을 데이터가 보여주고 있는 것이다.</p>


<p></p>

<h5>모바일 사용자, PC 사용자</h5>


<p>그런데 내 생각에 저런 수치들이 제대로 반영하지 못하는 하나의 현실이 더 있다. 바로 극명하게 다른 PC 사용자와 모바일 사용자들의 성향이다. 모바일 사용자는 처음 몇 번의 시도 후 제대로 동작하지 않는 것 같다고 느끼면 그냥 서비스에서 이탈해버리고 다시 돌아오지 않는 경우가 많다. 즉, 이탈률이 매우 높다. 따라서 이탈을 하지 않도록 사용자에게 빠르게 지속적으로 동작을 유도해야한다. 또한 PC에 비해 모바일의 화면이 더 작아 너무 많은 정보를 한 번에 받는 것에 대해 부담을 느낀다. 마지막으로 그 둘의 역할이 많이 분리가 되었다. 간단한 검색이나 기사 읽기 등 &#8216;이건 내가 모바일로도 할 수 있겠다&#8217; 하는 일들이라면 모바일에서 처리하는 유저의 비중이 높은 반면, 복잡한 멀티프로세싱을 해야하는 경우라면 PC가 더 사용률이 높다. 다시 말해, PC와 모바일은 비슷해보일지 몰라도 자세히 보면 완전히 다른 성향을 가지고 있는 별개의 플랫폼이다. 즉, 어떤 서비스를 개발했을 때, 완전히 다른 두 개의 플랫폼에서 이 서비스를 동시에 지원할지 말아야할지 염두해두어야하며, 만약 동시에 지원하는 경우 이 작업을 꼭 PC앞에서 해야하는 강력한 motive 가 있는게 아니라면 많은 사람들은 모바일로 그 서비스를 접근하려 할 것이라는 말이다. 그게 웹이되었거나 앱이 되었거나.</p>


<h5>Mobile First</h5>


<p>Start up 쪽에서 흔히 많이 하는 말 중에 Lean Start up 이라거나, Mobile first 등의 용어가 있다. [Mobile first: <a href="http://www.lukew.com/ff/entry.asp?933">링크1</a>, <a href="http://study.gnuboard.org/wiki/read/studygroup/rwd/Mobile-First-and-RWD">링크2</a>, <a href="http://h30458.www3.hp.com/kr/ko/discover-performance/it-execs/2012/oct/1243352.html">링크3</a>], [Lean Startup: <a href="http://theleanstartup.com/">링크1</a>, <a href="http://www.jimmyrim.com/153">링크2</a>, <a href="http://platum.kr/archives/tag/%EB%A6%B0%EC%8A%A4%ED%83%80%ED%8A%B8%EC%97%85">링크3</a>]</p>


<p>Mobile first는 간단히 얘기하면 처음 시작점을 무조건 모바일에 맞춰서 시작을 하라는 의미이다. 이유는 (1) 모바일이 점점 거대해지고 있으며 (2) 모바일 개발에만 치중하면서 적은 리소스를 한 곳에 집중할 수 있을 뿐더라 (3) 모바일에 포함되는 많은 기술들이 (GPS, Multi-touch UI 등) 기존 웹에서 사용되는 javascript 기반의 PC-based Web보다 더 많은 사용자 경험을 줄 수 있기 때문이라는 것이다. 내 생각에도 지금 같은 서비스를 사용하더라도 많은 사람들이 mobile로 그 서비스를 access하는 경우가 점점 늘어나고 있으며, 만약 모바일과 웹이 있을 때 하나를 선택하라고 했을 때 모바일로 접속을 하는 사람들이 많아지고 있는 지금, 웹을 먼저 개발하기 보다는 모바일에 먼저 치중한 이후 나중에 웹으로 확장을 하는 편이 더 좋다고 생각된다. (때에 따라서는 PC 지원을 아예 하지 않는 경우도 존재한다) 하지만 Mobile first를 할 때 주의해야할 점들이 몇 가지가 있는데, 가장 중요한 것은 품질관리이다. 모바일은 아주 빠르게 변화하는 곳이기 떄문에 더 빠른 업데이트와 대응이 필수적인데, 자칫잘못했다가는 제품의 품질이 떨어지고 앱의 평점과 리뷰가 부정적인 방향으로 바뀔 수 있기 때문이다. 또한 현재 모바일 앱의 특성상 나쁜 리뷰와 별점은 추가적인 앱 다운로드에 악영향을 미친다. 따라서 이 <a href="http://h30458.www3.hp.com/kr/ko/discover-performance/it-execs/2012/oct/1243352.html">Mobile first: 링크3</a>에서 제안하는 방법은 애자일 프로세스이다. 기존의 느린 의사결정 방식으로 모바일 애플리케이션을 대해서는 안된다는 의미이다. 더 빠르고 더 기민하게 움직여야만한다. 그리고 난 그런 흐름 속에서 Mobile first가 Lean startup과의 시너지를 도모할 수 있다고 본다. 하지만 애자일을 도입해도 근본적인 제약조건이 존재하는데, (1) 작은 화면, (2) 네트워크 품질 (3) 기기의 성능 이 그것이다. 이 부분에 대해서는 뒤에 더 자세히 다뤄보도록하자.</p>


<p>Lean startup은 일종의 프로덕트 개발 방법론 중 하나인데, 애자일한 개발, 완성되지 않은 프로토타입의 시장 진출, 고객과의 긴밀한 피드백루프 구축 등으로 구성이 되어있다. 기본적인 아이디어는 waterfall 식의 느린 의사결정으로 회사를 운영하거나, 제품을 개발하지 말고, 최대한 lean하게, 혹은 애자일하게 일단 빨리 빨리 무엇을 만들어보고 시장의 반응을 보고 버리거나 다른 식으로 develop을 하라는 얘기이다. 때문에 방금 전에 언급했던 Mobile first와 상당한 시너지를 일으킬 수 있는데 기본적으로 애자일 방법론을 기반으로 하기 때문에 위에서 언급했던 빠른 대응이나 지속적인 배포를 하기에 매우 용이하며, 프로토타입 단계에서 시장에 대한 가설을 테스트할 때에도 모바일에서 먼저 가설을 테스트해보고 더 크기를 키워도 되겠다는 결정을 내리고 나서 웹이나 다른 플랫폼으로의 확장을 결정하라는 것이다. 린스타트업에 대해 파고들어가기 시작하면 너무나 많은 얘기를 해야하기 때문에 깊은 얘기는 가급적 피하도록 하겠지만, 분명 린스타트업은 모바일퍼스트와 궁합이 잘 맞는 조합임에 분명하다.</p>


<p>모바일퍼스트니, 린스타트업이니 하는 거창한 얘기를 하지 않더라도 내가 어떤 서비스를 만든다고 하면 이제는 항상 모바일에 대한 생각을 하지 않을 수 없다. 이 서비스를 지금은 모바일에서 지원할 예정이 없더라도 추후 모바일에서도 지원할지, 아니면 모바일에서만 지원할지 나중에 웹으로 확장을 할 것인지. 네이티브 앱으로 만들 것인지 아니면 웹으로 만들어서 모바일 뷰를 따로 만들 것인지. 모바일 뷰를 따로 만들 것인지 아니면 반응형으로 만들어서 하나의 통합 url로 관리를 하게 할 것인지. 이 모든 것들을 반드시 처음에 한 번 쯤은 생각을 해야만 한다.</p>


<h5>모바일의 제약조건</h5>


<p>그런데 모바일이 만능 키인 것은 아니다. 모바일은 근본적으로 하드웨어에서부터 기인하는 여러 문제점들을 떠안고 있기 때문이다. (1) 작은 화면 (2) 모바일 네트워크 (3) 기기의 성능이 그것이었다.</p>


<p>먼저 작은 화면은 UI적인 측면에서 엄청난 변혁을 일으켰다. 기존의 PC-based 서비스들은 (웹 기반인 경우) 처음 보이는 웹에 굉장히 많은 정보들을 넣고 사용자가 그 정보들을 알아서 고르게하는 방식을 선택했었다면, 모바일로 넘어오고 나서는 그 화면의 크기가 어마어마하게 줄었기 때문에 (간단하게 생각해보면 22인치 모니터에서 5.5인치 아이폰6플러스는 화면의 크기가 16배 차이가 난다.) 처음 보여주는 정보의 양도 제한적일 수밖에 없고 또한 UI 역시 2차원적인 UI가 아니라 스크롤이 들어가는 1차원 세로형 UI가 강제 된다. 때문에 모바일에 익숙하지 않은 상태에서 UX를 web을 만들듯 디자인을 하게 되면 사용자 입장에서는 별로 좋지 못한 UX를 경험할 수 밖에 없는 것이다. 하지만 화면이 작기 때문에 채워야하는 정보의 양도 적고, 내가 어떤 정보를 보여줘야 더 효율적일지 더 고민할 수 있는 여지가 있기 때문에 오히려 작은 화면이 더 좋은 서비스를 개발하는데에 도움이 된다는 주장도 존재한다.</p>


<p>다음으로 모바일 네트워크의 문제는 LTE로 넘어오면서 거의 해결이 되었다. 하지만 아직도 다른 국가들을 봤을 때 3G 이상의 망이 이렇게 보급이 된 곳은 많이 없고, 또한 모바일 유저는 데이터 소모에 매우 민감하기 때문에 앱을 설계할 때 네트워크 리소스에 대한 고민을 해야할 필요가 여전히 존재한다.</p>


<p>마지막으로 기기의 성능 문제가 있다. 이건 꽤나 치명적인데, Web을 생각해보자. 웹은 서버에서 모든 로직이 실행되고 사용자 컴퓨터의 성능에 좌우되는 것은 랜더링을 하는 브라우져 뿐이었다. 즉, 동적으로 무언가를 생성하는 스크립트 등의 속도가 다소 느려질 수 있는 문제를 제외하면 대부분의 속도에 관련된 문제는 서버side에서 해결해야하는 경우가 대다수였다. 하지만 모바일로 넘어오면서 얘기가 완전히 달라졌는데, 먼저 PC보다 브라우져의 성능이 크게 저하되었고, 스마트폰의 여러 리소스를 사용하는 일은 그만큼 배터리 소모를 빠르게하고 스마트폰의 성능을 저하하는 요소가 되었기 때문에 상당히 많은 부분에서 희생을 해야한다. 물론 서비스를 한다는 것 부터가 이미 서버를 사용한다는 의미가 되기 때문에 크게 문제가 없을 수도 있지만, 이는 분명 PC에 비해 어마어마한 단점이다.</p>


<h5>결론1: 모바일을 대하는 우리의 자세</h5>


<p>이제 모바일은 절대로 무시할 수 없는 거대한 공룡이 되어가고 있다. 새로운 서비스를 시작할 때 거의 99.9% 이상 모바일퍼스트를 선택해야하며 이에 따라 필연적으로 애자일방법론, 더 나아가 린스타트업을 적용해야할 필요가 있다. 그러나 근본적으로 모바일의 제약조건이 존재한다는 점은 꽤나 치명적인데, 그만큼 한 서비스를 만들 때 처음부터 모바일에 모든 리소스를 부어가며 시작할 필요가 있다는 것이다. 그리고 모바일 이외의 환경으로 확장하는 것도 항상 염두를 하며 서비스 아키텍쳐 설계를 할 때 이에 대한 문제를 항상 생각을 할 필요가 있을 것이다.</p>


<h5>결론2: 통합 플랫폼을 만드려는 MS의 행보는 어떤 결과를 가져올까</h5>


<p>앞서 설명했듯 MS는 새로운 통합 플랫폼에 대한 원대한 야망을 가지고있다. 하지만 나는 이것이 별로 효과가 없을 것이라고 생각하는데, (1) 모바일과 웹을 동시에 지원하는 것이 아니라 어차피 모바일에만 집중해야하는데 두 개를 전부 고려해서 설계를 하면 리소스가 분산이 되기 쉽다. (2) 모바일과 PC의 사용자 성향은 극도로 다르기 때문에 PC에서 주었던 경험을 모바일에서 그대로 주는 것이 항상 능사는 아니다. (3) PC와 모바일 둘 다 이미 어느정도 정형화된 경험이 존재하는데, 그 경험을 깨어가면서까지 새로운 윈도우를 사용하게할 유인요소가 보이지 않는다. 결론적으로 서비스를 만드는 입장에서 결론적으로는 모바일과 PC는 함께 가져가야할지 모르지만, 처음 시작하는 단계에서부터 반드시 같이 가져가야하는 것은 아니기 때문에 나는 윈도우10 역시 좋은 평가를 받지 못할 것이라 생각된다.</p>




<h5>References</h5>


<ul>
<li>StatCounter <a href="http://gs.statcounter.com/#all-comparison-ww-monthly-201309-201409">global stats page</a></li>
<li><a href="http://www.nasmedia.co.kr/">나스미디어</a>의 <a href="http://lib.nasmedia.co.kr/file/534f5d4242381">2014년 NPR (Netizen Profile Research)</a></li>
</ul>

</div>
  
  

<hr>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/63/">Machine Learning 스터디 (7) Convex Optimization</a></h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-09-10T06:28:00+09:00" pubdate data-updated="true">Sep 10<span>th</span>, 2014</time>
        
         | <a href="/63/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h5>들어가며</h5>


<p>Machine learning 문제를 풀다보면 Objective function을 만들고 그 objective function을 optimize 해야하는 경우가 매우 빈번하게 발생한다. 간단히 생각해서 loss function을 minimize하는 것도 optimization이다. 그렇다면 그런 optimization은 도대체 어떻게 해야하는 것일까. 여러가지 방법이 있겠지만 이번 글에서는 간단한 optimization이라는 것에 대한 컨셉을 다루고, 그 중 특수 케이스인 convex optimization에 대해 다루도록 하겠다.</p>


<h5>Optimization</h5>


<p>대부분의 Optimization은 아래와 같은 식으로 표현할 수 있을 것이다.</p>


<p>$$ \min f(x) \text{ s.t. } g(x) = c $$</p>


<p>여기에서 \(f(x), g(x)\)는 함수이다. 어떤 함수의 optimum point, 즉 그것이 최소이거나 혹은 최대인 지점을 찾는 과정을 optimization이라고 한다고 생각하면 간단할 것이다. 엄청 간단하게 생각해보면 \(f(x)\)는 loss function이고, \(g(x)\)는 일종의 constriants로 생각하면 될 것 같다. Machine learning 문제를 풀다보면 이렇게 optimization을 해야하는 일이 아주 빈번하게 발생하는데, 안타깝게도 항상 이런 function들의 optimum point를 찾을 수 있는 것은 아니다. 가장 간단하게 생각했을 때 이런 point를 찾는 방법은 미분을 하고 그 값이 0이 되는 지점을 찾는 것인데, 안타깝게도 미분 자체가 되지 않는 함수가 존재할 수도 있으며, 미분값이 0이라고 해서 반드시 극점인 것은 아니기 때문이다. (saddle point를 생각해보자.) 따라서 대부분의 경우에 이런 방법으로 극점을 구하는 것은 불가능하며, 매우매우 특수한 일부 경우에 대해서 완전한 optimum을 찾는 것이 알려져 있다. 그리고 그 경우가 바로 convex optimization이다.</p>


<h5>Convex function</h5>


<p>Convex function은 convex한 function을 의미한다. 이때 convex는 한국어로 옮기면 볼록에 가까운데, convex function은 볼록 함수라고 번역할 수 있다. Convex가 무슨 의미인지 차근차근 알아보자. 먼저 <a href="http://en.wikipedia.org/wiki/Convex_set">convex set</a>에 대해 알아보자. 어떤 set이 convex하다는 것의 의미는 그 set에 존재하는 그 어떤 점을 잡아도 그 점들 사이에 있는 모든 점들 역시 그 set에 포함되는 set을 알컬어 convex set이라고 부른다. 따라서 convex한 set을 그림으로 그리게 되면 움푹하게 파인 지점 없이 약간 동글동글한 모양을 하고 있을 것이다. 그렇다면 이제 convex function을 정의해보자. Convex function은 domain이 convex set이며, 함수는 다음과 같은 성질을 만족해야한다.</p>


<p>$$ f(\lambda x_1 + (1-\lambda x_2) \leq \lambda f(x_1) + (1-\lambda) f(x_2)) \text{ for } \forall x_1, x_2 \in X, \forall \lambda \in [0,1] $$</p>


<p>즉, 아래와 같은 함수는 convex function이다.</p>


<p><img src="/images/post/63-1.png" width="500"></p>

<p>Convex function이 좋은 이유는 반드시 optimal한 값이 하나 밖에 존재하지 않는다는 것이다. 여기에서 내가 optimal point가 하나라고 얘기하지 않은 이유는 아래와 같은 예가 있기 때문이다.</p>


<p><img src="/images/post/63-2.png" width="500"></p>

<p>이 함수는 optimal한 값은 unique하게 존재하지만, 그 값을 가지는 point가 unique하지는 않다.</p>


<p>따라서 unique한 optimal point를 찾기 위해서는 하나의 조건이 더 필요한데, 바로 strictly convex라는 조건이다. 이 조건은 위의 식에서 = 이 빠진 형태이다. 즉 &le; 가 &lt; 으로 바뀌는 것이다.</p>


<p>이런 strictly convex function에 대해서 optimal point가 unique하게 존재한다는 것을 증명할 수 있으며, 증명과정은 크게 어렵지 않으니 <a href="http://math.stackexchange.com/questions/345865/strictly-convex-function-and-well-separated-minimum">링크</a> 등을 참고하면 될 것 같다. 아무튼 strictly convex function은 minimum point가 unique하게 존재하기 때문에, 이런 convex function에 대해서 우리는 어떤 optimization algorithm을 design할 수 있다.</p>


<h5>Convex Optimization</h5>


<p>Convex function \(f, g_1, g_2, &#8230;, g_m\)에 대해 아래와 같은 optimization 문제를 Convex optimization이라 정의한다.</p>


<p>$$ \min f(x) \text{ subject to } g_i (x) \leq 0, \text{ i = 1,&#8230;,m}$$</p>


<p>모든 함수들이 convex하기 때문에 이 optimization의 solution은 unique하며, 이런 optimization 문제를 풀 수 있는 방법은 아주아주 많이 존재한다.</p>


<p>이런 convex optimization의 subset으로 linear programming, quadratic programming, semidefinite programming 등이 존재한다. 이 글에서는 그런 특수한 경우는 다루지 않고, 일반적인 convex optimization에서 사용할 수 있는 알고리듬들을 다룰 예정이다. 크게 gradient descent method, newton method, 그리고 lagrange multiplier가 그것이다.</p>


<h5>Gradient Descent Method</h5>


<p><a href="http://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent Method</a>는 미분 가능한 convex function의 optimum point를 찾는 가장 popular한 방법 중 하나이다. 장점이라면 많은 application에 implement하기 매우 간단하고, 모든 차원과 공간으로 확장할 수 있으며, 수렴성이 항상 보장된다는 것이지만, 속도가 느리다는 단점이 존재한다.</p>


<p>아이디어는 매우 간단하다. 어떤 산 위에 우리가 서있다고 가정해보고 우리가 알 수 있는 정보는 내 위치와 내 주변 위치들의 높이 차이밖에 없다고 가정해보자. 만약 내가 산의 가장 낮은 위치로 내려가야하는 상황이라면 어떻게 내려가면 낮은 위치에 도달할 수 있을까? 가장 간단한 방법은 가장 기울기가 가파른 방향을 골라서 내려가는 것이다. 그러다보면 언젠가는 기울기가 0이 되는 지점에 도달하게 될 것이고, 그 지점이 주변에서는 가장 낮은 지점이 될 것이다. 만약 산의 높이가 convex function이라면, 즉 가장 낮은 지점이 unique하다면, 그렇게 도달한 지점이 우리가 원했던 가장 optimal한 지점이라는 것을 알 수 있다. 즉, 이 알고리듬은 매 step마다 현재 위치에서의 가장 가파른 아래로 내려가는 기울기 \(-\nabla f(x^{(k)})\)를 계산하고, 그 방향으로 이동하고, 다시 기울기를 계산하는 방식의 iterative algorithm이다.</p>


<p><img src="/images/post/63-3.png" width="500"></p>

<p>Algorithm description은 다음과 같다.</p>


<p>$$ x^{(k+1)} = x^{(k)} - \eta^{(k)} \nabla f(x^{(k)}) $$</p>


<p>이 때 \(x^{(k)}\) 는 k번 째 iteration에서의 x의 값이며 \(\nabla f(x^{(k)})\) 는 그 지점에서의 gradient 값이다. 이를 조금 더 알고리듬스럽게 기술해보면</p>


<ol>
    <li>set iteration counter k=0, and make an initail guess \(x_0\) for the minimum</li>
    <li>Compute \(-\nabla f(x^{(k)})\)</li>
    <li>Choose \(\eta^{(k)}\) by using some algorithm</li>
    <li>Update \(x^{(k+1)} = x^{(k)} - \eta^{(k)} \nabla f(x^{(k)}))\) and k = k+1</li>
    <li>Go to 2 until \(\nabla f(x^{(k)})) < \epsilon \)</li>
</ol>


<p>만약 function이 convex하다면, 이런 방법으로 x를 계속 update하다보면 적절한 \(\eta\)를 취했을 때 이 algorithm은 global unique optimum으로 수렴하게 된다. 이때 \(\eta\)를 Step size라고 일컫는데, 이 step size를 어떻게 설정하느냐에 따라 알고리듬의 performance가 좌우된다. 만약 step size가 너무 작다면 iteration을 너무 많이 돌아서 전체 performance자체가 저하될 것이다. 그렇다고 step size가 너무 크다면 minima에 converge하는 것이 아니라 그 주변에서 diverge를 할 수도 있다.</p>


<p><img src="/images/post/63-4.png" width="500"></p>

<p>Step size를 고르는 방법은 크게 fixed step size를 취하는 방법과 매번 optimal한 step size를 고르는 방법 두 가지가 존재한다. 먼저 fixed step size에 대해 살펴보자.</p>


<p>앞서 언급했듯, step size를 잘 잡는 것이 중요한데, 너무 큰 step size를 잡게 되면 algorithm이 diverge 하기 때문이다. 다행히도 우리는 어떤 적절한 step size \(\eta\)에 대해 algorithm이 strictly convex function f의 global unique optimum으로 수렴한다는 증명을 할 수 있다.</p>


<p>이 적절한 step size에 대해 설명을 하려면 먼저 L-Lipschitz function이라는 것을 정의해야하는데, 이는 다음과 같이 정의된다.</p>


<p>$$ \|\nabla f(x) - \nabla f(y) \|_2 \leq L \|x-y\|_2, \forall x,y \in R^n $$</p>


<p>만약 f가 L-Lipschitz function이고 어떤 optimum이 존재한다면 fixed step size \(\eta \leq \frac{2}{L}\) 을 취했을 때 gradient descent algorithm이 stationary point로 수렴하게 된다는 것을 증명할 수 있다. 증명은 이 <a href="http://users.ece.utexas.edu/~cmcaram/EE381V_2012F/Lecture_4_Scribe_Notes.final.pdf">렉쳐노트</a>를 참고하기를 바란다.</p>


<p>다음으로 step size를 계속 update하는 방식(이를 Line search라고 한다)을 살펴보자.</p>


<p>먼저 exact line search라는 것 부터 살펴보자. Exact line search의 algorithm은 다음과 같다</p>


<ol>
    <li>set iteration counter k=0, and make an initail guess \(x_0\) for the minimum</li>
    <li>Compute \(-\nabla f(x^{(k)})\)</li>
    <li>Choose \(\eta^{(k)} = argmin_\eta f(x^{(k)} - \eta \nabla f(x^{(k)}))\)</li>
    <li>Update \(x^{(k+1)} = x^{(k)} - \eta^{(k)} \nabla f(x^{(k)}))\) and k = k+1</li>
    <li>Go to 2 until \(\nabla f(x^{(k)})) < \epsilon \)</li>
</ol>


<p>이 알고리듬은 가장 optimal한 \(\eta\)를 매 순간 찾아준다. 하지만 이 알고리듬은 3번 과정 때문에 practical하지는 못하고, 이 알고리듬을 조금 더 practical하게 보완한 backtracking line search algorithm이 조금 더 많이 쓰인다.</p>


<p>For \(\alpha \in {0, 0.5}, \beta \in {0,1}\)</p>


<ol>
    <li>set iteration counter k=0, and make an initail guess \(x_0\) and choose initial \(\eta=1\)</li>
    <li>Compute \(-\nabla f(x^{(k)})\)</li>
    <li>Update \(\eta^{(k)} = \beta \eta^{(k)}\)</li>
    <li>Go to 2 until \(f(x^{(k)} - \eta^{(k)} \nabla f(x^{(k)}))) \leq f(x^{(k)}) - \alpha \eta^{(k)} \| \nabla f(x^{(k)})) \|^2 \)</li>
    <li>Update \(x^{(k+1)} = x^{(k)} - \eta^{(k)} \nabla f(x^{(k)}))\) and k = k+1</li>
    <li>Go to 1 until \(\nabla f(x^{(k)})) < \epsilon \)</li>
</ol>


<p>보통 \(\alpha\)는 0.01에서 0.3 사이의 값으로 선택하고 \(\beta\)의 값은 0.1에서 0.8 정도로 설정된다.</p>


<p>이론적으로는 line search 쪽이 convergence speed가 훨씬 빠르지만, 실제로는 이를 구하는 것보다 적당한 step size로 값을 고정해놓고 gradient descent를 취하는 방법이 더 쉽고, line search를 위해 update되는 step size에 소모되는 computation이 꽤 크기 때문에 practical하게는 적당한 step size를 고정하는 방법이 훨씬 더 많이 사용된다.</p>


<p>Gradient Descent를 약간 응용하여 변형한 알고리듬으로는 Coordinate Descent method, Steepest descent method 등이 존재한다.</p>


<p>간단하게 개념만 설명하자면, <a href="http://en.wikipedia.org/wiki/Coordinate_descent">Coordinate descent</a>는 각 좌표계 방향에서 한 방향씩으로만 번갈아가면서 gradient descent를 하는 것이다. 예를 들어 n차원 function이 있는 경우, 첫번째 차원에 대해 gradient descent를 계산하고 두번째 세번째.. n번째 차원에 대해 이 과정을 반복한다. 그리고 이 과정을 전체 함수가 converge할 때 까지 반복한다. 이 방법이 좋은 이유는 함수가 비록 convex하지 않더라도, 어떤 특수한 경우에 대해 이 방법을 사용해 optimal point를 얻을 수 있기 때문이다.</p>


<p> <br/>
<img src="/images/post/63-5.jpg" width="500"></p>

<p><a href="http://en.wikipedia.org/wiki/Method_of_steepest_descent">Steepest descent</a>는 간단히 생각하면 norm을 적절한 norm으로 바꿔 더 빠르게 converge를 시키는 방법이다. 이 방법은 saddle point가 존재하는 경우에 유용하게 사용할 수 있다고 한다.</p>


<p><img src="/images/post/63-6.gif" width="500"></p>

<h5>Newton&#8217;s Method</h5>


<p>Gradient descent는 기울기 정보 즉, 미분을 한 번만 한 값만을 사용하는데 만약 우리가 두 번 미분한 값을 사용할 수 있다면 훨씬 훨씬 빠른 수렴속도를 보이는 알고리듬을 디자인할 수 있을 것이다. <a href="http://en.wikipedia.org/wiki/Newton's_method">Newton&#8217;s method</a>는 Gradient Descent의 2nd derivative version으로 훨씬 수렴성이 빠르다는 장점을 가지고 있지만, Hessian Matrix를 계산해야하기 떄문에 computation과 memory측면에서 expensive하다는 단점을 가지고 있다.</p>


<p><img src="/images/post/63-7.gif" width="500"></p>

<p>2번 미분 가능한 strongly convex function f에 대해 Newton step은 다음과 같이 기술된다.</p>


<p>$$ \triangle x_{nt} (x) = -\nabla^2 f(x)^{-1} \nabla f(x) $$</p>


<p>이 newton step에 대해 newton&#8217;s method 알고리듬은 다음과 같이 쓸 수 있다.</p>


<ol>
    <li>initialize</li>
    <li>Compute the newton step \(\triangle x = -\nabla^2 f(x)^{-1} \nabla f(x)\)</li>
    <li>Choose step size \(\eta\)</li>
    <li>Update \(x^+ = x + \eta \triangle x_{nt} (x) \)</li>
    <li>Go to 2 until converge</li>
</ol>


<p>이 알고리듬을 깊게 파고들어가면 할 얘기가 정말 많아지므로 일단 convergence 조건이나, step size를 고르는 방법 등에 대해서는 생략하도록 하겠다. 하지만 이 알고리듬에 대해 크게 두 가지 얘기는 꼭 하고 넘어가야할 것 같은데, 하나는 convergence speed, 그리고 하나는 computation이다.</p>


<p>먼저 이 알고리듬은 매우 빠르게 수렴한다. 실제 convergence rate를 증명했을 때 gradient descent보다 빠르게 수렴할 뿐더러, 실제 practical하게도 (Hessian을 계산할 수 있다면) 아래와 같은 convergence phase를 보인다</p>


<p><img src="/images/post/63-8.png" width="500"></p>

<p>즉 처음에는 linear하게 converge하는 것처럼 보이지만, 시간이 지나면 순식간에 quadratic으로 수렴한다. 생각해보면, newton method는 기울기 뿐 아니라, 기울기의 기울기 정보도 같이 사용하기 때문에, 처음에 기울기가 크게 변하지 않을 때는 빠르게 감소하다가, 갑자기 기울기의 크기가 변하기 시작하면 그에 맞춰서 적절한 newton step을 찾을 수 있기 때문에 아주 빠르게 수렴할 수 있다. 특히 saddle point에 대해 영향을 크게 받지 않기 때문에 gradient descent 보다는 훨씬 훨씬 빠르게 수렴한다.</p>


<p>하지만 Newton method의 근본적인 한계는 바로 Hessian을 계산해야한다는 점이다. 이 Hessian을 계산하는 것 자체도 매우 연산이 복잡할 뿐 아니라, gradient의 제곱 만큼의 공간이 필요하기 때문에 memory 역시 efficient하게 사용하기가 어렵다. 때문에 매우 복잡한 함수에 대해서는 newton method를 사용하기가 매우 힘들다. 예를 들어서 neural network에서 gradient descent method를 사용하면 chain rule을 통해 아주 쉽게 그 값을 계산할 수 있지만, second derivation으로 넘어가는 순간, computation을 해야할 양이 급격하게 증가하고, 안그래도 부족한 메모리가 더 부족하게 되기 때문에 neural network에서는 사용되지 않는 방법이다.</p>


<p>대략 요약하자면, 별 일이 없다면 gradient descent에서 fixed step size를 사용해 converge를 시키는 것이 practical하게는 가장 많이 쓰이고 있다. 하지만, 더 빠른 convergence speed가 필요하다면 line search나 steepest method, newton&#8217;s method를 한 번쯤은 고려해볼만 할 것이다.</p>


<h5>Lagrange Multiplier</h5>


<p>마지막으로 <a href="http://en.wikipedia.org/wiki/Lagrange_multiplier">Lagrange multiplier</a>에 대해 살펴보자. Lagrange Multiplier는 constrained optimization을 푸는 매우 popular한 방법 중 하나이다. 원리는 원래 constrained optimization과 같은 optimum point를 가지는 새로운 unconstrained optimization 문제를 만들어서 optimum point를 구하는 것이다. 즉, 다음과 같은 optimization 을 생각해보자</p>


<p>$$ \min f(x) \text{ s.t. } g(x) = c $$</p>


<p>그렇다면 이와 같은 극점을 가지는 다음과 새로운 optimization problem을 만드는 상수 \(\lambda\)가 존재한다.</p>


<p>$$ \min f(x) + \lambda (g(x) - c) $$</p>


<p>보통 c는 상수이기 때문에 극값에 영향을 주지 않으므로 많이 무시된다.</p>


<p>이 문제를 푸는 방법은 여러 개가 있지만, 어렵지 않은 문제인 경우 Lagrange function을 편미분해 0이 되는 값들을 모두 구해 \(\lambda\)를 계산해 대입해서 극값을 찾는 방법을 많이 취한다.</p>


<p>하지만 편미분을 구하기 어려운 경우도 존재하기 때문에 항상 그렇게 푸는 것은 아니고, 이런 문제를 잘 풀 수 있는 여러 알고리듬들이 존재하며, 최근 많이 쓰이는 알고리듬으로는 <a href="http://en.wikipedia.org/wiki/Augmented_Lagrangian_method">ALM</a> (Augumented Lagrange method)가 있다.</p>


<p>Lagrange Multiplier는 풀기 어려운 constrained optimization problem을 그보다 더 풀기 쉬운 unconstrained optimization problem으로 바꿔주기 때문에, 새로운 Lagrange function을 풀기 쉬운 경우에 많이 사용한다.</p>


<h5>Optimization for non-convex function (Local optimum)</h5>


<p>하지만 위에서 서술한 방법들은 오직 convex한 function에만 적용할 수 있는 방법들이므로 우리는 non convex한 함수들은 optimize할 수 없다.. 라고 말해야하지만, 사실 꼭 그렇지만은 않다. Convex function은 global optimum, 즉 해당 식을 만족하는 x를 반드시 찾을 수 있지만, 같은 방법을 적용했을 때 non-convex한 함수는 그럴 수 없다. 하지만 non-convex한 함수이더라도 local optimum 값을 찾을 수는 있다. 때문에 많은 경우에 optimization problem이 convex하지 않다고 하더라도 converge를 하는 것 만으로도 그 문제를 풀었다라고 얘기하는데, 이때, local하게 함수를 봤을 때 convex하다면 gradient descent 등의 방법을 사용해서 local optimum을 계산할 수 있다. 예를 들어서 Neural network에 많이 쓰이는 backpropagation algorithm은 사실 gradient descent method algorithm인데, 따라서 이 알고리듬의 결과는 항상 local optimum으로 converge한다.</p>


<p><img src="/images/post/63-9.jpg" width="500"></p>

<p>따라서 convex하지 않은 optimization일지라하더라도, 일단은 gradient descent 등의 방법을 통해 optimization을 할 수 있다면, local optimum을 구할 수 있다.</p>


<p>하지만 그럼에도 local한 optimum이 엄청나게 많은 경우에는 local optimum으로 converge하는 것이 문제가 되기 때문에 함수를 convex하게 relaxation 시켜서 optimization을 푸는 경우도 존재한다. 특히 원래 문제가 NP-hard인 경우, parameter를 골라야하는 경우 등에 convex relaxation을 많이하는 것 같다.</p>




<h5>변경 이력</h5>


<ul>
<li>2014년 9월 10일: 글 등록</li>
<li>2015년 2월 28일: 변경 이력 추가</li>
</ul>


<h5>Reference</h5>


<ul>
<li><a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex optimization</a> by Boyd</li>
<li><a href="http://stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf">Lecture slides</a> by Boyd and Vandenberghe</li>
<li><a href="http://users.ece.utexas.edu/~cmcaram/EE381V.html">EE381V &ndash; Large Scale Optimization</a> The University of Texas at Austin</li>
</ul>


<hr>


<p><a href="/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="/57">Machine Learning이란?</a></li>
<li><a href="/58">Probability Theory</a></li>
<li><a href="/59">Overfitting</a></li>
<li><a href="/60">Algorithm</a></li>
<li><a href="/61">Decision Theory</a></li>
<li><a href="/62">Information Theory</a></li>
<li><a href="/63">Convex Optimzation</a></li>
<li><a href="/64">Classification Introduction (Decision Tree, Naïve Bayes, KNN)</a></li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Ensemble Learning (Random Forest, Ada Boost)</li>
<li>Graphical Model</li>
<li><a href="/69">Clustering (K-means, Gaussian Mixture Model)</a></li>
<li><a href="/70">EM algorithm</a></li>
<li>Hidden Markov Model</li>
<li>Dimensionality Reduction (LDA, PCA)</li>
<li>Recommendation System (Matrix Completion, Collaborative Filtering)</li>
<li>Neural Network Introduction</li>
<li>Deep Learning</li>
<li>Reinforcement Learning</li>
</ul>

</div>
  
  

<hr>
    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/archives">Blog Archives</a>
    
  </div>
</div>
<!--
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/69/">Machine Learning 스터디 (13) Clustering (K-means, Gaussian Mixture Model)</a>
      </li>
    
      <li class="post">
        <a href="/64/">Machine Learning 스터디 (8) Classification Introduction (Decision Tree, Naïve Bayes, KNN)</a>
      </li>
    
      <li class="post">
        <a href="/86/">블룸버그 폰 인터뷰 후기</a>
      </li>
    
      <li class="post">
        <a href="/85/">2015년 02월 27일 새벽 5시 반</a>
      </li>
    
      <li class="post">
        <a href="/82/">블로그에 Disqus 설치</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/SanghyukChun">@SanghyukChun</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'SanghyukChun',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>
//&#8211;>
    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Sanghyuk Chun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'sanghyukchun';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=182012898639519&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
