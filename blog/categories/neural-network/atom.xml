<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Neural-Network | README]]></title>
  <link href="http://SanghyukChun.github.io/blog/categories/neural-network/atom.xml" rel="self"/>
  <link href="http://SanghyukChun.github.io/"/>
  <updated>2015-09-14T20:41:17+09:00</updated>
  <id>http://SanghyukChun.github.io/</id>
  <author>
    <name><![CDATA[Sanghyuk Chun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Recurrent Neural Network Regularization]]></title>
    <link href="http://SanghyukChun.github.io/89/"/>
    <updated>2015-09-14T19:26:00+09:00</updated>
    <id>http://SanghyukChun.github.io/89</id>
    <content type="html"><![CDATA[<p>최근 머신러닝 분야에서 가장 주목받고 있는 분야는 Deep learning이다. Recurrent Neural Network, 혹은 RNN은 Deep learning 연구 분야 중에서도 요즘 가장 활발하게 연구가 진행되고 있는 분야 중 하나이다. RNN은 sequencial data를 처리하는데에 적합한 형태로 디자인 되어있으며, 현재 language model, speech recognition, machine translation 등에서 우수한 결과를 성취하고 있는 neural network model 중 하나이다. 이 논문은 popular한 RNN 중 하나인 LSTM 모델을 regularization 시켜서 보다 기존 결과들보다 더 잘 동작하는 결과를 제안한다.</p>




<h5>Motivation: Regularization of Recurrent Neural Network</h5>




<p>RNN이 sequencial data에 대해 꽤 좋은 성능을 보이고 있는 것은 사실이지만, RNN을 regularization하는 방법은 많이 제안되어있지 않은 상황이다. 기존 MLP (Multi-Layer Perceptron, 혹은 feed-forward network) 쪽에서는 Dropout, ReLU 등의 컨셉들이 연구되면서 상당한 발전이 있었지만, 아직 RNN에는 Dropout조차 제대로 적용되지 않고 있다고 한다. Dropout을 붙이면 오히려 성능이 떨어지기 때문에 아직은 LSTM (Long-Short-Term-Memory) 모델에 dropout없이 연구가 진행되고 있는 모양이다. 이 논문에서는 LSTM에 dropout을 RNN의 특성을 잘 살린 형태로 적용하여 dropout이 잘 동작하도록 하는 방법을 제안한다.</p>




<h5 id="RNN-intro">RNN Introduction</h5>




<p>본 논문을 소개하기 전에 먼저 RNN에 대해 간단하게 설명을 하고 넘어가도록 하겠다. 이름에서도 알 수 있듯 일반적인 Feed-forward network와 RNN의 차이는 recurrent한 loop의 존재 유무이다. 이는 자기 자신을 향한 self-loop일 수도 있고, 아니면 cycle 형태이거나 아니면 undirected edge의 형태일 수도 있다. 보통 일반적으로 RNN이라 하면 아래 그림과 같이 hidden unit에 self-loop이 있는 형태를 일컫는 듯하다. (출처: Bengio Deep Learning book)</p>


<p><img src="/images/post/89-1.PNG" width="600"></p>

<p>이 그림에서도 알 수 있듯 self-loop의 존재는 RNN으로 하여금 자연스럽게 historical data를 현재 decision에 반영하도록 만들어준다. 즉, RNN 모델은 마치 HMM 등의 sequencial data를 처리하는 모델들처럼 동작하는 것이다. 실제 learning을 할 때는 시간에 대해 self-loop를 'unfold' 하여 마치 weight를 공유하는 deep layer를 연산하듯 update한다. RNN에 대한 더 자세한 설명은 추후 다른 포스팅을 통해 다룰 수 있도록 하겠다.</p>




<h5>Long-Short-Term-Memory (LSTM) Architecture</h5>




<p>기존 vanilla RNN은 long-term dependency를 가지도록 learnig을 하게되면 gradient vanishing이나 exploding 문제에 직면하기 쉬워진다. 이유는 dependency를 더 long-term으로 가져갈수록 gradient 값이 시간에 따른 곱하기 형태가 되어 gradient growth가 exponential해지기 때문이다 (역시 위와 마찬가지로 나중에 더 자세하게 다루도록 하겠다). 때문에 이를 해결하기 위한 아이디어 중 하나로 LSTM이라는 것이 존재한다.</p>




<p>LSTM은 historical information을 저장하기 위한 다소 복잡한 dynamics를 가지고 있다. "long term" memory라는 것은 memory cell (\(c_t\))에 저장되며, 시간에 따라, 그리고 주어진 input data에 따라 저장해둔 information을 얼마나 간직하고 있을지 forget gate (\(f_t\)) 라는 것을 통해 결정하게 된다. LSTM을 그림으로 표현하면 아래 그림과 같다. (출처: 논문)</p>


<p><img src="/images/post/89-2.PNG" width="600"></p>

<p>이를 수식으로 한 번 나타내어보자. 먼저 몇 가지 notation을 정의해보자. 먼저 모든 state는 n-dimension이라고 가정하자. \(h_t^l \in \mathbb R^n \)은 layer \(l\)의 timestamp \(t\)일 때의 hidden state라고 하자. 그리고 \(T_{n,m}: \mathbb R^n \to \mathbb R^m\) 을 n차원에서 m차원으로 가는 affine transform이라고 해보자. 예를 들어 parameter \(W\)와 \(b\)로 나타내어지는 \(Wx + b\)도 \(T_{n,m}\)에 포함된다 (즉, 이 논문에서는 복잡한 weight와 bias에 대한 식을 T라는 notation으로 간단하게 치환했다고 생각하면 된다). 마지막으로 \(\odot\)을 두 벡터의 element-wise multiplication이라고 정의해보자. 이렇게 notation을 정의하고 나면 일반적인 vanilla RNN을 다음과 같이 과거의 hidden state와 현재 hidden state의 이전 layer의 state로부터 현재 hidden state를 표현하는 function으로 표현할 수 있다.</p>


<p>\[\mbox{RNN: } h_t^{l-1}, h_{t-1}^l \to h_t^l, \mbox{ where } h_t^l = f(T_{n,n} h_t^{l-1} + T_{n,n} h_{t-1}^l). \]</p>


<p>이때, function \(f\)는 RNN의 경우 sigmoid나 tanh 함수 중 하나로 선택하는 것이 일반적이다. 그럼 이번에는 LSTM을 수식으로 표현해보자.</p>


<p><img class="center" src="/images/post/89-3.PNG" width="250"></p>

<p>앞에서 언급했던 LSTM의 graphical representation을 살펴보면서 수식을 읽어보면 어렵지 않게 이해할 수 있을 것이다.</p>




<h5>Dropout Regularization for LSTM</h5>




<p>저자들은 RNN에 Dropout을 붙였을 때 잘 동작하지 않는 이유가 dropout이 지워버리면 안되는 과거 information까지 전부 지워버리기 때문이라고 주장한다. 때문에 RNN에 Dropout을 적용하기 위해서는 recurrent connection이 아닌 connection 들에 대해서만 Dropout을 적용해야한다고 논문에서는 주장하고 있다. 아래 식에 조금 더 자세하게 적혀있다. 이때 \(\mathbf D\) 는 dropout operator라는 것으로, 주어진 argument의 random subset을 0으로 만들어버리는 operator이다. 즉, \(\mathbf D (h)\) 라고 한다면 vector \(h\) 중 random하게 고른 일부를 (보통 50%) 0으로 설정하라는 뜻이다.</p>


<p><img class="center" src="/images/post/89-4.PNG" width="250"></p>

<p>이를 그림으로 표현하면 아래와 같다. 이때 실선은 일반적인 connection이고, 점선이 dropout으로 연결된 connection을 의미한다. (출처: 논문)</p>


<p><img src="/images/post/89-5.PNG" width="600"></p>

<p>위 그림에서도 알 수 있듯, 과거에서부터 propagation되는 information은 언제나 100% 보존되지만, 아래 layer에서 위 layer로 전달되는 information은 특정 확률로 dropout에 의해 corruption되어 진행된다. 이때, 맨 아래 data layer로부터 맨 위 \(L\)번째 layer까지 information이 전달되는 동안 점선으로 그려진 connection은 정확하게 \(L+1\) 번 만큼만 지나게 된다. 만약 recurrent connection까지 dropout을 적용했다면, 이 횟수는 \(L+1\) 보다 항상 같거나 클 것이며, 더 long-term dependency를 가질수록 그 효과가 더 강해져서 우리가 원하는 과거 정보는 거의 다 희석되고, 결과적으로 안좋은 결과를 얻게 될 확률이 높아질 것이다.</p>


<p><img src="/images/post/89-6.png" width="600"></p>

<p>위 그림은 어떻게 information이 time t-2로부터 t+2까지 전달되는지 그 flow를 표현한 것이다. 굵은 선이 information path를 나타내는데, 앞서 설명한 것 처럼 이런 information flow는 data layer로부터 decision layer까지 정확하게 \(L+1\) 번만 dropout의 영향을 받게 된다. 반면 standard dropout을 적용했더라면 information이 더 많은 dropout들에 의해 영향을 받아서 LSTM이 정보를 더 긴 시간 동안 저장할 수 없도록 만들게 되는 것이다. 때문에 recurrent connection에 dropout을 적용하지 않는 것 만으로도 LSTM에서 좋은 regularization 효과를 얻을 수 있는 것이다.</p>




<h5>Experiments</h5>




<p>논문에서는 총 4개의 실험을 진행한다. Language Modeling (Penn Tree Bank - PTB dataset), Speech Recognition, Machine Translation 그리고 마지막으로 Image Caption Generation이 그것이다. 결과는 순서대로 아래 Table 1,2,3,4에 나열되어있다.</p>


<p><img src="/images/post/89-7.png" width="600"></p>

<h5>Summary of Recurrent Neural Network Regularization</h5>


<ul>
<li>Motivation: Dropout을 RNN에 그냥 적용하면 성능이 좋지 않다</li>
<li>Idea: Dropout을 모든 connection에 적용하는 대신 non recurrent connection에만 dropout을 적용하자</li>
</ul>


<h5>Reference</h5>


<ul>
<li><a href="http://arxiv.org/abs/1409.2329">Zaremba, Wojciech, Ilya Sutskever, and Oriol Vinyals. &ldquo;Recurrent neural network regularization.&rdquo; arXiv preprint arXiv:1409.2329 (2014).</a></li>
<li><a href="http://www.iro.umontreal.ca/~bengioy/dlbook/">Deep Learning, Yoshua Bengio and Ian J. Goodfellow and Aaron Courville, Book in preparation for MIT Press, 2015</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine learning 스터디 (18) Neural Network Introduction]]></title>
    <link href="http://SanghyukChun.github.io/74/"/>
    <updated>2015-09-13T23:13:00+09:00</updated>
    <id>http://SanghyukChun.github.io/74</id>
    <content type="html"><![CDATA[<h5>들어가며</h5>


<p>최근 Machine Learning 분야에서 가장 뜨거운 분야는 누가 뭐래도 Deep Learning이다. 엄청나게 많은 사람들이 관심을 가지고 있고, 공부하고 응용하고 있지만, 체계적으로 공부할 수 있는 자료가 많이 없다는 것이 개인적으로 조금 안타깝다. 이제 막 각광받기 시작한지 10년 정도 지났고, 매년 새로운 자료들이 쏟아져나오기 때문에 책이나 정리된 글을 찾기가 쉽지가 않다. 그러나 Deep Learning은 결국 artificial neural network를 조금 더 복잡하게 만들어놓은 모델이고, 기본적인 neural network에 대한 이해만 뒷받침된다면 자세한 내용들은 천천히 탑을 쌓는 것이 가능하다고 생각한다. 이 글에서는 neural network의 가장 기본적인 model에 대해 다루고, model paramter를 update하는 algorithm인 backpropagation에 대해서 다룰 것이다. 조금 더 advanced한 topic들은 이 다음 글에서 다룰 예정이다. 이 글의 일부 문단은 <a href="http://SanghyukChun.github.io/blog/categories/neural-network/">이전 글들</a>을 참고하였다.</p>


<h5>Motivation of Neural Network</h5>


<p>이름에서부터 알 수 있듯 neural network는 사람의 뇌를 본 따서 만든 머신러닝 모델이다 (참고: 원래 neural network의 full name은 artificial neural network이지만, 일반적으로 neural network라고 줄여서 부른다). 본격적으로 neural network에 대해 설명을 시작하기 전에 먼저 인간보다 컴퓨터가 훨씬 잘 할 수 있는 일들이 무엇이 있을지 생각해보자.</p>


<ul>
<li>1부터 10000000까지 숫자 더하기</li>
<li>19312812931이 소수인지 아닌지 판별하기</li>
<li>주어진 10000 by 10000 matrix 의 determinant값 계산하기</li>
<li>800 페이지 짜리 책에서 &lsquo;컴퓨터&rsquo; 라는 단어가 몇 번 나오는지 세기</li>
</ul>


<p>반면 인간이 컴퓨터보다 훨씬 잘 할 수 있는 일들에 대해 생각해보자</p>


<ul>
<li>다른 사람과 상대방이 말하고자하는 바를 완벽하게 이해하면서 내가 하고 싶은 말을 상대도 이해할 수 있도록 전달하기</li>
<li>주어진 사진이 고양이 사진인지 강아지 사진인지 판별하기</li>
<li>사진으로 찍어보낸 문서 읽고 이해하기</li>
<li>주어진 사진에서 얼마나 많은 물체가 있는지 세고, 사진에 직접 표시하기</li>
</ul>


<p>컴퓨터가 잘 할 수 있는 0과 1로 이루어진 사칙연산이다. 기술의 발달로 인해 지금은 컴퓨터가 예전보다도 더 빠른 시간에, 그리고 더 적은 전력으로 훨씬 더 많은 사칙연산을 처리할 수 있다. 반면 사람은 사칙연산을 컴퓨터만큼 빠르게 할 수 없다. 인간의 뇌는 오직 빠른 사칙연산만을 처리하기 위해 만들어진 것이 아니기 때문이다. 그러나 인지, 자연어처리 등의 그 이상의 무언가를 처리하기 위해서는 사칙연산 그 너머의 것들을 할 수 있어야하지만 현재 컴퓨터로는 인간의 뇌가 할 수 있는 수준으로 그런 것들을 처리할 수 없다.</p>


<p>예를 들어 아래와 같이 주어진 사진에서 각각의 물체를 찾아내는 문제를 생각해보자 (출처: <a href="http://www.engadget.com/2014/09/08/google-details-object-recognition-tech/">링크</a>). 사람에게는 너무나 간단한 일이지만, 컴퓨터가 처리하기에는 너무나 어려운 일이다. 어떻게 어디부터 어디까지가 'tv or monitor'라고 판단할 수 있을까? 컴퓨터에게 사진은 단순한 0과 1로 이루어진 픽셀 데이터에 지나지 않기 때문에 이는 아주 어려운 일이다.</p>


<p><img class="center" src="/images/post/74-2.jpg" width="400"></p>

<p>그렇기 때문에 자연언어처리, 컴퓨터 비전 등의 영역에서는 인간과 비슷한 성능을 내는 시스템을 만들 수만 있다면 엄청난 기술적 진보가 일어날 수 있을 것이다. 그렇기 때문에 인간의 능력을 쫓아가는 것 이전에, 먼저 인간의 뇌를 모방해보자라는 아이디어를 낼 수 있을 것이다. Neural Network는 이런 모티베이션으로 만들어진 간단한 수학적 모델이다. 우리는 이미 인간의 뇌가 엄청나게 많은 뉴런들과 그것들을 연결하는 시냅스로 구성되어있다는 사실을 알고 있다. 또한 각각의 뉴런들이 activate되는 방식에 따라서 다른 뉴런들도 activate 되거나 activate되지 않거나 하는 등의 action을 취하게 될 것이다. 그렇다면 이 사실들을 기반으로 다음과 같은 간단한 수학적 모델을 정의하는 것이 가능하다.</p>


<h5>Model of Neural Network: neuron, synapse, activation function</h5>


<p>먼저 뉴런들이 node이고, 그 뉴런들을 연결하는 시냅스가 edge인 네트워크를 만드는 것이 가능하다. 각각의 시냅스의 중요도가 다를 수 있으므로 edge마다 weight를 따로 정의하게 되면 아래 그림과 같은 형태로 네트워크를 만들 수 있다. (출처: <a href="https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Activation_Functions">위키</a>)</p>


<p><img src="/images/post/74-1.png" width="600"></p>

<p>보통 neural network는 directed graph이다. 즉, information propagation이 한 방향으로 고정된다는 뜻이다. 만약 undirected edge를 가지게 되면, 혹은 동일한 directed edge가 양방향으로 주어질 경우, information propagation이 recursive하게 일어나서 결과가 조금 복잡해진다. 이런 경우를 recurrent neural network (RNN)이라고 하는데, 과거 데이터를 저장하는 효과가 있기 때문에 최근 음성인식 등의 sequencial data를 처리할 때 많이 사용되고 있다. 이번 ICML 2015에서도 RNN 논문이 많이 발표되고 있고, 최근들어 연구가 활발한 분야이다. 이 글에서는 일단 가장 간단한 'multi layer perceptron (MLP)'라는 구조만 다룰 것인데, 이 구조는 directed simple graph이고, 같은 layer들 안에서는 서로 connection이 없다. 즉, self-loop와 parallel edge가 없고, layer와 layer 사이에만 edge가 존재하며, 서로 인접한 layer끼리만 edge를 가진다. 즉, 첫번째 layer와 네번째 layer를 직접 연결하는 edge가 없는 것이다. 앞으로 layer에 대한 특별한 언급이 없다면 이런 MLP라고 생각하면 된다. 참고로 이 경우 information progation이 'forward'로만 일어나기 때문에 이런 네트워크를 feed-forward network라고 부르기도 한다.</p>


<p>다시 일반적인 neural network에 대해 생각해보자. 실제 뇌에서는 각기 다른 뉴런들이 activate되고, 그 결과가 다음 뉴런으로 전달되고 또 그 결과가 전달되면서 최종 결정을 내리는 뉴런이 activate되는 방식에 따라 정보를 처리하게 된다. 이 방식을 수학적 모델로 바꿔서 생각해보면, input 데이터들에 대한 activation 조건을 function으로 표현하는 것이 가능할 것이다. 이것을 activate function이라고 정의한다. 가장 간단한 activation function의 예시는 들어오는 모든 input 값을 더한 다음, threshold를 설정하여 이 값이 특정 값을 넘으면 activate, 그 값을 넘지 못하면 deactivate되도록 하는 함수일 것이다. 일반적으로 많이 사용되는 여러 종류의 activate function이 존재하는데, 몇 가지를 소개해보도록 하겠다. 편의상 \(t = \sum_i w_i * x_i\) 라고 정의하겠다. (참고로, 일반적으로는 weight 뿐 아니라 bais도 고려해야한다. 이 경우 \(t = \sum_i (w_i * x_i + b_i) \)로 표현이 되지만, 이 글에서는 bais는 weight와 거의 동일하기 때문에 무시하고 진행하도록 하겠다. - 예를 들어 항상 값이 1인 \(x_0\)를 추가한다면 \(w_0\)가 bais가 되므로, 가상의 input을 가정하고 weight와 bais를 동일하게 취급하여도 무방하다.)</p>




<ul>
    <li><p>sigmoid function: \(f(t) = \frac{1}{1+ e^{-t}}\)</p></li>
    <li><p>tanh function: \(f(t) = \frac{e^t - e^{-t}}{e^t + e^{-t} }\)</p></li>
    <li><p>absolute function: \(f(t) = \|t\|\)</p></li>
    <li><p>ReLU function: \(f(t) = max(0, t)\)</p></li>
</ul>




<p>보통 가장 많이 예시로 드는 activation function으로 sigmoid function이 있다. (출처는 위의 <a href="https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Activation_Functions">위키</a>와 같음)</p>


<p><img class="center" src="/images/post/74-4.png" width="300"></p>

<p>이 함수는 미분이 간단하다거나, 실제 뉴런들이 동작하는 것과 비슷하게 생겼다는 등의 이유로 과거에는 많이 사용되었지만, 별로 practical한 activation function은 아니고, 실제로는 ReLU를 가장 많이 사용한다 (2012년 ImageNet competition에서 우승했던 <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a> publication을 보면, ReLU와 dropout을 쓰는 것이 그렇지 않은 것보다 훨씬 더 우수한 결과를 얻는다고 주장하고 있다. 이에 대한 자세한 내용은 다른 포스트를 통해 보충하도록 하겠다). 참고로 neuron을 non-linearity라고 부르기도 하는데, 그 이유는 activation function으로 linear function을 사용하게 되면 아무리 여러 neuron layer를 쌓는다고 하더라도 그것이 결국 하나의 layer로 표현이 되기 때문에 non-linear한 activation function을 사용하기 때문이다.</p>


<p>따라서 이 모델은 처음에 node와 edge로 이루어진 네트워크의 모양을 정의하고, 각 node 별 activation function을 정의한다. 이렇게 정해진 모델을 조절하는 parameter의 역할은 edge의 weight가 맡게되며, 가장 적절한 weight를 찾는 것이 이 수학적 모델을 train할 때의 목표가 될 것이다.</p>




<h5>Inference via Neural Network</h5>


<p>먼저 모든 paramter가 결정되었다고 가정하고 neural network가 어떻게 결과를 inference하는지 살펴보도록하자. Neural network는 먼저 주어진 input에 대해 다음 layer의 activation을 결정하고, 그것을 사용해 그 다음 layer의 activation을 결정한다. 이런 식으로 맨 마지막까지 결정을 하고 나서, 맨 마지막 decision layer의 결과를 보고 inference를 결정하는 것이다 (아래 그림 참고, 빨간 색이 activate된 뉴런이다).</p>


<p><img src="/images/post/74-3.png" width="600"></p>

<p> 이때, classification이라고 한다면 마지막 layer에 내가 classification하고 싶은 class 개수만큼 decision node를 만든 다음 그 중 하나 activate되는 값을 선택하는 것이다. 예를 들어 0부터 9까지 손글씨 데이터를 (MNIST라는 유명한 dataset이 있다) classification해야한다고 생각해보자. 그 경우는 0부터 9까지 decision이 총 10개이므로 마지막 decision layer에는 10개의 neuron이 존재하게 되고 주어진 데이터에 대해 가장 activation된 크기가 큰 decision을 선택하는 것이다.</p>




<h5 id="backprop">Backpropagation Algorithm</h5>


<p>마지막으로 이제 weight를 어떻게 찾을 수 있는지 weight paramter를 찾는 알고리즘에 대해 알아보자. 먼저 한 가지 알아두어야 할 점은 activation function들이 non-linear하고, 이것들이 서로 layer를 이루면서 복잡하게 얽혀있기 때문에 neural network의 weight optimization이 non-convex optimization이라는 것이다. 따라서 일반적인 경우에 neural network의 paramter들의 global optimum을 찾는 것은 불가능하다. 그렇기 때문에 보통 gradient descent 방법을 사용하여 적당한 값까지 수렴시키는 방법을 사용하게 된다.</p>


<p>Neural network (이 글에서는 multi-layer feed-forward network)의 parameter를 update하기 위해서는 backpropagation algorithm이라는 것을 주로 사용하는데, 이는 단순히 neural network에서 gradient descent를 chain rule을 사용하여 단순화시킨 것에 지나지 않는다 (Gradient descent에 대해서는 이전에 쓴 <a href="http://SanghyukChun.github.io/63">Convex Optimization글</a>에서 자세히 다루고 있으니 참고하면 좋을 것 같다). 모든 optimization 문제는 target function이 정의되어야 풀 수 있다. Neural network에서는 마지막 decision layer에서 우리가 실제로 원하는 target output과 현재 network가 produce한 estimated output끼리의 loss function을 계산하여 그 값을 minimize하는 방식을 취한다. 일반적으로 많이 선택하는 loss에는 다음과 같은 함수들이 있다. 이때 우리가 원하는 <a class="red tip" title="만약 MNIST라면 d=10">d-dimensional</a> target output을 \(t=[t_1, \ldots, t_d]\)로, estimated output을 \(x=[x_1, \ldots, x_d]\) 로 정의해보자.</p>




<ul>
    <li><p>sum of squares (Euclidean) loss: \(\sum_{i=1}^d (x_i - t_i)^2 \)</p></li>
    <li><p>softmax loss: \(-\sum_{i=1}^d t_i * \log (\frac{e^{x_i} }{\sum_{j=1}^d e^{x_j} }) \)</p></li>
    <li><p>cross entropy loss: \(\sum_{i=1}^d [ -t_i \log x_i - (1-t_i) \log (1-x_i) ]\)</p></li>
    <li><p>hinge loss: \(\max(0,1-t \cdot x)\), 이때 \(\cdot\)은 내적을 의미한다.</p></li>
</ul>




<p>상황에 따라 조금씩 다른 loss function을 사용하지만, classification에 대해서는 보통 softmax loss가 gradient의 값이 numerically stable하기 때문에 softmax loss를 많이 사용한다. 이렇게 loss function이 주어진다면, 이 값을 주어진 paramter들에 대해 gradient를 구한 다음 그 값들을 사용해 parameter를 update하기만 하면 된다. 문제는, 일반적인 경우에 대해 이 paramter 계산이 엄청 쉬운 것만은 아니라는 것이다.</p>


<p>Backpropagtaion algorithm은 chain rule을 사용해 gradient 계산을 엄청 간단하게 만들어주는 알고리즘으로, 각각의 paramter의 grdient를 계산할 때 parallelization도 용이하고, 알고리즘 디자인만 조금 잘하면 memory도 많이 아낄 수 있기 때문에 실제 neural network update는 이 backpropagtaion 알고리즘을 사용하게 된다.</p>


<p>Gradient descent method를 사용하기 위해서는 현재 parameter에 대한 gradient를 계산해야하지만, 네트워크가 복잡해지면 그 값을 바로 계산하는 것이 엄청나게 어려워진다. 그 대신 backpropataion algorithm에서는 먼저 현재 paramter를 사용하여 loss를 계산하고, 각각의 parameter들이 해당 loss에 대해 얼마만큼의 영향을 미쳤는지 chain rule을 사용하여 계산하고, 그 값으로 update를 하는 방법이다. 따라서 backpropagation algorithm은 크게 두 가지 phase로 나눌 수가 있는데, 하나는 propagation phase이며, 하나는 weight update phase이다. propagation phase에서는 training input pattern에서부터 에러, 혹은 각 뉴런들의 변화량을 계산하며, weight update phase에서는 앞에서 계산한 값을 사용해 weight를 update시킨다.</p>


<h6>Phase 1: Propagation</h6>


<ol>
    <li>Forward propagation: input training data로부터 output을 계산하고, 각 ouput neuron에서의 error를 계산한다. (input -> hidden -> output 으로 정보가 흘러가므로 'forward' propagation이라 한다.)</li>
    <li>Back propagation: output neuron에서 계산된 error를 각 edge들의 weight를 사용해 바로 <a class="red tip" title="이 경우는 hidden layer가 하나이므로 hidden layer를 지칭한다.">이전 layer</a>의 neuron들이 얼마나 error에 영향을 미쳤는지 계산한다. (output -> hidden 으로 정보가 흘러가므로 'back' propagation이라 한다.)</li>
</ol>


<h6>Phase 2: Weight update</h6>


<ol>
    <li>Chain rule을 사용해 paramter들의 gradient를 계산한다.</li>
</ol>


<p>이때, chain rule을 사용한다는 의미는 아래 그림에서 나타내는 것처럼, 앞에서 계산된 gradient를 사용해 지금 gradient 값을 update한다는 의미이다. (그림은 bengio의 <a href="http://www.iro.umontreal.ca/~bengioy/dlbook/">deep learning book</a> <a href="http://www.iro.umontreal.ca/~bengioy/dlbook/mlp.html">Ch6</a> 에서 가져왔다.)</p>


<p><img src="/images/post/74-6.png" width="400"></p>

<p>두 그림 모두 \(\frac{\partial z}{\partial x}\)를 구하는 것이 목적인데, 직접 그 값을 계산하는 대신, \(y\) layer에서 이미 계산한 derivative인 \(\frac{\partial z}{\partial y}\)와 \(y\) layer와 \(x\)에만 관계있는 \(\frac{\partial y}{\partial x}\)를 사용하여 원하는 값을 계산하고 있다. 만약 \(x\) 아래에 \(x^\prime\)이라는 parameter가 또 있다면, \(\frac{\partial z}{\partial x}\)와 \(\frac{\partial x}{\partial x^\prime}\)을 사용하여 \(\frac{\partial z}{\partial x^\prime}\)을 계산할 수 있는 것이다. 때문에 우리가 backpropagation algorithm에서 필요한 것은 내가 지금 update하려는 paramter의 바로 전 variable의 derivative와, 지금 paramter로 바로 전 variable을 미분한 값 두 개 뿐이다. 이 과정을 output layer에서부터 하나하나 내려오면서 반복된다. 즉, output -> hidden k, hidden k -> hidden k-1, ... hidden 2 -> hidden 1, hidden 1 -> input의 과정을 거치면서 계속 weight가 update되는 것이다. 예를 들어서 decision layer와 가장 가까운 weight는 직접 derivative를 계산하여 구할 수 있고, 그보다 더 아래에 있는 layer의 weight는 그 바로 전 layer의 weight와 해당 layer의 activation function의 미분 값을 곱하여 계산할 수 있다. 이해가 조금 어렵다면 아래의 <a href="74#example">예제</a>를 천천히 읽어보기를 권한다.</p>


<p>이 과정을 맨 위에서 아래까지 반복하면 전체 gradient를 구할 수 있고, 이 gradient를 사용해 parameter들을 update할 수 있다. 이렇게 한 번의 iteration이 진행되고, 충분히 converge했다고 판단할 때 까지 이런 iteration을 계속 반복하는 것이 feed-forward network의 parameter를 update하는 방법이다.</p>


<p>이를 그림으로 표현하면 아래와 같다. (출처: <a href="http://tex.stackexchange.com/questions/162326/drawing-back-propagation-neural-network">링크</a>)</p>


<p><img src="/images/post/42-1.png" width="600"></p>

<p>이렇듯 backpropagation은 직접 weight를 바로 변화시키는 것이 아니라 오직 error만을 보고 gradient descent method based approach를 사용해 error를 minimize하는 방향으로 계속 weight를 update시키는 것이다. 또한 한 번 error가 연산된 이후에는 output layer에서부터 그 이전 layer로 '역으로' 정보가 update되기 때문에 이를 backpropagation, 한국어로는 역전사라고 하는 것이다.</p>




<h5>Stochastic Gradient Descent</h5>


<p>Gradient를 계산했으니 이제 직접 Gradient Descent를 써서 parameter만 update하면 된다. 그러나 문제가 하나 있는데, 일반적으로 neural network의 input data의 개수가 엄청나게 많다는 것이다. 때문에 정확한 gradient를 계산하기 위해서는 모든 training data에 대해 gradient를 전부 계산하고, 그 값을 평균 내어 정확한 gradient를 구한 다음 '한 번' update해야한다. 그러나 이런 방법은 너무나도 비효율적이기 때문에 Stochastic Gradient Descent (SGD) 라는 방법을 사용해야한다.</p>


<p>SGD는 모든 데이터의 gradient를 평균내어 gradient update를 하는 대신 (이를 'full batch'라고 한다), 일부의 데이터로 'mini batch'를 형성하여 한 batch에 대한 gradient만을 계산하여 전체 parameter를 update한다. Convex optimization의 경우, 특정 조건이 충족되면 SGD와 GD가 같은 global optimum으로 수렴하는 것이 증명되어있지만, neural network는 convex가 아니기 때문에 batch를 설정하는 방법에 따라 수렴하는 조건이 바뀌게 된다. Batch size는 일반적으로 메모리가 감당할 수 있을 정도까지 최대한 크게 잡는 것 같다.</p>




<h5 id="example">Backpropagation Algorithm: example</h5>


<p>이전에 chain rule로 gradient를 계산한다고 언급했었는데, 실제 이 chain rule이 어떻게 적용되는지 아래의 간단한 예를 통해 살펴보도록하자. 이때 계산의 편의를 위해 각각의 neuron은 sigmoid loss를 가지고 있다고 가정하도록 하겠다.</p>


<p><img src="/images/post/74-5.png" width="600"></p>

<p>이때 각각의 neuron의 input으로 들어가는 값을 \(in_{o_5}\), output으로 나가는 값을 \(out_{h_3}\)와 같은 식으로 정의해보자 (이렇게 된다면 in과 out은 \(out_{h_3} = \sigma(in_{h_3})\) 으로 표현 가능하다. - 이때 \(\sigma\)는 sigmoid function). 먼저 error를 정의하자. error는 가장 간단한 sum of square loss를 취하도록 하겠다. 우리가 원하는 target을 \(t\)라고 정의하면 loss는 \(E = \frac{1}{2}(t_5-out_{o_5})^2 + \frac{1}{2}(t_6-out_{o_6})^2\)가 될 것이다 (1/2는 미분한 값을 깔끔하게 쓰기 위해 붙인 상관없는 값이므로 무시해도 좋다). 그리고 우리가 원하는 값들은 \(\frac{\partial E}{\partial w_{13}}, \frac{\partial E}{\partial w_{14}}, \ldots, \frac{\partial E}{\partial w_{46}}\)이 될 것이다. 이제 가장 먼저 \(\frac{\partial E}{\partial w_{35}}\) 부터 계산해보자.</p>


<p>\[\frac{\partial E}{\partial w_{35}} = \frac{\partial E}{\partial out_{o_5}} * \frac{\partial out_{o_5}}{\partial in_{o_5}} * \frac{\partial in_{o_5}}{\partial w_{35}}. \]</p>


<p>즉, 우리가 원하는 derivative를 계산하기 위해서는 세 개의 다른 derivative (\(\frac{\partial E}{\partial out_{o_5}}, \frac{\partial out_{o_5}}{\partial in_{o_5}}, \frac{\partial in_{o_5}}{\partial w_{35}}\))를 계산해야한다. 각각을 구하는 방법은 다음과 같다.</p>


<ul>
    <li><p>\(\frac{\partial E}{\partial out_{o_5}}\): error를 \(E = \frac{1}{2}(t_5-out_{o_5})^2 + \frac{1}{2}(t_6-out_{o_6})^2\)라고 정의했으므로, \(\frac{\partial E}{\partial out_{o_5}} = out_{o_5} - t_5\)이다. - 이때 \(out_{o_5}\)와 \(t_5\)는 weight update이전 propagation step에서 계산된 값이다.</p></li>
    <li><p>\(\frac{\partial out_{o_5}}{\partial in_{o_5}}\): \(o_5\)는 sigmoid activation function을 사용하므로 \(out_{o_5} = \sigma(in_{o_5})\)이다. 또한 sigmoid function의 미분 값은 \(\frac{\partial \sigma(x)}{\partial x} = \sigma(x) (1 - \sigma(x))\)으로 주어지므로, 이 값을 대입하면 \(\frac{\partial out_{o_5}}{\partial in_{o_5}} = out_{o_5} (1 - out_{o_5})\)가 된다. - 역시 여기에서도 미리 계산한 \(out_{o_5}\)를 사용한다.</p></li>
    <li>\(\frac{\partial in_{o_5}}{\partial w_{35}}\): \(o_5\)로 들어온 값의 총 합은 앞선 layer의 output과 \(o_5\)로 들어오는 weight를 곱하면 되므로 \(in_{o_5} = w_{35} out_{h_3} + w_{45} out_{h_4}\)이고, 이것을 통해 \(\frac{\partial in_{o_5}}{\partial w_{35}} = out_{h_3}\)가 됨을 알 수 있다. - \(out_{h_3}\) 역시 이전 propagation에서 계산된 값이다.</li>
</ul>


<p>따라서 \(\frac{\partial E}{\partial w_{35}}\)의 derivative 값은 위의 세 값을 모두 곱한 것으로 계산 할 수 있다. 그림으로 표현하면 아래와 같은 그림이 될 것이다. 즉, 'backward' 방향으로 derivative에 대한 정보를 'propagation'하면서 parameter의 derivative를 계산하는 것이다. 마찬가지 방법으로 \(w_{36}, w_{45}, w_{46}\)에 대한 derivative도 계산할 수 있다.</p>


<p><img src="/images/post/74-7.png" width="300"></p>

<p>그럼 이번에는 그 전 layer의 paramter들 중 하나인 \(w_{13}\)의 derivative를 계산해보자. 이번에 계산할 과정도 위와 비슷한 그림으로 표현해보면 아래와 같다.</p>


<p><img src="/images/post/74-8.png" width="300"></p>

<p>그러면 이제 \(\frac{\partial E}{\partial w_{13}}\)을 구해보자.</p>


<p>\[\frac{\partial E}{\partial w_{13}} = \frac{\partial E}{\partial out_{h_3}} * \frac{\partial out_{h_3}}{\partial in_{h_3}} * \frac{\partial in_{h_3}}{\partial w_{13}}.\]</p>


<p>마찬가지로 각각을 구하는 방법에 대해 적어보자.</p>


<ul>
    <li><p>\(\frac{\partial E}{\partial out_{h_3}}\): \(E = \frac{1}{2}(t_5-out_{o_5})^2 + \frac{1}{2}(t_6-out_{o_6})^2\)를 \(E = E_{o_5} + E_{o_6}\)로 decompose 하면 이 미분 식은 \(\frac{\partial E_{o_5}}{\partial out_{h_3}} + \frac{\partial E_{o_6}}{\partial out_{h_3}}\)로 쓸 수 있다. 각각의 계산은 다음과 같다.</p></li>
    <ul>
        <li><p>\(\frac{\partial E_{o_5}}{\partial out_{h_3}} = \frac{\partial E_{o_5}}{\partial in_{o_5}} * \frac{\partial in_{o_5}}{\partial out_{h_3}}\)으로 쓸 수 있다. 이 중 앞의 값인 \(\frac{\partial E_{o_5}}{\partial in_{o_5}}\)은 이미 전 과정에서 계산했던 \(\frac{\partial E}{\partial out_{o_5}}\)과 \(\frac{\partial out_{o_5}}{\partial in_{o_5}}\)의 곱으로 계산가능하다. 뒤의 값은 \(\frac{\partial in_{o_5}}{\partial out_{h_3}} = w_{35}\)이므로 간단하게 계산할 수 있다.</p></li>
        <li><p>\(\frac{\partial E_{o_6}}{\partial out_{h_3}}\)도 위와 같은 방법으로 연산이 가능하다.</p></li>
    </ul>
    <li><p>\(\frac{\partial out_{h_3}}{\partial in_{h_3}}\): \(\frac{\partial out_{o_5}}{\partial in_{o_5}}\)와 같다. 따라서 \(out_{h_3} (1-out_{h_3})\)이다.</p></li>
    <li><p>\(\frac{\partial in_{h_3}}{\partial w_{13}}\): \(\frac{\partial in_{o_5}}{\partial w_{35}}\)와 같다. 따라서 \(out_{i_1}\)이다.</p></li>
</ul>


<p>이렇게 \(\frac{\partial E}{\partial out_{h_3}}\)에서는 앞에서 계산했던 값들을 재활용하고, 아래의 값들은 activation function과 network의 topological property에 맞는 derivative를 곱하는 방식으로 \(\frac{\partial E}{\partial w_{13}}\)을 구할 수 있다.</p>


<p>이렇듯 backpropagation algorithm은 forward propagation을 통해 필요한 값들을 미리 저장해두고, backward propagation이 진행되면서 위에서부터 loss에 대한 derivative를 하나하나 계산해나가면서 다음 layer에서 바로 전 layer에서 계산한 값들과 각 neuron 별로 추가적으로 필요한 derivative들을 곱해나가면서 weight의 derivative를 계산하는 알고리즘이다.</p>


<p>이렇게 한 번 전체 gradient를 계산한 다음에는 learning rate를 곱하여 전체 parameter의 값을 update한 다음, 다시 처음부터 이 과정을 반복한다. 보통 에러가 감소하는 속도를 관측하면서 '이 정도면 converge한 것 같다' 하는 수준까지 돌린다.</p>


<p>익숙해지려면 다소 시간이 걸리지만, 개념적으로 먼저 'error를 먼저 계산하고, 그 값을 아래로 전달해나가면서 바로 전 layer에서 계산한 미분값들을 사용해 현재 layer의 미분값을 계산한 다음, 그 값을 사용해 다음 layer의 미분값을 계산한다.' 라고 개념만 이해해두고 다시 차근차근 chain rule을 계산해나가면서 계산하면 조금 편하게 익숙해 질 수 있을 것이다.</p>




<h5>정리</h5>


<p>Deep learning을 다루기 위해서는 가장 먼저 aritifitial neural network의 model에 대한 이해와 gradient descent라는 update rule에 대한 이해가 필수적이다. 이 글에서는 가장 기초적이라고 생각하는 feed-forward network의 model을 먼저 설명하고, paramter를 update하는 gradient descent algorithm의 일종인 backpropagation에 대한 개념적인 설명을 다루었다. 조금 어려울 수 있는 내용이니 다른 글들을 계속 참고하면서 보면 좋을 것 같다.</p>




<h5>변경 이력</h5>


<ul>
<li>2015년 9월 13일: 글 등록</li>
<li>2015년 9월 14일: 오타수정, SGD 내용 추가 등</li>
</ul>


<h5>Reference</h5>


<ul>
<li><a href="http://www.iro.umontreal.ca/~bengioy/dlbook/">Deep Learning, Yoshua Bengio and Ian J. Goodfellow and Aaron Courville, Book in preparation for MIT Press, 2015</a></li>
<li>wiki (<a href="https://en.wikibooks.org/wiki/Artificial_Neural_Networks">링크</a>)</li>
</ul>


<hr>


<p><a href="http://SanghyukChun.github.io/blog/categories/machine-learning-study/">Machine Learning 스터디</a>의 다른 글들</p>


<ul>
<li><a href="http://SanghyukChun.github.io/57">Machine Learning이란?</a></li>
<li><a href="http://SanghyukChun.github.io/58">Probability Theory</a></li>
<li><a href="http://SanghyukChun.github.io/59">Overfitting</a></li>
<li><a href="http://SanghyukChun.github.io/60">Algorithm</a></li>
<li><a href="http://SanghyukChun.github.io/61">Decision Theory</a></li>
<li><a href="http://SanghyukChun.github.io/62">Information Theory</a></li>
<li><a href="http://SanghyukChun.github.io/63">Convex Optimzation</a></li>
<li><a href="http://SanghyukChun.github.io/64">Classification Introduction (Decision Tree, Naïve Bayes, KNN)</a></li>
<li>Regression and Logistic Regression</li>
<li>PAC Learning &amp; Statistical Learning Theory</li>
<li>Support Vector Machine</li>
<li>Ensemble Learning (Random Forest, Ada Boost)</li>
<li>Graphical Model</li>
<li><a href="http://SanghyukChun.github.io/69">Clustering (K-means, Gaussian Mixture Model)</a></li>
<li><a href="http://SanghyukChun.github.io/70">EM algorithm</a></li>
<li>Hidden Markov Model</li>
<li><a href="http://SanghyukChun.github.io/72">Dimensionality Reduction (LDA, PCA)</a></li>
<li>Recommendation System (Matrix Completion, Collaborative Filtering)</li>
<li><a href="http://SanghyukChun.github.io/74">Neural Network Introduction</a></li>
<li>Deep Learning</li>
<li>Reinforcement Learning</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Batch Normalization]]></title>
    <link href="http://SanghyukChun.github.io/88/"/>
    <updated>2015-08-25T21:25:00+09:00</updated>
    <id>http://SanghyukChun.github.io/88</id>
    <content type="html"><![CDATA[<p>Batch Normalization은 현재 <a href="http://image-net.org/challenges/LSVRC/2015/">ImageNet competition</a>에서 state-of-art (Top-5 error: 4.9%)를 기록하고 있는 Neural Network model의 기본 아이디어이다. 이 글에서는 arXiv에 제출된 (그리고 ICML 2015에 publish된) <a href="http://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a> 논문을 리뷰하고, batch normalization이 어떤 기술이고, 어떤 원리에 의해 작동하는지 등에 대해 다룰 것이다.</p>


<h5>Motivation: Deep learning의 속도를 어떻게 더 빠르게 만들 수 있을까?</h5>


<p>Deep learning이 잘 동작하고, 뛰어난 성능을 보인다는 것은 이제 누구나 알고 있다. 그러나 여전히 deep learning은 굉장히 시간이 오래 걸리는 작업이고, 그만큼 computation power도 많이 필요로 한다. 그 동안의 연구 결과를 보면, converge한 것 처럼 보이더라도 더 많이 돌리게 된다면 더 좋은 결과로 수렴한다는 것을 알 수 있는 만큼, deep neural network의 train 속도를 높이는 것은 전체적인 성능 향상에 도움이 될 것이다.</p>


<p>보통 Deep learning을 train할 때에는 stochastic gradient descent (SGD) method를 사용한다. SGD의 속도를 높이는 가장 naive한 방법은 learning rate를 높이는 것이지만, 높은 learning rate는 보통 gradient vanishing 혹은 gradient exploding problem을 야기한다는 문제가 있다.</p>


<p>Gradient vanishing은 backpropagation algorithm에서 아래 layer로 내려갈수록, 현재 parameter의 gradient를 계산했을 때 앞에서 받은 미분 값들이 곱해지면서 그 값이 거의 없어지는 (vanish하는) 현상을 의미한다. Gradient exploding은 learning rate가 너무 높아 diverge하는 현상을 말한다. Learning rate의 값이 크면 이 두 가지 현상이 발생할 확률이 높기 때문에 우리는 보통 작은 learning rate를 고르게 된다. 그러나 우리는 이미 일반적으로 learning rate의 값이 diverge하지 않을 정도로 크면 gradient method의 converge 속도가 향상된다는 것을 알고 있다. 따라서 이 논문이 던지는 질문은 다음과 같다. 자연스럽게 나오는 궁금증은 Gradient vanishing/exploding problem이 발생하지 않도록 하면서 learning rate 값을 크게 설정할 수 있는 neural network model을 design할 수 있는가?</p>


<h5>Internal Covariate Shift: learning rate의 값이 작아지는 이유</h5>


<p>Gradient vanishing problem이 발생하는 이유에 대해서는 여러가지 설명이 가능하지만 (exploding은 그냥 우리가 값을 작게 설정하여 해결할 수 있다) 이 논문에서는 internal covariate shift라는 개념을 제안한다. Covariate shift는 machine learning problem에서 아래 그림과 같이 train data와 test data의 data distribution이 다른 현상을 의미한다. 아래 그림 참고 (<a href="http://blog.bigml.com/2014/01/03/simple-machine-learning-to-detect-covariate-shift/">출처</a>)</p>


<p><img src="/images/post/88-1.jpg" width="500"></p>

<p>이 논문에서는 단순히 train/test input data의 distribution이 변하는 것 뿐 아니라, 각각의 layer들의 input distribution이 training 과정에서 일정하지 않기 때문에 문제가 발생한다고 주장하며, 이렇게 각각의 layer들의 input distribution이 consistent하지 않은 현상을 internal convariate shift라고 정의한다. 이 논문에서 이것이 문제가 된다고 주장하는 이유는, 각각의 layer parameter들은 현재 layer에 들어오는 input data 뿐만 아니라 다른 model parameter들에도 영향을 받기 때문이라고한다. 즉, gradient vanishing problem이 발생하는 이유를 backpropagation 과정에서 아래로 내려갈수록 이전 gradient들의 영향이 더 커져서 지금 parameter가 거의 update되지 않는다고 설명하는 것과 같은 맥락이다.</p>


<p>기존에는 이런 현상을 방지하기 위하여 ReLU neuron을 사용하거나 (Nair & Hinton, 2010), cafeful initialization을 사용하거나 (Bengio & Glorot, 2010; Saxe et al., 2013), leanring rate를 작게 취하는 등의 전략을 사용했지만, 그런 방법이 아닌 다른 방법을 통해 internal covariate shift 문제가 해결이 된다면 더 높은 learning rate를 선택하여 learning 속도를 빠르게하는 것이 가능할 것이다.</p>


<p></p>

<h5>Navie approach: Whitening</h5>


<p>따라서 이 논문의 목표는 internal covariate shift를 줄이는 것이다. 그렇다면 internal covariate shift는 어떻게 줄일 수 있을까? 이 논문에서는 엄청 간단하게 input distribution을 zero mean, unit variance를 가지는 normal distribution으로 normalize 시키는 것으로 문제를 해결하며, 이를 whitening이라한다 (LeCun 1998, Wiesler & Ney 2011). 주어진 column data \(X\in R^{d\times n}\)에 대해 whitening transform은 다음과 같다.</p>


<p>\[\hat{X} = Cov(X)^{-1/2} X, Cov(X) = E[( X - E[X] ) ( X - E[X] )^\top ].\]</p>


<p>그러나 이런 naive한 approach에서는 크게 두 가지 문제점들이 발생하게 된다.</p>


<ol>
<li>multi variate normal distribution으로 normalize를 하려면 inverse의 square root를 계산해야 하기 때문에 필요한 계산량이 많다.</li>
<li>mean과 variance 세팅은 어떻게 할 것인가? 전체 데이터를 기준으로 mean/variance를 training마다 계산하면 계산량이 많이 필요하다.</li>
</ol>


<p>따라서 이 논문에서는 이런 문제점들을 해결할 수 있으면서, 동시에 everywhere differentiable하여 backpropagation algorithm을 적용하는 데에 큰 문제가 없는 간단한 simplification을 제안한다.</p>


<h5>Batch Noramlization Transform</h5>


<p>앞서 제시된 문제점들을 해결하기 위하여 이 논문에서는 두 가지 approach를 제안한다.</p>


<ol>
<li>각 차원들이 서로 independent하다고 가정하고 각 차원 별로 따로 estimate를 하고 그 대신 표현형을 더 풍성하게 해 줄 linear transform도 함께 learning한다</li>
<li>전체 데이터에 대해 mean/variance를 계산하는 대신 지금 계산하고 있는 batch에 대해서만 mean/variance를 구한 다음 inference를 할 때에만 real mean/variance를 계산한다</li>
</ol>


<p>먼저 naive approach에서 covariance matrix의 inverse square root를 계산해야했던 이유는 모든 feature들이 서로 correlated되었다고 가정했기 때문이지만, 각각이 independent하다고 가정함으로써, 단순 scalar 계산만으로 normalization이 가능해진다. 이를 수식으로 표현하면 다음과 같다.</p>


<p></p>

<p>d dimensional data \(x = (x^{(1)}, x^{(2)}, \ldots, x^{(d)})\)에 대해 각각의 차원 \(k\) 마다 다음과 같은 식을 계산하여 \(\hat x\)를 계산한다</p>


<p>\[\hat{x}^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}.\]</p>


<p>그러나 이렇게 correlation을 무시하고 learning하는 경우 각각의 관계가 중요한 경우 제대로 되지 못한 training을 하게 될 수도 있으므로 이를 방지하기 위한 linear transform을 각각의 dimension \(k\)마다 learning해준다. 이 transform은 scaling과 shifting을 포함한다.</p>


<p>\[y^{(k)} = \gamma \hat{x}^{(k)} + \beta.\]</p>


<p>이때 parameter \(\gamma, \beta\)는 neural network를 train하면서 마치 weight를 update하듯 같이 update하는 model parameter이다.</p>


<p>두 번째로, 전체 데이터의 expectation을 계산하는 대신 주어진 mini-batch의 sample mean/variance를 계산하여 대입한다.</p>


<p></p>

<p>이제 앞서 설명한 두 가지 simplification을 적용하여 다음과 같은 batch normalization transform이라는 것을 정의할 수 있다.</p>


<p><img src="/images/post/88-2.png" width="500"></p>

<p>이때, backpropagation에 사용되는 \(\gamma, \beta\) 그리고 layer를 위한 chain rule은 다음과 같이 계산된다.</p>


<p><img src="/images/post/88-4.png" width="500"></p>

<h5>Train/Inference with BN network</h5>


<p>앞에서 batch normalization transform을 각각의 layer input을 normalization하는데에 사용할 것이라는 설명을 했었다. 다시말해서 BN network는 기존 network에서 각각의 layer input 앞에 batch normalization layer라는 layer를 추가한 것과 구조가 동일하다.</p>


<p><img src="/images/post/88-5.png" width="500"></p>

<p>이때 자세한 알고리즘은 다음과 같다.</p>


<p><img src="/images/post/88-3.png" width="500"></p>

<p>주의해야할 점 하나는 train 과정에서는 mini-batch의 sample mean/variance를 사용하여 BN transform을 계산하였지만, inference를 할 때에도 같은 규칙을 적용하게 되면 mini-batch 세팅에 따라 inference가 변할 수도 있기 때문에 각각의 test example마다 deterministic한 결과를 얻기 위하여 sample mean/variance 대신 그 동안 저장해둔 sample mean/variance들을 사용하여 unbiased mean/variance estimator를 계산하여 이를 BN transform에 이용한다.</p>


<h5>BN network의 장점</h5>


<p>저자들이 주장하는 BN network의 장점은 크게 두 가지이다.</p>


<ol>
<li>더 큰 learning rate를 쓸 수 있다. internal covariate shift를 감소시키고, parameter scaling에도 영향을 받지 않고, 더 큰 weight가 더 작은 gradient를 유도하기 때문에 parameter growth가 안정화되는 효과가 있다.</li>
<li>Training 과정에서 mini-batch를 어떻게 설정하느냐에 따라 같은 sample에 대해 다른 결과가 나온다. 따라서 더 general한 model을 learning하는 효과가 있고, drop out, l2 regularization 등에 대한 의존도가 떨어진다.</li>
</ol>


<p>논문을 살펴보면 BN transform이 scale invariant하고, 큰 weight에 대해 작은 gradient가 유도되기 때문에 paramter growth를 안정화시키는 효과가 있다는 언급이 있다. 또한 regularization효과를 더 강화하기 위하여 매 mini-batch마다 training data를 shuffling하여 input으로 넣는데, 이때 한 mini-batch 안에서는 같은 데이터가 중복으로 나오지 않도록 shuffling하여 대입한다.</p>


<h5>실험</h5>


<p>먼저 BN network가 주장하는대로 잘 동작하는지 보여주는 실험이다.</p>


<p><img src="/images/post/88-6.png" width="500"></p>

<p>가장 왼쪽은 MNIST data에 대해 BN을 쓴 것과 쓰지 않은 것의 convergence speed를 비교한 것이며, 다음 그림들은 BN을 사용했을 때와 사용하지 않았을 때, internal covariate shift가 어떻게 변화하는지를 보여주는 것이다. 한 뉴런의 training 동안 activation value의 변화를 plot한 것으로, 가운데 있는 선이 평균 값이고, 위 아래가 variance를 의미한다고 생각하면 된다. BN을 사용하면 처음부터 끝까지 거의 비슷한 distribution을 가진다는 것을 알 수 있다.</p>


<p></p>

<p>다음으로 single network에 대해 inception network와의 성능을 비교한 실험이다</p>


<p><img src="/images/post/88-7.png" width="500"></p>

<p>세팅은 전부 같고 inception network와 비교하여 BN이 추가되었는지 여부와 learning rate가 몇 배인지 (x5는 5배의 leanring rate를 취한 것이다) 여부만 다르게 설정하였음에도 불구하고 convergence speed와 심지어 최종 max acc까지 차이가 나는 것을 볼 수 있다.</p>


<p>이런 결과들을 기반으로 약간의 paramter tunning을 거쳐 아래와 같은 ImageNet state-of-art를 기록했다고 한다.</p>


<p><img src="/images/post/88-8.png" width="500"></p>

<h5>BN 네트워크 성능 accelerating하기</h5>


<p>BN을 추가하는 것 만으로 성능 개선이 엄청나게 일어나는 것은 아니며 다음과 같은 parameter tunning이 추가로 필요하다고 한다.
1. learning rate 값을 키운다 (0.0075 &ndash;> 0.045, 5)
2. drop out을 제거한다 (BN이 regularization 효과가 있기 때문이라고 한다)
3. l2 weight regularization을 줄인다 (BN이 regularization 효과가 있기 때문이라고 한다)
4. learning rate decay를 accelerate한다 (6배 더 빠르게 가속한다)
5. local response normalization을 제거한다 (BN에는 적합하지 않다고 한다)
6. training example의 per-batch shuffling을 추가한다 (BN이 regularization 효과를 증폭시키기 위함이다)
7. photometric distortion을 줄인다 (BN이 속도가 더 빠르고 더 적은 train example을 보게 되기 때문에 실제 데이터에 더 집중한다고 한다)</p>

<p>이런 parameter tunning이 추가로 이루어지고 나면, 기존 neural network보다 ImageNet에서 훨씬 좋은 성능을 내는 neural network를 구성할 수 있다고 한다.</p>


<h5>Summary of BN network</h5>


<ul>
<li>아이디어: 각 nonlinearity의 input으로 BN transform을 추가한다</li>
<li>BN transform은 다음과 같은 두 가지 simplification으로 구성된다

<ul>
<li>각 feature들의 correlation을 무시하고 각각 따로 normalize 하고 각각에 대한 linear transform을 같이 learning한다</li>
<li>Mini-batch의 sample mean/variance로 normalize 한다</li>
</ul>
</li>
<li>BN network의 train/inference에서는 다음과 같은 특이점이 있다

<ul>
<li>Train/inference의 forward rule이 다르다 (각각이 사용하는 mean/variance가 다르다)</li>
<li>Train 과정에서 mini-batch를 (중복없이) shuffling하여 train시킨다</li>
</ul>
</li>
<li>BN network를 사용함으로써 다음과 같은 효과를 볼 수 있다

<ul>
<li>Learning rate를 큰 값으로 설정할 수 있어 converge가 빠르다</li>
<li>Generalized model을 learning하는 효과가 있다</li>
</ul>
</li>
</ul>


<h5>Reference</h5>


<ul>
<li><a href="http://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>, Sergey Ioffe, Christian Szegedy, ICML 2015</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coursera Neural Networks for Machine Learning Week4 & 5 - Applications]]></title>
    <link href="http://SanghyukChun.github.io/43/"/>
    <updated>2014-04-05T21:38:00+09:00</updated>
    <id>http://SanghyukChun.github.io/43</id>
    <content type="html"><![CDATA[<h5>들어가기 전에</h5>


<p>이 글은 Geoffrey Hinton 교수가 2012년 Coursera에서 강의 한 <a href="https://class.coursera.org/neuralnets-2012-001/lecture">Neural Networks for Machine Learning</a> 4주차와 5주차 강의를 요약한 글이다. 이 강의에서는 이론적인 형태의 무언가를 배운다기보다는 real application의 예로 Neural Network를 사용해 word prediction (NLP에서 쓰이는) 그리고 object recognition를 하는 방법에 대해 다룬다. 내가 관심이 있는 부분은 실제 이 NN을 어떻게 적용하냐라기 보다는 NN이란 무엇이며 어떤 이론적 배경이 있는 것이며 그 알고리듬에 더 관심이 있기 때문에 대부분이 engineerning issue인 이번 두 강의들은 대략적으로 어떤 내용에 대해서 다루는지만 아주 간략하게 기술하였다.</p>


<h5>Learning feature vectors for words</h5>


<p>Speech recoginition에서 가장 중요한 문제 중 하나는 바로 제대로 인식되지 않은 단어가 무엇일지 추측하는 것이다. 아무리 기술이 좋아지더라도 speech를 완전하게 복원하는 것은 불가능하다. 살제 사람들도 완전하게 speech를 인식하는 것은 아니고 때에 따라 적당히 추측해서 이해하는 것처럼, 이런 문제가 음성 인식에서 많이 중요한 문제로 대두되고 있다. 나도 seri를 사용하다보면 음성인식률이 생각보다 좋지않아서 실망하고는 하는데, 이런 문제점을 해결하기 위해 다양한 방법들이 제시되고 있다. 이 강의는 이런 것들을 개선시키기 위해 neural network를 도입했었던 연구들에 대해 다룬다. 참고로 여기에서 사용하는 모든 NN들은 softmax function neuron을 사용하고 error function은 cross entropy error를 사용한다. 이유는 sigmoid function을 사용했을 때 error가 rmse라면 제대로 우리가 원하는 방향으로 학습하기가 어렵기 때문이다. 왜냐하면 sigmoid function은 양 쪽 끝 부분이 거의 평평하기 때문에 만약 우리가 정 반대쪽 방향에서 rmse의 gradient 방향을 취하게 된다면 거의 변화가 없다고 판단할 수도 있기 때문이다. 따라서 이런 방법을 개선하기 위해서 cross entropy error를 사용하였고, 이 방법을 사용하기 위하여 sigmoid를 softmax로 바꿔서 probability distribution으로 만들어준 것이다. 아무튼 이 강의에서 설명하는 방법들은 이런 방법들에 기반해서 NN을 만든다. 아무튼 우리가 처음에 풀려고 했었던 단어를 추측하는 고전적인 방법 중에 <a href="http://en.wikipedia.org/wiki/N-gram">N-gram</a>문제라는 것이 있는데, n개의 단어 배열들을 학습하여 임의의 n-1개의 단어가 주어졌을 때 그 다음 단어가 무엇일지 예측하는 문제이다. 실제로 자연언어처리에서 많이 사용하는 기법 중 하나인데, 보통 trigram을 많이 사용한다 (3개의 단어 시퀀스를 학습) 그런데 이 경우 우리가 모든 단어를 학습할 수도 없고, 우리가 관측하지 못한 단어배열이라고 해서 세상에 존재하지 않는 단어 배열이라 확신할 수가 없기 때문에 당연히 성능 역시 좋지 않을 것이라고 예측할 수 있을 것이다. 대신 input을 앞의 2개의 단어를 취하고 그 output을 세 번째 단어로 하는 neural network를 학습할 수도 있을 것이다. 하지만 이렇게 할 경우 output의 양이 너무 많아지므로 대신 3번째 단어의 후보군들의 집합을 같이 넣어서 결과를 얻는 방식을 취할 수도 있을 것이다. 더 성능을 높이기 위해서 엄청 긴 word seqeunce를 통채로 학습하고, 임의의 단어의 앞의 n개 단어 뒤의 m개 단어를 보고 추측하는 것이 가능할 것이다. 이 경우, 지금 단어가 random인지 제대로 된 단어인지 일부러 섞어서 learning을 하게 되면 output을 binary로 받는 것이 가능해져서 엄청나게 빠른 test time을 가질 수가 있게 된다는 장점이 있다.</p>


<h5>Object recognition with neural nets</h5>


<p>우리가 물체를 인식하는 것을 매우 자연스러운 일로 생각하지만 실제로 이것을 구현하는 것은 절대로 쉬운 일이 아니다. 우리는 물체가 살짝 가려져 있어도 구분이 가능하고, 또한 해당 물체를 유동적으로 인식한다. 무슨 말인가하면, 인식 알고리듬을 디자인하는데 있어서 문제점은 (1) 물체가 다른 물체 혹은 주변 환경에 의해서 가려진 상태일 때 (2) 밝기와 조명에 따른 해당 물체의 색 변화 (pixel 정보가 변한다) (3) 같은 클래스에 속해도 조금씩 다른 모습 - 예를 들어서 손글씨 숫자는 비록 같은 숫자이나 전부 필체가 달라서 variation이 있다. (4) 물체가 정의되는 것은 모양이 아니라 다른 방법으로 결정되는 경우도 많다 - 예를 들어 의자는 모습으로 구분하는 것이 아니라 그 사용처가 어디인가에 따라 분류해야 구분할 수 있을 것이다.</p>


<p>그 밖에도 결국 우리가 사용할 수 있는 정보는 image 정보이고, 디지털 input image는 단순한 pixel map이다. 예를 들어서 1024 by 720 pixel의 사진이라고 한다면 총 737280개의 pixel이 input이 될 것이다. 각 pixel은 RGB정보를 가지고 있으므로 값은 (0,0,0) ~ (255,255,255) 사이의 값으로 정해질 것이다. 색상이 중요하지 않은 경우에는 흑백 사진으로 바꾸어 단순히 밝기로만 판단하기도 한다. 아무튼 그렇기 때문에 약간의 물체의 이동도 성능을 크게 바꿔버릴 수 있다. 단순히 옆으로 이동한 것 뿐 아니라 회전된 정보나 뒤집힌 정보는 우리가 인식 알고리듬을 작성하는데에 매우 어려운 부분으로 작용한다. 따라서 우리는 모든 정보를 normalization시켜야할 필요가 있으며 align해야 할 필요가 있다. 이런 처리 없이는 올바른 정보를 학습하기가 매우 어려워질 것이다.</p>


<p>이 강의에서는 이런 문제점들을 가지고 있는 object recognition을 neural network로 접근한다. 이런 경우 determistic method보다 훨씬 더 좋은 성능을 낼 수 있으리라는 것은 자명할 것이다. Input은 pixel map이고, output은 어떤 object인지 알려주는 label 혹은 class가 될 것이다. 이런 Hidden layer가 포함된 neural network를 backpropagation 방법을 사용하여 learning한다. 실제로 많은 image recoginition에서 neural network를 사용하고 있으며, 앞에서 설명했었던 여러 문제점들을 해결해주는 경우가 많다. 또한 아마 이런 목적을 가지고 설계된 알고리듬 중에서는 neural network가 가장 성능이 좋을 것이다.</p>




<h5>Coursera Neural Networks for Machine Learning</h5>


<p>다른 요약글들 보기 (<a href="http://SanghyukChun.github.io/blog/categories/cousera-nn/">카테고리로 이동</a>)</p>


<ul>
    <li>Lecture 1: <a href="http://SanghyukChun.github.io/39">Introduction</a></li>
    <li>Lecture 2: <a href="http://SanghyukChun.github.io/40">The Perceptron learning procedure</a></li>
    <li>Lecture 3: <a href="http://SanghyukChun.github.io/42">The backpropagation learning proccedure</a></li>
    <li>Lecture 4: <a href="http://SanghyukChun.github.io/43">Learning feature vectors for words</a></li>
    <li>Lecture 5: <a href="http://SanghyukChun.github.io/43">Object recognition with neural nets</a></li>
    <li>Lecture 6: Optimization: How to make the learning go faster</li>
    <li>Lecture 7: Recurrent neural networks</li>
    <li>Lecture 8: More recurrent neural networks</li>
    <li>Lecture 9: Ways to make neural networks generalize better</li>
    <li>Lecture 10: Combining multiple neural networks to improve generalization</li>
    <li>Lecture 11: Hopfield nets and Boltzmann machines</li>
    <li>Lecture 12: Restricted Boltzmann machines (RBMs)</li>
    <li>Lecture 13: Stacking RBMs to make Deep Belief Nets</li>
    <li>Lecture 14: Deep neural nets with generative pre-training</li>
    <li>Lecture 15: Modeling hierarchical structure with neural nets</li>
    <li>Lecture 16: Recent applications of deep neural nets</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coursera Neural Networks for Machine Learning Week3 - Backpropagation]]></title>
    <link href="http://SanghyukChun.github.io/42/"/>
    <updated>2014-03-26T00:10:00+09:00</updated>
    <id>http://SanghyukChun.github.io/42</id>
    <content type="html"><![CDATA[<h5>들어가기 전에</h5>


<p>이 글은 Geoffrey Hinton 교수가 2012년 Coursera에서 강의 한 <a href="https://class.coursera.org/neuralnets-2012-001/lecture">Neural Networks for Machine Learning</a> 3주차 강의를 요약한 글이다. 이 렉쳐에서는 Perceptron의 한계를 극복하기 위해 도입된 multi-layer feed forward network를 learning하는 algorithm인 backpropagation algorithm에 대해서 다룬다.</p>


<h5>Learning the weights of a linear neuron</h5>


<p><a href="http://SanghyukChun.github.io/40#what-perceptrons-cant-do">Lecture 2의 마지막</a>에서 다뤘던 perceptron의 가장 큰 문제점은 문제가 조금만 복잡해지거나, linear하게 표현되지 않는 문제는 올바른 결과로 수렴할 수 없다는 것이었다. 예를 들어서 엄청나게 간단한 로직인 xor은 perceptron으로 learning될 수 없다. 이런 문제를 해결하기 위해 <a class="red tip" title="이 렉쳐에서는 multi-layer perceptron이라고 지칭한다.">multi-layer feed forwad neural network</a>의 필요성이 대두된다. 일단 우리는 기존의 perceptron algorithm으로는 해당 문제를 해결할 수 없다는 것을 알고있으므로, 무언가 다른 알고리듬을 한 번 고안해보도록 하자. 가장 간단하게 생각할 수 있는 알고리듬은 어떤 error function을 정의하고 그 error를 minimize시키는 network를 learning하는 것일 것이다. 그렇다면 어떤 error function을 minimize해야할까? 간단하게 neural network의 output을 계산해서 expected value (target value)와 actual output value의 차이를 error로 정의하면 어떨까? 즉, neural network의 output이 우리가 원하는 output과 가장 근접한 weight를 learning하는 방법을 취하는 것이다. 근데 여기에서 문제가 하나 생기게 되는데, 바로 이 error function이 weight에 대해서 convex하지가 않다는 것이다. 당연히 관련되는 weight set도 엄청나게 많고, network자체가 convex한 form이 아니기 때문이다. 즉, 실제 좋은 performance를 내는 weight들의 여러 set을 취해 그 중간 값을 취해 얻은 weight가 좋은 weight가 아닐 수도 있다는 것이다. perceptron algorithm의 가장 attractive한 점은 algorithm이 convex하기 때문에 언제나 같은 값으로 converge한다는 점인데, 이런 방식으로는 그런 convergence가 보장이 안되는 것이다.</p>


<p>일단, 어쨌거나 perceptron이 적용이 안되는 상황이니깐, 위에서 정의한 error minimization의 측면에서 문제를 접근해보도록하자. 가장 간단한 예시인 Linear neuron에 대해서 살펴보자. 일단 y를 neuron을 통해서 얻어진 estimated output, w를 weight vector, x를 input vector라고 하면 다음과 같은 식을 세울 수 있다.</p>


<p>$$ y = \sum_i w_i x_i = \mathbf w^\top \mathbf x $$</p>


<p></p>

<p>이 상황에서 input vector x의 real output을 t (target output)이라고 해보자. 이런 상황에서 가장 간단한 error는 actual output과 desired output의 squared difference이다. 즉, 이를 수식으로 나타내면 \(error = \sqrt{t-y}\)로 표현할 수 있을 것이다. 우리의 목표는 이런 상황에서 weight를 iterative method를 사용하여 구하고 싶은 것이다. Iterative method라는 것은 어떤 특정한 반복적인 알고리듬을 사용하여 (예를 들어 gradient descent나 perceptron처럼) 계속 값을 update시켜나가면서 가장 적절한 것으로 보이는 값을 찾아내는 방법이다. 즉, \(w_{t+1} = f(w_t) \)로 표현이 가능하다. \(w_t\)는 t번 째 loop에서 w의 값이고, f는 w를 update하는 rule이다. 그렇다면 여기에서 잠시 궁금한 점이 생길 수 있다. 만약 우리가 target vector를 알고 있다면, 왜 문제를 analytically하게 해결하지 않을까? 즉, 우리가 이미 x와 y를 안다면 이를 가장 최적화시키는 w를 계산으로 단 한 번에 구할 수 있을 것인데, 왜 하필 iterative method를 사용하여 계속 값을 update하는 것일까? 훨씬 비효율적이지 않을까? 이 질문에 대한 알고리듬 관점에서 바라봤을 때의 답을 간략하게 말해주자면, 그런 형태의 analytic solution은 반드시 문제가 linear해야하고 또 squared error measure에 대해서만 working하기 때문인 것이 하나, 그리고 Iterative method가 조금 비효율적으로 보일지는 몰라도 더 복잡한 네트워크에 대해서 generalize하기가 더 간단힌 이유 하나를 들 수 있을 것이다.</p>


<p>이런 iterative method는 맨 처음 모든 weight를 random하게 guess하고 <a class="red tip" title="조건은 바뀔 수 있다. 예를 들어 input 3개를 보고 update하는 것도 가능하다. 뒤에서 조금 더 자세히 다루도록 하겠다.">매 input마다</a> 적절하게 weight를 update시킨다. 이 방법은 weight가 어떤 특정한 value로 converge할 때까지 계속된다. 그렇다면 이런 방법의 예를 하나 들어보자. 이 강의에서는 다음과 같은 function을 정의한다. \(price = x_{fish} w_{fish} + x_{chip} w_{chip} + x_{ketchup} w_{ketchup}\) 즉, 내가 식당에서 <a class="red tip" title="fish and chips라고 하는 요리.. 생선튀김이랑 감자튀김 같이 먹는거랑 똑같다">생선과 칩과 케첩</a>을 먹었을 때 내가 지불해야하는 금액을 내가 먹은 양 (x), 그리고 각 item들의 가격 (w)으로 나타낸 것이다. 내가 알고 있는 값은 input x (내가 시킨 양) 그리고 계산서를 통해 얻은 값이다. 하지만 나는 w를 모르며, 이 w를 찾는 것이 목적이다. 그렇다면 처음에는 random하게 w를 guess할 수 있을 것이다. 이때, (120, 50, 100)이 true weight라고 해보자. 즉, 현재 input이 2,5,3일 때 price는 850일 것이다. 현재 우리는 weight에 대한 정보가 없으므로 모두 50이라고 가정하면 내가 estimate한 price는 500이고, error의 값은 350이 된다. 이때, \(\triangle w_i = \epsilon x_i (t-y)\)라는 learning rule이 있다고 해보자. (이 learning rule은 delta-rule이라는 규칙으로, 바로 다음 단락에서 자세히 다루도록 하겠다.) 이 수식을 적용하면 다음 weight는 70, 100, 80이 되고 error는 30으로 줄어들게 된다 (esitimated price = 880, true = 850) 이런 식으로 각 iteration마다 error의 값을 줄여나가면서 true weight를 찾는 것이 iterative method의 작동원리인 것이다.</p>


<p>그렇다면 이런 방법에서 가장 중요한 개념은 아마 learning rule일 것이다. 이 렉쳐에서는 'Delta Rule'이라는 rule을 소개하고 있다. 이 방법은 일종의 Gradient Descent method인데, single layer neural network에서 주로 사용하는 방법이라고 한다. 자세한 설명은 <a href="http://en.wikipedia.org/wiki/Delta_rule">wiki</a>를 참고. 그렇다면 왜 delta-rule은 \(\triangle w_i = \epsilon x_i (t-y)\) 의 꼴을 띄고 있는 것일까? 증명은 간단하다. error를 squared residuals summation error로 정의하고 차근차근 수식을 전개하면 해당 꼴을 얻을 수 있다. wiki에도 언급이 되어 있으므로 설명이 미진하다면 wiki를 참고하면 될 것 같다. 먼저 \(E = \sum_j \frac 1 2 (t_j - y_j)^2\)이라하자. (notation은 wiki의 notation을 사용하겠다.) 이 error는 convex function이고 domain도 convex하므로 gradient descent method를 사용하면 error의 global minimum값을 반드시 찾을 수 있다. 따라서 만약 우리가 "weight space"에 대해서 이 error를 최소화하게 된다면 매 순간 minimize하기 위해 내려가는 방향 즉, 이 함수의 gradient 값은 \(\frac {\partial E} {\partial w_{ji}}\)이 될 것이다. 이때, 이 gradient descent는 error를 줄이기 위해서 필요한 weight들의 change이고, 방향은 반대이므로 \(\triangle w_{ij} = - \epsilon \frac \partial E \partial w_{ji}\)라고 할 수 있는 것이다. 그리고 뒤의 미분항을 간단하게 chain rule을 사용하여 정리하면 이전의 식은 결국 다음과 같은 수식으로 표현이 가능하다.</p>


<p>$$ \triangle w_{ij} = \epsilon (t_j - y_j)x_i $$</p>


<p>wiki에서는 active function의 미분항까지 들어가게 되는데, 이 경우는 일단 생략하였다.</p>


<p>이제 update rule을 만들었으니 필연적으로 생기는 question들을 점검해보자. (1) 이 알고리듬은 반드시 global한 값으로 converge하는가? - convex optimization이기 때문에 global truth로 converge하긴한다. 적절한 step size가 필요한데 이것은 이론적으로 구할 수 있으므로 큰 상관이 없다. (2) converge rate는 얼마나 될 것인가? - gradient descent method들이 대부분 그러하듯 많이 느릴 것이다. 이를 개선하기 위해 steepest descent method를 적용하는 등의 방법이 있는 것으로 보인다. 마지막으로 perceptron과 비교해보자. perceptron은 'error가 발생해야만' update가 일어났으며, error는 binary error였기 때문에 update가 일어나지 않을 수도 있었다. 하지만 지금은 error가 real function이므로 error는 거의 항상 non zero value가 되고 update도 지속적으로 일어난다. 또한 perceptron이 아무런 parameter tuning이 없던 것과 비교해 (margin은 일단 예외로 하자) learning rate를 골라야하는 귀찮은 문제가 하나 생기게 되었다.</p>


<h5>The error surface for a linear neuron</h5>


<p>이 소강의는 거의 언급할 내용이 없다. 앞에서 이미 이 문제가 convex임을 밝혔으며, 또한 weight space라는 concept역시 이미 언급했다. 언급되고 있는 문제는 거의 gradient descent method의 문제점들이다. 특히 convergence rate가 느린 경우, zig-zag하게 수렴하는 경우는 어떻게 해야할 것인가? 등에 대한 question만 던지는 강의이기 때문에 과감하게 생략하도록 하겠다.</p>


<h5>Learning the weights of a logistic output neuron</h5>


<p>delta rule을 logistic neuron에 대해 적용하는 것인데, 결론만 얘기하면</p>


<p>$$ \triangle w_{ij} = \epsilon (t_j - y_j) y_i (1-y_i) x_i $$</p>


<p>의 꼴이 된다. 즉, 앞에서 언급했던 activate function의 미분값인 \(y_i (1-y_i)\)가 포함되는 형태라는 것만 알아두면 된다. 다만, 이 경우에 binary threshold neuron이 아니라 logistic neuron을 쓰는 이유는 binary threshold neuron은 error가 항상 0아니면 1이기 때문에 gradient descent method를 사용할 수 없기 때문이다. 이제 간단한 배경지식을 갖추었으니 이번 렉쳐의 메인인 backpropagation으로 넘어가보자.</p>


<h5>The backpropagation algorithm</h5>


<p>자, 사실 앞에서 이런저런 얘기를 주절주절 했던 이유는 바로 backpropagation algorithm에 대해 설명하기 위해서였다. 이 algorithm은 당연히 iterative method이며, logistic neuron에 대해서 delta-rule (gradient descent method)를 적용하여 최적의 weight를 계산해낸다. 이 알고리듬은 hidden layer가 존재하는 neural network를 learning하기 위해 사용이 되는 알고리듬이며, <a class="red tip" title="backpropagation은 역전파, 즉 반대 쪽으로 영향을 미친다는 뜻이다, 이 경우는 결과를 통해 weight를 학습하기 때문에 역전파라고 부른다">이름에서 알 수 있듯</a> network의 output value에서부터 역으로 weight를 learning하게 된다. 왜 우리는 hidden layer가 존재하는 neural network를 learning해야할까? 이런 방법을 쓰지 않으면 network가 항상 linear하기 때문에 real problem을 풀 수가 없기 때문이다. 그리고 또한, hidden layer를 사용한다는 의미는 우리가 임의의 feature를 정하고, 각 feature들의 weight가 얼마나 되는지 학습을 한다는 의미와 같다. 무슨 얘기이냐하면, 만약 엄청나게 dimension이 큰 input이 있을 때 (예 - 해상도 높은 사진) 실제 algorithm을 돌릴 때 모든 input을 사용해 learning하는 것은 거의 의미가 없고 (특히 high dimension, samll input인 경우는 overfitting issue가 크게 작용한다.) 해당 알고리듬에 대입해서 실행시킬 feature를 뽑아내는 과정을 필요로 하는 경우가 많다. 그런데 대부분의 경우 우리는 이런 feature를 heuristic하게 찾는다. 즉, 사진에서 눈, 코, 입을 feature로 삼아야한다고 우리의 heuristic으로 결정하고, masking을 손으로 하고 그 결과를 알고리듬에 대입하는 것이다. 그런데 hidden layer를 사용하게 되면 그런 불필요한 행동을 줄일 수 있다. 만약 hidden unit각각이 머리카락, 눈, 입술, 코, 귀 등등을 의미하고 있다면 적절한 weight를 learning함으로써 feature에 대한 weight를 결정할 수 있고, 우리가 일일이 손으로 하던 것들을 자동화시킬 수 있는 것이다. 이렇기 때문에 hidden layer가 포함된 neural network가 powerful하고 meaningful하다. 그리고 backpropagation을 사용하는 이유는 그것이 가장 효율적이고 빠른 학습 방법 중 하나이기 때문이다.</p>


<p>Backpropagation이 아닌 다른 예를 하나 생각해보자. 예를 들어서 output을 사용하지 않고 initial weight를 주고 weight를 조금씩 변화시키면서 적절한 값을 찾을 수도 있을 것이다. (Learning using perturbations) 즉, 원하는 target value를 고정해두고 해당 value에 가장 가깝도록 weight를 하나하나 강제로 조정하면서 전체 weight를 찾아가는 다소 reinforcement learning과 비슷한 방법으로 접근하는 것이 가능할 수도 있다. 그러나 이런 방법은 큰 문제가 있다. 먼저 weight가 많아질수록 찾아야하는 값이 많아지고 computation time이 엄청나게 빠르게 증가할 것이다. 또한 이런 방법은 weight에 대해 network가 convex하다면 의미가 있을 수 있지만 당연히 hidden layer가 포함된 network는 convex하지 않다. 결국 이 방법은 우리가 상상도 하지 못할 만큼 많은 양의 computation time을 필요로 하는 좋지 못한 방법인 것이다. 심지어 아주 적은 수의 neuron만 있더라도 바로 뒤에서 설명하게 될 backpropagation이 더 성능이 우수하기 때문에 이런 방법 자체를 사용하지 않는 것이다.</p>


<p>그렇다면 이제 backpropagation algorithm에 대해 discribe해보자. backpropagation의 기본 아이디어는 우리가 hidden unit들 그 자체에 대해서 알 필요가 하나도 없고 (알 수도 없을 뿐더러), 대신 hidden unit들로 인해 생성되는 error change를 관측하는 것이 더 낫다는 것이다. 즉, hidden unit 그 자체의 activity를 learning하는 것이 아니라, hidden unit들로 인해서 생겨나는 error derivatives를 사용하자는 것이다. 이 방법은 ouput layer에서 아래 layer로 정보를 backpropagation하여 (역으로 보내어) lower layer에서 그 값을 기준으로 다시 weight를 update시킨다. input pattern은 hidden layer에 전달이 되고, 다시 hidden layer가 output layer로 전달을 시키므로 (hidden layer가 하나일 때) 이런 방법으로 현재 weight에 대한 expected value와 estimated value 사이의 error를 구할 수 있고 이것을 최소화 하는 방향으로 weight를 learning하는 것이다. weight를 learning할 때는 앞에서 우리가 이미 살펴보았던 delta-rule을 사용하여 output layer에서의 각 neuron들의 error를 사용해 weight들을 update한다.</p>


<p>이를 그림으로 표현하면 아래와 같다. (출처: <a href="http://tex.stackexchange.com/questions/162326/drawing-back-propagation-neural-network">링크</a>)</p>


<p><img src="/images/post/42-1.png" width="600"></p>

<p>Backpropagation은 크게 두 가지 phase로 나눌 수가 있는데, 하나는 propagation phase이며, 하나는 weight update phase이다. propagation phase에서는 training input pattern에서부터 에러, 혹은 각 뉴런들의 변화량을 계산하며, weight update phase에서는 앞에서 계산한 값을 사용해 weight를 update시킨다.</p>


<h6>Phase 1: Propagation</h6>


<ol>
    <li>Forward propagation: input training data로부터 output을 계산하고, 각 ouput neuron에서의 error를 계산한다. (input -> hidden -> output 으로 정보가 흘러가므로 'forward' propagation이라 한다.)</li>
    <li>Back propagation: output neuron에서 계산된 error를 각 edge들의 weight를 사용해 바로 <a class="red tip" title="이 경우는 hidden layer가 하나이므로 hidden layer를 지칭한다.">이전 layer</a>의 neuron들이 얼마나 error에 영향을 미쳤는지 계산한다. (output -> hidden 으로 정보가 흘러가므로 'back' propagation이라 한다.)</li>
</ol>


<h6>Phase 2: Weight update</h6>


<ol>
    <li>Delta rule을 사용해 weight를 update한다. update rule은 다음과 같다. (delta rule for logistic neuron)<br>
        \( \triangle w_{ij} = \epsilon (t_j - y_j) y_i (1-y_i) x_i \)</li>
</ol>


<p>위의 과정은 output layer에서부터 하나하나 내려오면서 반복된다. 즉, output -> hidden k, hidden k -> hidden k-1, ... hidden 2 -> hidden 1, hidden 1 -> input의 과정을 거치면서 계속 weight가 update되는 것이다. 그리고 이 cycle자체가 converge했다고 판단될 때 까지 계속 반복된다.</p>


<p>이렇듯 backpropagation은 직접 weight를 바로 변화시키는 것이 아니라 오직 error만을 보고 gradient descent method based approach를 사용해 error를 minimize하는 방향으로 계속 weight를 update시키는 것이다. 또한 한 번 error가 연산된 이후에는 output layer에서부터 그 이전 layer로 '역으로' 정보가 update되기 때문에 이를 backpropagation, 한국어로는 역전사라고 하는 것이다.</p>


<h5>How to use the derivatives computed by the backpropagation algorithm</h5>


<p>Overfitting과 Optimization issue가 나오는데, Online, batch update 중 무엇을 고르느냐, 어떻게 overfitting을 줄이냐 등등, 이미 예전에 많이 다뤘거나 앞으로 다시 다뤄질 주제들이라 판단되어 생략하도록 하겠다.</p>


<p>다만, backpropagation에 대해 중요한 언급이 빠져있어서 첨언을 하자면, backpropagation 은 항상 global optimum으로 converge하지 않기 때문에 언제나 local minimum으로 converge할 가능성이 존재한다. 이는 특히 hidden layer가 많아지면, 혹은 네트워크가 deep해지면 deep해질 수록 더 심해진다. 따라서 initial value를 어떻게 설정하느냐가 매우 민감하다. initial value에 따라 수렴하는 방향이 달라질 수 있기 때문인데, 나중에 배울 Deep belif network에서는 initial value를 미리 pre-training하는 방법으로 이를 극복해낸다.</p>




<h5>Coursera Neural Networks for Machine Learning</h5>


<p>다른 요약글들 보기 (<a href="http://SanghyukChun.github.io/blog/categories/cousera-nn/">카테고리로 이동</a>)</p>


<ul>
    <li>Lecture 1: <a href="http://SanghyukChun.github.io/39">Introduction</a></li>
    <li>Lecture 2: <a href="http://SanghyukChun.github.io/40">The Perceptron learning procedure</a></li>
    <li>Lecture 3: <a href="http://SanghyukChun.github.io/42">The backpropagation learning proccedure</a></li>
    <li>Lecture 4: <a href="http://SanghyukChun.github.io/43">Learning feature vectors for words</a></li>
    <li>Lecture 5: <a href="http://SanghyukChun.github.io/43">Object recognition with neural nets</a></li>
    <li>Lecture 6: Optimization: How to make the learning go faster</li>
    <li>Lecture 7: Recurrent neural networks</li>
    <li>Lecture 8: More recurrent neural networks</li>
    <li>Lecture 9: Ways to make neural networks generalize better</li>
    <li>Lecture 10: Combining multiple neural networks to improve generalization</li>
    <li>Lecture 11: Hopfield nets and Boltzmann machines</li>
    <li>Lecture 12: Restricted Boltzmann machines (RBMs)</li>
    <li>Lecture 13: Stacking RBMs to make Deep Belief Nets</li>
    <li>Lecture 14: Deep neural nets with generative pre-training</li>
    <li>Lecture 15: Modeling hierarchical structure with neural nets</li>
    <li>Lecture 16: Recent applications of deep neural nets</li>
</ul>

]]></content>
  </entry>
  
</feed>
