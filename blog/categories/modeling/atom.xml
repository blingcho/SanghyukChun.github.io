<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Modeling | README]]></title>
  <link href="http://SanghyukChun.github.io/blog/categories/modeling/atom.xml" rel="self"/>
  <link href="http://SanghyukChun.github.io/"/>
  <updated>2014-10-10T06:37:16+09:00</updated>
  <id>http://SanghyukChun.github.io/</id>
  <author>
    <name><![CDATA[Sanghyuk Chun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Network Science - Scale Free Network (Barabasi-Albert Network)]]></title>
    <link href="http://SanghyukChun.github.io/52/"/>
    <updated>2014-04-23T15:33:00+09:00</updated>
    <id>http://SanghyukChun.github.io/52</id>
    <content type="html"><![CDATA[<h5 id="52-1-before">들어가기 전에</h5>


<p>이 글은 <a href="http://SanghyukChun.github.io/47" target="new">2014년 KAIST Network Science 수업</a> 중 Scale Free Network 내용을 요약한 글이다. 이 렉쳐에서는 Scale Free Network라는 concept에 대해 다루게 된다.</p>


<h5 id="52-2-scalefreenetwork">Scale Free Network</h5>


<p>이전 글들에서 <a class="red tip" title="따로 글로 정리를 하지는 않았지만, Watts-Strogatz를 설명하면서 다뤘던 부분이다.">Regular Network</a>, <a href="http://SanghyukChun.github.io/50" target="new">Random Network</a>와 <a href="http://SanghyukChun.github.io/51" target="new">Small world Network</a>에 대해 다뤘던 것들 중 Path length, Clustering coefficient, 그리고 Degree distribution 부분을 정리해보자.</p>


<p>먼저 Path length이다. 우리가 관측하는 대부분의 network들은 Path length가 그 크기의 logarithm function으로 표현된다는 것을 알 수 있다. 조금 더 구체적으로 표현하자면 \(l_{rand} \approx {\log N \over \log \bar k}\)로 표현이 된다. 먼저 Regular Network의 path length는 \(l \approx N^{1/D}\)로 표현이 된다. 우리가 원하는 log 와는 다른 형태임을 알 수 있다. 그렇다면 Random Network와 Small world Network는 어떨까? 이전 결과들을 통해 확인할 수 있듯 \(l_{rand} \approx {\log N \over \log \bar k}\)로 표현이 된다는 사실을 알 수 있다. 즉, Erdös-Rényi Network와 Watts-Strogatz Network는 일반적으로 우리가 관측하는 네트워크와 비슷한 Path length를 지니고 있고 Regular Network는 그렇지 않음을 알 수 있다.</p>


<p>Clustering coefficient는 어떠한가? 대부분의 실제 네트워크의 clustering coefficient는 그 크기에 무관하게 항상 상수로 표현된다. 즉, \(C \sim const \)로 표현이 된다. Regular network와 small world network가 이 값이 상수임에 반해, Random network는 이 값이 \(C = p = {\bar k \over N}\)으로 표현이 된다. 즉, 크기가 커질수록 이 값이 감소하는 경향을 보이는데 이 부분은 실제 네트워크와 큰 차이가 있는 부분이다. 즉, Random network는 실제 네트워크보다 뭉침 현상이 덜 하고, Regular Network와 Small world network는 실제 네트워크와 그 뭉침 정도가 비슷하다는 것을 알 수 있다.</p>


<p>그렇다면 지금까지의 결론을 보면 Small world Network만 Path lenth, 그리고 Clustering의 두 가지 측면에서 실제 네트워크와 유사함을 알 수 있다. 그렇다면 마지막 Degree distribution은 어떠한가? 실제 네트워크에서 나타나는 degree distribution은 power law distribution으로 표현이 된다. 즉, \(P(k) \sim k^{-\gamma}\)로 표현이 된다. 그런데 Regular Network의 degree distribution은 \(P(k) = \delta (k-k_d)\)이며 Random Network는 \(P(k) = e^{-\bar k} {\bar k ^k \over k!}\)로 표현이 된다. 그리고 Small world network의 degree 역시 exponential function으로 표현이 된다. 즉, 지금까지 우리가 살펴본 그 어떤 네트워크도 실제 네트워크와 유사한 degree distribution을 보이지 않음을 알 수 있다.</p>


<p>이러한 문제점, 즉, degree distribution이 잘 맞지않는다는 문제점으로 인하여 새로운 Scale-Free network라는 개념이 등장하게 된다. Scale-Free network란 degree를 \(k\)라 했을 때 degree sequence \(g'\)이 power-law function \(h(k) \sim k^{-q}\)로 표현이 되는 네트워크를 의미한다. 이 때 exponent \(q\)의 값은 보통 2에서 3 사이로 결정이 된다. 수학적이지 않은 관점에서 바라본다면 scale-free network는 적은 숫자의 high degree node가 있고 그 이외의 많은 node들은 엄청 작은 degree를 가지는 네트워크를 의미한다. 그리고 이런 degree가 높은 node를 일컬어 hub라고 부르게 되며, 다시 말하자면 Scale-Free Network란 hub가 존재하는 네트워크를 의미하게 된다. 이 현상은 사실 생각해보면 우리 주변에도 많이 발생하는데, <a class="red tip" title="영어 단어의 분포는 그 단어의 빈도의 순위의 역수로 표현된다. 즉, 상위 일부가 전체 대다수를 차지한다.">Zipf의 법칙</a>나 <a class="red tip" title="상위 20%가 80%의 부를 가져간다는 법칙. 보통 2:8의 법칙으로 불린다">Pareto의 법칙</a> 등의 관측도 존재하고, 실제 social network에서도 친구가 엄청나게 많은 일부의 사람들이 존재하고 나머지 사람들은 그보다는 적은 사람의 친구를 가지는 등, 이미 hub라는 현상은 우리가 자연스럽게 받아들일 수 있는 개념이라는 것이다.</p>


<p>그렇다면 degree가 exponential인 것과 power-law인 것이 정말 크게 차이가 날까? 만약 그게 아니라면 우리는 충분히 Watts-Strogatz의 결과물을 사용할 수 있을 것이다. 아래 그 둘을 비교한 그림이 있다.</p>


<p><img src="/images/post/52-1.png" width="400"></p>

<p>이 그림을 통해 알 수 있듯, exponential과 power-law는 그 기울기의 감소 정도가 매우 많이 차이가 난다는 것을 알 수 있고, 우리는 degree distribution이 power-law를 가지는 새로운 network가 필요하다는 것을 알 수 있다. 이런 Scale-Free Network는 1999년 Alber, <a class="red tip" title="KAIST 물리과 정하웅 교수님">Jeong</a>, Barabasi에 의해서 처음 연구가 되었으며, 이런 네트워크를 만드는 과정을 Barabasi-Albert Procedure라고 부른다. 그렇다면 Scale-Free라는 이름은 왜 생긴 것일까? Small-world라는 말이 diameter의 증가 정도가 네트워크의 증가 속도보다 훨씬 느리기 때문에 붙은 알이라면, Scale-Free는 degree가 증가하는 정도와 실제 distribution이 같은 속도로 증가함을 의미한다. 수식으로 나타내자면 \(h( \alpha k = \beta h(k)\)로 표현이 된다. 즉, x-axis로 factor \(\alpha\) 만큼 scaling을 한 결과는 y-axis에 factor \(\beta\) 만큼 scaling을 한 것과 같다는 것이다. 따라서 이 power-law curve를 factor \(\alpha\)로 scaling을 하더라도 그 모양은 단순히 위아래로 움직이기만하는 형태로 표현이 된다는 것이다. 즉, 그 우리가 Scaling을 하더라도 그 형태가 변하지 않는 Scale-Free한 Network라는 것이다.</p>




<h5 id="conclusion">Conclusion</h5>


<p>Scale-Free Network를 한 번 정리하고 넘어가보자. 먼저 Scale-Free란 degree distribution이 power-law로 표현되는 network이며, 토폴로지 관점에서 봤을 때 Small-world와 Random network 사이 쯤에 존재하는 네트워크이다. 아래 그림을 보면 엔트로피와 Clustering Coefficient, Average path length, hub degree를 모두 비교해본 결과인데 이 결과를 보면 다른 네트워크와 비교했을 때 다른 값들은 대체로 높지만 상대적으로 뭉침 정도가 약함을 알 수 있다.</p>


<p><img src="/images/post/52-10.png" width="500"></p>

<p>Scale-free network의 entropy는 \(I(G) \sim O( \log_2 ( \Delta m) = O( \log_2 (density(n/2)))\)임을 알 수 있다. 이는 small-world network의 \(I(G) \sim O( \log_2 p )\)와 비슷한 결과이며, 따라서 엔트로피의 관점에서 봤을 때 random network보다는 small-world network에 가까움을 알 수 있다.</p>


<p>Path length는 fixed n에 대해 \(l = A - B k_{hub} \sim O({ \log (n) \over \log (n) + \log (density)}) \)으로 표현이 된다. 그리고 cost-effectiveness라는 것도 정의가 되는데, \(E = {1-\bar {l(density)} \over m}\)으로 표현이 되며 Density는 \(2 \frac {m} {n(n-1)}\)으로 표현이 된다. ========</p>


<p></p>




<h5>KAIST Network Science</h5>


<p>다른 요약글들 보기 (<a href="http://SanghyukChun.github.io/blog/categories/network-science/" target="new">카테고리로 이동</a>)</p>


<ul>
    <li>Lecture 1: <a href="http://SanghyukChun.github.io/47" target="new">Introduction</a></li>
    <li>Lecture 2: <a href="http://SanghyukChun.github.io/48" target="new">Graph Theory</a></li>
    <li>Lecture 3: <a href="http://SanghyukChun.github.io/49" target="new">Measures and Metric</a></li>
    <li>Lecture 4: <a href="http://SanghyukChun.github.io/50" target="new">Random Network</a></li>
    <li>Lecture 5: <a href="http://SanghyukChun.github.io/51" target="new">Small world Network</a></li>
    <li>Lecture 6: <a href="http://SanghyukChun.github.io/52" target="new">Scale free Network</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Network Science - Small World Network (Watts-Strogztz Network)]]></title>
    <link href="http://SanghyukChun.github.io/51/"/>
    <updated>2014-04-23T13:06:00+09:00</updated>
    <id>http://SanghyukChun.github.io/51</id>
    <content type="html"><![CDATA[<h5 id="51-1-before">들어가기 전에</h5>


<p>이 글은 <a href="http://SanghyukChun.github.io/47" target="new">2014년 KAIST Network Science 수업</a> 중 Small World Network 내용을 요약한 글이다. 이 렉쳐에서는 Small World Network라는 concept과 실제 그런 컨셉을 적용한 Network model 중 하나인 Watts-Strogztz Network에 대해 다루게 된다.</p>


<h5 id="51-2-problemofrandomnetwork">Prolem of Random Network</h5>


<p><a href="http://SanghyukChun.github.io/50#50-10-problems" target="new">이전 글</a>에서 다뤘 듯, Random Network는 실제 Network와 맞지 않는 부분이 많이 존재한다. 가장 큰 문제는 degree distribution과 clustering coefficient가 실제 network 분포와 크게 반하다는 점이다. 따라서 이 글에서는 그런 점들을 개선시킨 새로운 컨셉의 네트워크 모델링에 대해서 다루게 될 것이다. 사실 이 Small world network라는 것이 맨 처음 1998년도 논문으로 발표가 되었을 때 그 기반이 되는 Network가 <a href="http://en.wikipedia.org/wiki/Regular_graph" target="new">Regular Network</a>이기 때문에 이런 Regular Network에 대해서도 다룬 이후에 Small World Network를 다루는 것이 맞다고 생각하지만, 실제 강의 내용에서 Regular Network 생략되었기 때문에 나 역시 이 글에서 Regular Network에 대해서는 많이 다루지 않을 생각이다. 참고로 Regular Network는 모든 vertex가 같은 degree를 가지는 Network를 의미하며 k-regular network라고 하면 모든 vertex의 mean degree가 \(k\)라는 의미이다. 그런데 이 lecture에서는 local degree의 값이 \(k\)가 아니라 \(2k\)이며 \(k= {m \over n}\)으로 정의한다. 엄청나게 헷갈리기는 하지만.. 일단 lecture의 notation을 따르도록 하겠다. 즉, 2-regular network는 local degree가 4이며 즉, 각 vertex는 4개의 edge를 가진다. 실제 이 chapter 자체가 2-regular network를 small world network로 바꾸는 Watts-Strogztz Network에 대한 내용이므로 이 점을 꼭 숙지하고 넘어가야한다.</p>


<h5 id="51-3-smallworldnetwork">Small World Network</h5>


<p>Small world network란 예전 <a href="http://SanghyukChun.github.io/34#34-2-smallworld" target="new">인터넷 속의 수학</a>에서도 간략하게 다뤘던 내용이므로 예전 글을 참고해도 좋을 것 같다. Small World Network란 높은 clustering coefficient를 가지고 있고, 상대적으로 짧은 diameter를 가지고 있으며 entropy가 scalable한 sparse network를 의미한다. 여기에서 여러 가지 용어들이 나오는데, clustering coefficient는 넘어가도 되고, diameter는 network에서 가장 긴 shortest path, 그리고 entrophy는 이 graph를 나타내기 위한 information의 양을 의미한다. 마지막으로 sparse network라는 것은 모든 vertex pair사이에 edge가 존재하는 것이 아니라 edge가 존재하지 않는 vertex pair가 존재한다는 의미이다. Small world network는 regular network와 random network의 중간 정도 쯤 되는 network인데, 역시 이것도 <a href="http://SanghyukChun.github.io/34#34-3-poissonregularnetwork" target="new">이전 글</a>에서 다뤘던 내용이므로 관심이 있다면 간략하게 읽어보기를 권한다. 간단하게 설명하면 Samll world network는 regular network에 적당한 randomness를 추가하여 얻을 수 있기 때문에 이 두 개의 네트워크의 중간 정도라고 표현하는 것이다.</p>


<p>사실 이 Small world라는 단어는 Stanley Milgram의 6 degree 실험에서 처음 등장한 것인데, 이 실험에 대한 자세한 설명은 <a href="http://SanghyukChun.github.io/32#32-3-milgramexp" target="new">이전에 적은 글</a>을 참고하기를 바란다. 이 실험의 결론만 얘기하자면 실제 social 네트워크에서는 임의의 vertex pair를 선택했을 때 그 둘 사이를 지르는 가장 짧은 path의 길이가 network의 크기에 비해서 엄청나게 짧다는 것이다. 이 실험에서는 실제 미국 내의 네트워크에서 6개의 step이면 상대방에게 도달할 수 있다는 것을 알 수 있었다. (심지어 shortest path도 아니고 greedy search 였음에도 불구하고) 이 글에서 설명하게 될 Small world network 역시 상대적으로 짧은 diameter를 가지게 되고, clustering coefficient와 closeness centrality도 높다.</p>


<h5 id="51-4-wattsstrogatz">Watts-Strogatz Procedure</h5>


<p>그러면 이제 small world network를 generate하는 방법에 대해 생각해보자. 이 과정을 Watts-Strogatz Procedure라고 부른다. 이 algorithm은 k-regular network를 small world network로 만드는 알고리듬인데, 주어진 k-regular network의 임의의 \(pm\) 개의 edge를 random하게 rewire를 시킴으로써 얻을 수 있다. 즉, 내가 임의로 regualr network에서 p의 확률로 하나의 edge를 random 한 edge로 바꿔주는 과정을 계속 반복하기만 하면 된다. 이런 과정을 통해 우리는 regular network에 강제적으로 randomness를 주입할 수 있게 되며, \(p\)가 약 1~4% 정도가 되면 small-world effect가 나타난다고 한다. 이 \(p\)의 값 0.01 ~ 0.04를 transition threshold 혹은 crossover point라고 한다.</p>


<p>놀라운 사실은, 이렇게 간단한 algorithm을 적용하기만 해도 degree sequence distribution, diameter, average path length 등의 정보가 크게 달라지게 된다. 특히 diameter와 average path length는 아주 조금의 randomness만 주입하게 되어도 그 값이 크게 감소하게 되는데, 이런 극적인 거리 감소 현상을 곧 small-world effect라고 하는 것이다.</p>


<p>이런 과정을 통해 얻어지는 Small world network는 아래 그림과 같다. 이 그림은 vertex가 20개 있는 2-regular network를 WS procedure를 사용해 reconstruct한 것으로, p의 값이 점점 올라가면서 그 모양이 바뀌는 모습을 관측한 것이다.</p>


<p><img src="/images/post/51-1.png" width="600"></p>

<p>자 그런데 지금까지 설명한 방법은 완전히 random procedure이기 때문에 connected graph를 보장할 수 없다. 어떻게 이것을 개선시킬 수 있을까? 간단하게 생각할 수 있는 방법으로는 만약 선택한 edge를 제거했을 때 isolated vertex가 생기는 경우 해당 edge를 바꾸지 않도록 하는 방법이 있을 수 있을 것이다. 2000년도 뉴먼이 제시한 NSWS model에서는 이런 문제를 해결한 새로운 알고리듬을 제시했다고 하는데 <a href="http://arxiv.org/pdf/cond-mat/0001118.pdf" target="new">논문</a>은 찾은 것 같은데 자세히 읽어보지는 못했다.</p>


<h5 id="51-5-degreedist">Degree Sequence Distribution</h5>


<p>Degree Sequence는 Graph \(G\)의 모든 \(n\) vertex들의 degree value 들의 sequence이며 \(g=[d_1, d_2, d_3, ..., d_n ]\) 과 같이 표현된다. 그리고 이것의 distribution, 즉, degree가 1인 node 들의 비율, 2인 node들의 비율.. 등등을 표현하는 distribution은 \(g' = [h_1, h_2, h_3, ... h_{max_d}]\) 라고 표현할 수 있다.</p>


<p>맨 처음 k-regular network의 모든 vertex들이 가지는 edge의 개수는 \(2k\)이다. 그런데 \(p\)의 확률로 edge가 변경되더라도 결국 평균 edge의 개수, 혹은 connectivity는 \(c=2k\)로 고정될 것이라는 사실을 알 수 있다. 자 이제 \(P_p (c)\)를 degree의 probability distribution이라고 해보자. vertex들의 2k connection 중 k개의 connection은 아직 still untouched 일 것이므로, 이런 상황에서 vertex i의 connectivity는 \(c_i = k+n_i \ n_i \geq 0 \)라는 것을 알 수 있다. 이제 \(n_i \)라는 것도 두 가지 부분으로 나눠 생각할 수 있는데, 먼저 \(n_i^1 \leq k \) 은 \(1-p\)의 확률로 rewire되지 않는 link e들의 개수이고, \(n_i^2 = n_i - n_i^1\) 은 그 반대로 vertex \(i\)에 reconnected된 edge들을 의미한다. 그리고 총 \(N\)개의 vertex가 있다고 했을 때, 임의의 edge가 vertex \(i\)로 rewire될 확률은 \(p \over N \)라는 것도 알 수 있다.</p>


<p>그렇다면 우리는 이 사실을 통해 small world network의 degree sequence distribution을 다음과 같은 과정을 통해 얻을 수 있게 된다.</p>


<p>$$ P_1 (n_i^1) = {k \choose n_i^1} (1-p)^{n_i^1} p^{k-n_i^1} $$</p>


<p>$$ P_2 (n_i^2) = {(kp)^{n_i^2} \over n_i^2 !} e^{-pk} \ for \ large \ N $$</p>


<p>$$ P_p (c) = \sum_{n=0}^{min(c-k, k)} {k \choose n} (1-p)^n p^{k-n} {(kp)^{c-k-n} \over (c-k-n)!} e^{-pk} \ c \geq k $$</p>


<p>아래 그림은 degree sequence distribution \(P_p (c)\)를 connectivity \(c=2k\)에 대해 표현한 것이다.</p>


<p>  <br/>
<img src="/images/post/51-2.png" width="600"></p>

<p>이 그림을 통해 우리는 degree sequence distribution이 평균값이 \(\bar c = 2k\)인 Poisson 분포임을 알 수 있다.</p>


<p>이번에는 random network와 실제 network data, 그리고 앞서 서명한 과정을 사용해 만들어낸 network의 degree distribution을 비교한 그림을 살펴보자</p>


<p><img src="/images/post/51-3.png" width="600"></p>

<p>이 그림을 통해 우리는 random network보다 small world network가 더 실제 네트워크와 더 비슷하다는 것을 알 수 있다.</p>


<h5 id="51-6-entropy">Entropy</h5>


<p>앞서 정의했었던 Degree sequence distribution을 사용하면 Graph의 entropy \(I(G)\)를 정의할 수 있는데 이 값은 곧 네트워크를 표현 하기 위한 information의 양을 의미한다. 당연히 Regular Network는 Entropy가 낮고 Random Network는 Entropy가 높다. 다시 말해서 Graph \(G\)의 Entropy는 그 graph의 randomness를 bit로 표현한 값이 되며, 이 randomness는 다시 말해서 degree sequence \(g'\)으로 다음과 같이 나타낼 수 있다.</p>


<p>$$ I(G) = - \sum_{i=1}^{max_d} h_i (\log_2 h_i), \ where \ g' = [h_1, h_2, h_3, ... h_{max_d}] $$</p>


<p>이 값을 확률 2-regular network를 \(p\)의 확률로 edge를 rewire하는 경우에 대해 ploting을 해보면 다음과 같은 결과를 얻을 수 있다.</p>


<p><img src="/images/post/51-4.png" width="600"></p>

<p>즉, 엔트로피는 확률 \(p\)의 log scale로 증가하게 된다. 또한 entropy의 정의에 따라 이 값은 \(I_{WS} = -\sum_k h(d) \log_2 h(k) \)로도 표현이 된다. 이런 결과들을 통해 우리는 small world network가 scalable하다는 것을 알 수 있는데 왜냐하면 \(p\)가 0이면 엔트로피의 값은 regular network와 같은 0이지만 \(p\)가 증가함에 따라서 우리가 원하는 entropy를 randomness를 조절함으로써 얻을 수 있기 때문이다. 따라서 이런 Small world network는 scalable하다는 것을 알 수 있다. (일단 수업에서 배운대로 정리를 하기는 했지만 이부분은 너무나도 모호하다. 아무래도 네트워크의 scalable의 definition을 추가로 찾아보고 알아봐야 할 것 같다)</p>


<h5 id="51-7-entropyvsdensity">Entropy vs Density</h5>


<p>k-regular network의 density는 단순하게 \(density = 2 { k \over n }\)으로 계산할 수 있으며, 따라서 우리는 \(k = n {density \over 2}\) 라는 사실을 알 수 있다. 이 값을 통해서 우리는 small world network의 entropy와 density의 관계를 유추할 수 있다. 즉, parameter \(A, B, C\)를 주고 그 값에 대해 \(I_{WS(density)} = A log_2 B(density) - C \) 라는 엔트로피 식을 적을 수 있다. 이 때 \(A, B, C\)를 각각 0.5, 60, 0 이라고 한다면 이 식은 \(I_{WS(density)} = 0.5 log_2 (60(density)) = O(log_2 (density)) = O \left(log_2 \left( \sqrt {k \over n} \right) \right)\) 임을 알 수 있다. 즉, 우리는 entropy가 density에 \(O(\log_2 density)\)의 형태로 표현된다는 것을 알 수 있으며 이 값은 random network의 \(O(density)\)보다 훨씬 덜 가파른 증가율이라는 것을 알 수 있다. 죽, 조금 더 자세히 말하자면 Small world network의 density의 증가률 혹은 rewiring probability의 증가율에 대한 entropy의 증가율은 random network의 그것보다 훨씬 더디게 증가함을 알 수 있다. 이것을 Density에 대해 ploting하게 되면 아래와 같은 결과를 얻게 된다. (일단 3개의 term 중에서 entropy만 보면 된다)</p>


<p><img src="/images/post/51-5.png" width="600"></p>

<p>다시 한번 정리하자면, small world network에서 density와 entropy는 logarithm relationship을 가진다.</p>


<h5 id="51-8-nmweq">Newman, Moore, and Watts Equation</h5>


<p>먼저 간단한 observation들을 나열해보자. 먼저 rewiring 이 없는 2-regular network는 average path가 \(n \over 4k\)로 표현이 된다. 그리고 바로 전 section에서 본 그림처럼 매우 작은 rewiring probability \(p\)에 대해서 average path length는 매우 빠르게 감소함을 알 수 있다. 그리고 마지막으로 어떤 early point \(p^*\)가 존재해서 이 값보다 작은 rewiring probability를 가진 small world network는 regular에 매우 가깝고 그보다 큰 값을 가지는 네트워크는 random에 더 가깝다. 이 지점을 우리는 crossover, 혹은 transition threshold라고 부르며 이런 현상을 네트워크의 phase transition이라 부른다.</p>


<p>Average path length는 \(p=0\)에서 \(n \over 4k\)의 값을 가지며, \(p\)가 증가함에 따라 감소한다. 이때 \(r=2pm\)이라는 값을 정의하면 \(r\)에 대한 path lenth scaling function을 아래와 같이 표현할 수 있다.</p>


<p>$$ f(r) = 4 {\tanh^{-1} {r \over \beta} \over \beta }; \ where \beta = \sqrt{r^2 + 4 r} $$</p>


<p>또한 average path length는 다음과 같이 표현이 된다.</p>


<p>$$ \bar L_{SW} = n {f(r) \over 2k} = {2n \over \beta k} tanh^{-1} {r \over \beta} $$</p>


<p>만약 \(n=100, m=200, k=2, density=0.04, p=0.04\)라는 조건을 넣고 이 값을 계산하면 average path length는 11.7이라는 값을 얻을 수 있다. 그런데 이 값은 ====</p>


<h5 id="51-9-avgpathlength">Average Path Length</h5>


<p>작성중</p>


<p>$$ log_2 \bar L(r) = \log_2 \left( {n \over 4k} \right) - q \log_2 r $$</p>


<p>$$ \bar L(r) = {n/4k \over r^q }, \ where \ r=pkn $$</p>


<p>즉, 이 값들을 통해 우리는 \(p\)가 0이 아닐 때 (0이면 regular network와 같은 값이 된다) 이 평균 path length는 \(\bar L(r) = {n/4k \over (pkn)^q }\) 로 표현된다는 것을 알 수 있다.</p>


<h5 id="51-10-clusteringcoefficient">Clustering Coefficient</h5>


<p>작성중</p>


<h5 id="51-11-closness">Closeness Centrality</h5>


<p>작성중</p>


<h5 id="51-12-search">Seach in Small World Network</h5>


<p>작성중</p>


<h5 id="51-13-conclusion">Conclusion</h5>


<p>자 이렇게 small world network에 대해 살펴보았다. Small world Network는 Regular Network에 확률 \(p\) 만큼 randomness를 부여해 만들어지는 graph이며, 이 randomness는 scalable하며, random network와 비교했을 때 훨씬 낮은 entropy를 가진다.또한 이런 small world network의 topology는 매우 높은 clustering coefficient와 closeness를 가지게 된다. 또한 그 크기에 비해 상대적으로 짧은 average path와 diameter를 가지게 된다. (그리고 이 특성 자체가 small world effect를 지칭하는 것이기도 하다) 그리고 small world network에서 가장 좋은 search algorithm은 max-degree search 알고리듬이라는 것도 알 수 있었다.</p>


<p>다만, 거의 대부분의 좋은 성질을 가지고 있음에도 불구하고 Small world network 혹은 Watts-Strogatz Model에는 real network와 반하는 특성이 하나 있는데, 바로 degree distribution이다. 일반적인 real network의 degree distribution이 \(P(k) \simeq k^{-\gamma}\)로 표현되는 것에 비해, WS model은 exponetial degree distribution을 가지게 된다. 따라서 이런 문제를 해결하기 위해서 우리는 degree distribution이 power law distribution으로 나타나는 새로운 형태의 network인 scale-free network에 대해 다루게 될 것이다.</p>




<h5>KAIST Network Science</h5>


<p>다른 요약글들 보기 (<a href="http://SanghyukChun.github.io/blog/categories/network-science/" target="new">카테고리로 이동</a>)</p>


<ul>
    <li>Lecture 1: <a href="http://SanghyukChun.github.io/47" target="new">Introduction</a></li>
    <li>Lecture 2: <a href="http://SanghyukChun.github.io/48" target="new">Graph Theory</a></li>
    <li>Lecture 3: <a href="http://SanghyukChun.github.io/49" target="new">Measures and Metric</a></li>
    <li>Lecture 4: <a href="http://SanghyukChun.github.io/50" target="new">Random Network</a></li>
    <li>Lecture 5: <a href="http://SanghyukChun.github.io/51" target="new">Small world Network</a></li>
    <li>Lecture 6: <a href="http://SanghyukChun.github.io/52" target="new">Scale free Network</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Network Science - Random Network (Erdös-Rényi Network)]]></title>
    <link href="http://SanghyukChun.github.io/50/"/>
    <updated>2014-04-22T11:37:00+09:00</updated>
    <id>http://SanghyukChun.github.io/50</id>
    <content type="html"><![CDATA[<h5 id="50-1-before">들어가기 전에</h5>


<p>이 글은 <a href="http://SanghyukChun.github.io/47" target="new">2014년 KAIST Network Science 수업</a> 중 Graph theory 내용을요약한 글이다. 이 렉쳐에서는 가장 기초적인 Network modeling 중 하나인 random network에 대해 다룬다.</p>


<h5 id="50-2-why">Why we need network model?</h5>


<p>이 글을 포함해 3개의 강의는 모두 네트워크 모델링과 관련된 내용이다. 이 글은 random network, 그리고 다음 글은 순서대로 small world network, 그리고 그 다음은 scale free network에 대해 다루게 된다. 이런 네트워크 모델링을 우리는 왜 알아야할까. 사실 이유는 간단하다. 그냥 네트워크를 사용해 무언가를 분석하는 것이 매우 어렵기 때문이다. 예를 들어서 우리는 실제 social network가 어떻게 구성되어있는지 알지못한다. 만약 우리가 실제 네트워크와 매우 유사한, 그러나 훨씬 간단한 형태의 모델을 만들게 된다면 해당 네트워크에서 발생하게 될 일들을 쉽게 예측할 수 있을 것이다. 이 글에서 다루게 되는 random network는 그러한 네트워크 모델링 중에서 가장 간단한 모델 중 하나이다.</p>


<h5 id="50-3-random-graph">Random Graph</h5>


<p>Random graph란 어떤 fixed parameter를 가지는 stochastic 모델이다. Notation은 \(G(n,p)\) 로 적게 되는데, n은 vertex의 개수, p는 각각의 vertex pair들이 서로 edge를 가질 independent probability를 의미한다. 즉, 이 network는 확률 p로 인해 edge가 생성되므로 매번 새로 generate할 때 마다 그 결과가 달라지는 stochastic model인 것이다. 따라서 우리가 n개의 vertex와 m개의 edge를 가지는 임의의 network \(G(n,m) \)를 얻게 될 확률은 \(P(G) = p^m (1-p) ^ { {n \choose 2} - m} \) 로 얻을 수 있다. 이러한 모델을 맨 처음 수학적으로 이를 분석했던 사람들의 이름을 따서 Erdös-Rényi model 이라고도 하고 그 degree와 edge의 distribution이 Poisson혹은 Bernoulli 분포를 따르기 때문에 Poisson random graph 혹은 Bernoulli random graph라고 하기도 한다.</p>


<h5 id="50-4-meanedgedegree">Mean Edge and Mean Degree in Random Graph</h5>


<p>아런 Random graph에서 n과 p가 주어졌을 때, graph가 generate가 될 때마다 항상 edge의 개수는 달라지지만, 이것이 특정 확률을 따르기 때문에 평균 edge의 개수를 계산하는 것이 가능하다. 계산하기 전에 간단하게 생각하면 n개의 vertex에 존재하는 모든 pair들 중 확률 p로 edge를 가지기 때문에 평균 edge의 개수는 모든 pair의 개수에서 edge가 존재할 확률인 p를 곱한 \( {n \choose k} p\) 가 될 것이다. 그렇다면 정말 그런지 확인해보도록 하자. 그러면 먼저 m개의 edge를 가지는 임의의 Graph \(G(m)\) 이 generate될 확률을 구해보자. 이 갚은 바로 위에서 edge가 m개인 graph \(G(m)\) 하나가 표현될 확률을 계산했으므로, 이런 graph의 개수를 count한 후 간단하게 이를 summation하면된다.</p>


<p>$$ P(m) = { {n \choose 2}  \choose m} p^m (1-p)^{ {n \choose 2} - m} $$</p>


<p>위에서 우리는 m에 대한 확률 분포를 구했기 때문에 m의 평균 값은 간단하게 \(\sum_m mP(m)\) 으로 계산할 수 있다. 그런데 \(m\)의 확률 분호 \(P(m)\)은 \(n\)이 \({n \choose m}\) 이고 \(k\)가 \(m\)인 binomial distribution이다. 또한 우리는 binomial distribution의 mean value가 단순하게 \(np\) 임을 알고 있으므로 평균 값은 아래와 같이 계산할 수 있다. 이에 대한 자세한 설명은 <a href="http://en.wikipedia.org/wiki/Binomial_distribution" target="new">위키피디아 링크</a>로 대체한다.</p>


<p>$$ \bar m = \sum_{m=0}^{n \choose 2} m P(m) = {n \choose 2} p $$</p>


<p>이 결과는 우리가 처음 예측한 값과 정확히 일치한다.</p>


<p>그러면 이제 degree의 평균 값을 구해보자. 그 이전에 이번에는 mean degree가 얼마일지 간단하게 생각해보자. 이때 mean degree라는 것은 결국 한 vertex에서 가지는 평균 edge의 개수를 의미하기 때문에 평균 edge개수인 \({n \choose k}p\)를 vertex pair 개수인 \(n \over 2\)로 나눠준 값인 \((n-1)p\) 가 될 것이라고 예측할 수 있다. 그렇다면 실제로 계산해보자. <a href="http://SanghyukChun.github.io/48#48-7-degree">이전 글</a>에서 이미 우리가 유도했던 것처럼 edge가 \(m\)개 있는 graph의 mean degree는 \(2m \over n\)으로 구할 수 있다. 따라서 평균 degree는 위에서 우리가 edge의 평균 개수를 구한 것 처럼 간단히 구할 수 있다.</p>


<p>$$ \bar k = \sum_{m=0}^{n \choose k} {2m \over n} P(m) = {2 \over n} {n \choose 2} p = (n-1)p $$</p>


<p>역시 처음에 예측한 값과 일치한다. 참고로 random graph에서 평균 degree는 \(c\)라는 notation으로 표기가 되며, 따라서 \(c=(n-1)p\)이다.</p>


<h5 id="50-5-degreedist">Degree Distribution</h5>


<p>그렇다면 이번에는 degree의 distribution을 알아보자. 평균 degree의 개수도 물론 중요하지만 실제 degree가 어떻게 분포하고 있는지를 아는 것도 매우 중요하다. 왜냐하면 결국 network의 특성을 이해하기 위해서는 개별 node들이 얼만큼 다른 node들과 연결되어있는지 알아야하며, 이 결과가 네트워크에 어떤 결과를 불러올지 파악하는 것이 매우 중요하기 때문이다. 그렇다면 먼저 간단하게 하나의 vertex가 \(k\)개의 다른 vertex와 연결되어있는 상황이 발생할 확률을 계산해보자. 이때, 당연히 전체 vertex 개수는 \(n\)개 이므로 \(k\)개의 vertex와 연결되어있는 vertex는 나머지 \(n-1-k\) vertex와 연결되어있지 않다. 따라서 임의의 vertex가 \(k\)개의 vertex와 연결되어있을 확률 \(p_k\)는 아래와 같이 계산된다.</p>


<p>$$ p_k = { n-1 \choose k } p^k (1-p)^{n-1-k} $$</p>


<p>이 결과는 또 binomial distribution이다. 즉, \(G(n,p)\)의 degree distribution은 binomial distribution이라는 것을 알 수 있다. 하지만 이 식은 간단한 근사식을 통해서 더 간단하게 표현하는 것이 가능하다. 대부분의 경우 우리가 관심이 있는 영역은 \(n\)이 엄청나게 큰 network이므로 이런 상황에서 앞 부분의 combination을 근사하고, 그 다음에는 뒷 부분의 \((1-p)^{n-1-k}\)의 log 값을 근사 시켜보자.</p>


<p>먼저 \(n-1 \choose k\)를 근사한 결과는 \({n-1 \choose k} = {(n-1)! \over (n-1-k)! k!} \simeq {(n-1)^k \over k!}\) 이다. 이 근사식은 그냥 매우 간단한 근사식이므로 설명을 생략하도록 하겠다. 그렇다면 이제 다음으로 확률의 맨 뒷부분을 근사해보자. 이 값은 먼저 log를 취한 후 log를 근사하여 그 값을 계산한다.</p>


<p>$$ \ln[(1-p)^{n-1-k}] = (n-1-k) \ln ( 1- \frac {c} {n-1}) \simeq -(n-1-k) { c \over n-1} \simeq -c $$</p>


<p>이 근사식에서 첫 번째 계산식은 \(p = { c \over n-1} \)이라는 이전의 결과를 사용한 것이고 근사하는 부분은 <a href="http://en.wikipedia.org/wiki/Natural_logarithm#Derivative.2C_Taylor_series" target="new">log의 taylor expansion</a>이 \(\ln(x) = (x-1) - {(x-1)^2 \over 2} + {(x-1)^3 \over 3} - ...\) 라는 것을 사용한 것이다. 그 다음 근사는 당연히 n이 k보다 엄청 크다고 가정한 것이다. 자 그 결과는 놀랍게도 \(\ln[(1-p)^{n-1-k}] \simeq -c\) 이다. 즉, \((1-p)^{n-1-k} \simeq e^{-c}\) 라는 사실을 알 수 있다.</p>


<p>자 이제 모든 결과를 종합해보면 n이 엄청나게 큰 상황에서 다음과 같은 결과를 얻는다</p>


<p>$$ p_k \simeq {(n-1)^k \over k!} p^k e^{-c} ={ (n-1)^k \over k!} ({c \over n-1})^k e^{-c} \simeq e^{-c} {c^k \over k!}$$</p>


<p>자, 우리는 n이 매우 크다는 조건 하나를 사용해 근사를 한 결과 Poisson distribution을 얻게 되었다. 즉, n이 매우 큰 \(G(n,p)\)에서 degree distribution은 poisson distribution을 가진다는 사실을 알 수 있다. (사실 글의 처음에서도 말했던 것 처럼 이런 이유로 random network라는 이름은 사실 poisson random graph의 준말이다.)</p>


<h5 id="50-6-cluster">Cluster and giant Component</h5>


<p>자 그러면 이제 또 중요한 measurement 중 하나인 clustering coefficient를 계산해보자. Random Graph에서 \(c\)는 평균 degree를 의미하기 때문에 이 글에서 clustering coefficient는 \(C\)로 표기될 것이다. 이 clustering coefficent는 내가 이웃한 vertex 두 개가 서로 연결되어있을 확률을 의미한다. 그런데 우리의 graph \(G(n,p)\)의 임의의 vertex pair가 서로 연결되어있을 확률은 언제나 \(c \over n-1 \)이다. 따라서 clustering coefficient \(C\)는 \(c \over n-1 \) 라는 사실을 아주 간단하게 알 수 있다. 즉, 이 식에 따르면 \(n \to \infty\) 가 되고 \(c\)의 값이 fixed 되어있는 graph에서의 \(C\)는 0으로 수렴한다는 사실을 알 수 있다. 그러나 실제 네트워크에서 관찰되는 결과는 mean degree가 fixed되어있더라도 clustering coeficient의 값이 여전히 크게 유지가 된다는 것이다. 이런 특성 때문에 바로 다음 글에서 설명하게 될 small world network의 필요성이 대두된다.</p>


<p>아무튼 단순히 clustering coefficient만 계산하는 것은 크게 와닿지 않는다. 구체적으로 이 네트워크에서 giant component라는 것이 존재할 확률이나 실제 존재했을 때 어떤 형태로 존재할지를 예측해보자. 여기에서 giant component란 문자 그대로 네트워크 상에서 존재하는 가장 largest한 component라고 보면 된다. (Component에 대한 설명은 <a href="http://SanghyukChun.github.io/48#48-8-path" taget="new">이전 글</a> 참고) Simple하게 \(p=0\)이면 모든 graph가 disjoint되어있고 giant component라는 것은 존재하지 않는다. 반면 \(p=1\)이면 모든 vertex가 연결되어있고 graph는 vertex의 개수가 \(n\)인 오직 하나의 componet를 가지게 된다. 자 그러면 이제 \(p\)가 0에서 1사이의 값일 때를 생각해보자. 이런 상황에서 giant component가 존재한다고 가정하고, 이 component에 포함되는 vertex의 개수를 \(n_{gc}\) 라고 하자. 이렇다고 가정을 하게 되면 임의의 fraction of nodes가 giant component에 포함이 되지 않을 확률을 \(u\)라고 하면 우리는 이 값이 \(u=1-{n_{gc} \over n}\) 이라는 사실을 알 수 있다. (당연히 \(n_{gc} = n(1-u)\) 이다.) 그렇다면 이제 이 u를 통해 giant component를 분석해보도록 하자.</p>


<p>먼저 임의의 vertex \(i\)가 이런 GC에 포함된다고 가정해보자. 그렇다면 이 vertex \(i\)는 vertex \(j\)라는 vertex를 거쳐 GC에 연결되어야한다고 했을 때, \(i\)가 GC에 포함이 되지 않을 확률은 (1) \(i\)와 \(j\)가 연결되어있지 않다: \(1-p\) (2) \(i\)와 \(j\)가 연결되어있으나 \(j\)가 GC에 연결되어있지 않다: \(pu\) 이렇게 총 두 가지 경우 임을 알 수 있다. 따라서 임의의 vertex \(i\)가 임의의 다른 vertex \(j\)를 거쳐 GC에 포함되지 않을 확률은 \(1-p+pu\)이고, 다른 모든 vertex에 대해 이를 확장해보면 다른 vertex가 \(n-1\)개 있으므로 이 확률은 \({(1-p+pu)}^{n-1}\) 임을 알 수 있다. 그런데 이 값은 결국 한 vertex가 GC에 포함될 확률 \(u\)와 같다. 따라서 \(u={(1-p+pu)}^{n-1}\) 이라는 사실을 알 수 있다.</p>


<p>자, 그러면 \(p={c \over n-1}\) 이므로 위의 식에 대입하고, log를 근사시키면 아래와 같은 결과를 얻게 된다.</p>


<p>$$ \ln u= (n-1) \ln {\left(1-{c \over n-1} (1-u) \right)} \simeq -(n-1) {c \over n-1} (1-u) = -c (1-u) $$</p>


<p>위의 식을 통해 \(u=e^{-c(1-u)}\) 라는 사실을 알 수 있다. 이때 giant component 안에 들어있는 vertex의 개수의 비율을 \(S=1-u={n_{gc} \over n}\) 이라고 정의한다면 이 식은 아래와 같이 적을 수 있다.</p>


<p>$$ S=1-e^{-cS} $$</p>


<p>이로부터 우리는 Giant component의 크기 자체가 평균 degree에 의해 bound된다는 사실을 알 수 있다. 즉, 어떤 값 \(c\)에 의해 S가 결정된다는 것이다. 그러나 식이 한 번에 풀릴 수 있는 간단한 형태가 아니기 때문에 이 식에서 바로 정확한 S값을 구할 수는 없고, 그 대안으로 graphical solution이 제시된다. 즉, x축이 S의 값이고 y축이 S에 대한 함수의 값인 2차원 그래프를 그리고, \(y=S\)와 \(y=1-e^{-cS}\)의 교점을 구하는 것이다. 이런 두 함수를 그려보게 되면 아래와 같은 결과를 얻게 된다.</p>


<p><img src="/images/post/50-1.png" width="500"></p>

<p>위의 그래프에서 알 수 있는 사실은, 모든 함수들이 원점에서부터 시작하고 계속 기울기가 감소하는 형태이기 때문에 만약 원점에서 함수의 기울기가 1보다 큰 값이 존재하는 함수가 존재한다면 그 함수는 반드시 원점이 아닌 교점이 존재한다는 사실이다. 이런 교점을 찾아보면, \({d \over dS} (1-e^-{-cS})=1\)이라는 식을 풀어야하며 이 식을 계산해보면 \(ce^{-cS} = 1\)이라는 식을 얻을 수 있다. 즉, S=0인 점에서 기울기는 무조건 \(c\)가 되므로 \(c\)의 값이 1보다 크면 반드시 giant component가 존재하며 그 보다 작으면 giant component가 존재하지 않는 다는 것을 알 수 있다.</p>


<h5 id="50-7-smallcomponent">Small Componets</h5>


<p>이번에는 Giant component에 포함되어있지 않은 Small component에 대해 알아보자. 만약 giant component가 네트워크에 딱 하나만 존재한다고 가정해보자. 그리고 각각의 크기가 \(S_1 n\) \(S_2 n\) 이라고 가정했을 때, \(i\)가 첫 번째 GC에 속하는 vertex, \(j\)가 두 번째 GC에 속하는 vertex일 때, 모든 distinct vertex pair \((i,j)\)의 개수는 간단하게 그 둘을 곱한 \(S_1 S_2 n^2\)일 것이다. 만약 각각의 pair는 \(p\)의 확률로 연결이 되어있거나 \(1-p\)의 확률로 연결되어져있지 않다. 따라서 이 두 개의 GC가 서로 완벽하게 분리되어있을 확률 \(q\)는 다음과 같이 계산할 수 있다</p>


<p>$$ q = (1-p)^{S_1 S_2 n^2} = \left( 1 - {c \over n-1} \right)^{S_1 S_2 n^2} $$</p>


<p>이때 만약 \(n \to \infty\) 가 된다면, 우리는 아래와 같은 근사식을 구할 수 있다.</p>


<p>$$ \ln q = S_1 S_2 \lim_{n \to \infty} \left[ n^2 \ln \left( 1 - {c \over n-1} \right) \right] = S_1 S_2 \left[ -c(n+1) + {1 \over 2} c^2 \right] = c S_1 S_2 [-n + ({1 \over 2} c -1) ]$$</p>


<p>그러면 우리는 남은 상수항을 \(q_0\)라 정의하고, \(q = q_0 e^{-c S_1 S_2 n}\) 이라는 식을 구할 수 있다. 이 식은 너무나 당연하게 \(n \to \infty\) 가 되면 값이 0이된다. 따라서 우리는 \(n\)이 매우 큰 상황에서 두 개의 GC가 존재할 확률이 0이므로 \(n\)이 큰 네트워크는 단 하나의 Giant component를 가지고 있다는 결론을 내릴 수 있다.</p>


<p>Random network는 단 하나의 Giant component만을 가지고 있기 때문에, 그에 포함되지 않은 나머지 component들을 모두 small component라고 정의할 수 있을 것이다. 이 때 각각의 small component의 크기를 \(\pi_s\)라고 정의하면 이 값들의 모든 합은 반드시 \(1-S\)이므로 \(\sum_s \pi_s = 1-S\) 라는 식을 얻을 수 있다.</p>


<p>본격적으로 small component에 대해 다루기 전에 먼저 small component가 어떤 형태로 구성이 되어있을지 생각해보도록 하자. 정답부터 말하자면, small component는 tree의 형태를 하고 있다. 각각의 small component를 \(s\)개의 vertex를 가지는 tree라고 해보자. 당연히 tree의 edge의 개수는 \(s-1\)일 것이며 이 값은 connected 되어있는 \(s\)의 vertex가 만들어낼 수 edge의 최소 개수이다. 만약 이 최소 개수보다 많은 edge가 단 하나라도 존재할 확률은 \(c \over n-1\)이며, 이런 graph는 반드시 cycle이 생기게 되므로 더 이상 tree가 아니게 되어버린다. 그렇다면 우리가 이 small component가 tree임을 입증하기 위해서는 이런 additional edge가 존재할 확률이 0라는 것을 보이면 된다. tree를 구성하는 edge이외에 추가가 될 수 있는 edge의 개수는 \({s \choose 2} - (s-1) = {1 \over 2} (s-1)(s-2)\)이다. 이를 통해 tree안에 이런 edge가 단 하나라도 존재할 확률은 \({1 \over 2} {c(s-1)(s-2) \over n-1}\) 라는 것을 알 수 있다. 따라서 \(n \to \infty\) 가 되면 이 확률은 0이 되어버린다. 따라서 이 component는 반드시 tree라는 사실을 알 수 있다.</p>


<p>이번에는 아래와 같은 상황을 한 번 상상해보자. 왼쪽과 오른쪽은 단 하나의 vertex만 제외하면 완벽하게 같은 Graph이다. 왼쪽 graph는 vertex \(i\)의 neighbor들이 모두 다른 small component에 속해있는 경우이며, 즉, 서로 분리되어있는 subgraph들을 하나로 이어주는 역할을 하고 있다. 오른쪽은 그 \(i\)는 없지만 여전히 서로 같은 확률을 그대로 유지하고 있고 여전히 확률 p를 가지는 random graph 이다.</p>


<p><img src="/images/post/50-2.png" width="500"></p>

<p>이런 상황에서 만약 우리가 충분히 큰 \(n\)을 가정했을 때 각각의 subgraph 역시 큰 graph의 특성을 따라갈 것이기 때문에, \(i\)가 없는 오른쪽 그림에서\(i\)의 neighbor \(n_1\)이 size가 \(s_1\)인 small component에 속할 확률은 \(\pi_{s_1}\)로 주어진다는 것을 예측할 수 있다.</p>


<p>자 그렇다면 이런 vertex \(i\)가 \(k\)의 degree를 가지고 있었다고 가정해보자. 위의 결과로 인해 vertex \(i\)가 \(s\) 만큼의 크기를 갖는 small component에 속할 확률 \(P(s|k)\)는 이 vertex의 모든 neighbor, 즉 \(k\)개의 neighbor들이 각각 \(s_1\)부터 \(s_k\)까지 속할 확률과 같으며 이 값은 아래와 같이 계산 할 수 있을 것이다.</p>


<p>$$ P(S|k) = \sum_{s_1}^infty ... \sum_{s_k}^{\infty} \left[ \Pi_{j=1}^k pi_{s_j} \right] \delta (s-1, \sum_j s_j) $$</p>


<p>이때 \(\delta (m,n)\)은 <a href="http://en.wikipedia.org/wiki/Kronecker_delta" target="new">Kronecker delta</a>를 의미하며 이 함수는 간단하게 두 값이 같으면 1 다르면 0을 반환한다. 즉, 이 수식에서 델타의 의미는 모든 \(s_j\)들을 더하면 \(s-1\)이 나와야한다는 것이다. =========== 추가 설명 작성 중 =============</p>


<p>============Small component에 대한 추가 설명 작성 중=================</p>


<h5 id="50-8-distofcompsize">Complete Distribution of Component Size</h5>


<p></p>


<h5 id="50-9-path">Path Length</h5>


<p>보통 네트워크, 혹은 그래프에서 Diameter, 혹은 지름이라 함은 가장 긴 longest geodesic distance를 의미한다. 이 값은 즉, 임의의 두 vertex를 골랐을 때 가장 짧은 경로의 길이를 의미한다고 보면 된다. Random graph에서 이 값은 어떻게 구할 수 있을까? 먼저 간단하게 임의의 vertex에서 \(s\) 번 이동했을 때 visit할 수 있는 평균 vertex의 개수는 매 진행마다 degree 만큼의 vertex를 추가로 더 갈 수 있으므로 평균 degree들을 \(s\)번 곱한 형태인 \(c^s\)일 것이다. 그리고 우리가 원하는 경로는 가장 짧은 경로를 찾는 것이므로 vertex travel step을 이 visit 가능한 vertex와 전체 vertex의 개수가 같아지는 순간 끝나하면 우리가 원하는 shortest path의 길이를 유추할 수 있게 될 것이다. (정확한 경로는 예측할 수 없지만) 따라서 \(c^s \simeq n\)이 될 것이며 따라서 \(s \simeq {\ln n \over \ln c}\)가 될 것이다. 즉, 놀랍게도 아무리 \(n\)의 값이 급격하게 커지더라도 random graph의 diameter가 증가하는 속도는 \(\log n\) 이라는 것이다. 이 값은 충분히 작은 값으로, 이런 움직임이 실제 네트워크의 움직임과 매우 흡사하다는 것을 실험을 통해서 밝혀졌다.</p>


<h5 id="50-10-problems">Random Graph의 문제점</h5>


<p>앞서 살펴본 바를 토대로 Random Graph가 가지고 있는 문제점들을 살펴보도록 하자. 먼저 Average path length는 \(\bar l \simeq {\log n \over \log c} \)로 표현이 되며 이것은 곧, random graph는 \(n\)의 값에 비례하여 path length가 늘어나는 것이 아니라 log scale로 증가한다는 것을 알 수 있다. 즉, \(n\)이 매우 크더라도 path는 그에 비해 매우 짧다는 것을 알 수 있다. 이것은 실제 대부분의 네트워크들에서도 나타나는 현상이다. 반면 clustering coefficient는 \(c \over n\)으로 표현이 되며 \(n\)의 값이 증가할 수록 떨어지는 것을 알 수 있는데, 실제 network들이 \(n\)이 커지더라도 높은 clustering coefficient를 유지한다는 점에서 현실과 잘 맞지 않는다는 것을 알 수 있다. 마지막으로 Degree distribution을 살펴보게 되면, random graph에서의 degree distribution은 \(P(k) \simeq e^{-c} {c^k \over k!}\)로 근사가 되는데, 실제 네트워크에서 관측되는 distribution은 \(P(k) \simeq k^{-\gamma}\) 와 같은 power distribution이다. 따라서 이 역시 잘 맞지 않는다는 것을 알 수 있다.</p>


<p>Random network는 가장 간단한 network모델이며 수학적으로 잘 증명되었고 쉽게 이해할 수 있는 network모델이다. 그러나 real network와 비교해 잘 맞지 않는 점들이 있기 때문에 우리는 결국 새로운 network model들을 계속 더 공부해야만 하는 것이다.</p>


<p>따라서 다음 글은 이와 같은 문제를 일부 해결한 Small world network에 대해 다루게 될 것이다.</p>




<h5>KAIST Network Science</h5>


<p>다른 요약글들 보기 (<a href="http://SanghyukChun.github.io/blog/categories/network-science/" target="new">카테고리로 이동</a>)</p>


<ul>
    <li>Lecture 1: <a href="http://SanghyukChun.github.io/47" target="new">Introduction</a></li>
    <li>Lecture 2: <a href="http://SanghyukChun.github.io/48" target="new">Graph Theory</a></li>
    <li>Lecture 3: <a href="http://SanghyukChun.github.io/49" target="new">Measures and Metric</a></li>
    <li>Lecture 4: <a href="http://SanghyukChun.github.io/50" target="new">Random Network</a></li>
    <li>Lecture 5: <a href="http://SanghyukChun.github.io/51" target="new">Small world Network</a></li>
    <li>Lecture 6: <a href="http://SanghyukChun.github.io/52" target="new">Scale free Network</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[인터넷 속의 수학 - Can I really reach anyone in 6 steps? (2/2)]]></title>
    <link href="http://SanghyukChun.github.io/34/"/>
    <updated>2013-12-12T16:48:00+09:00</updated>
    <id>http://SanghyukChun.github.io/34</id>
    <content type="html"><![CDATA[<p>본 포스팅은 <a href="http://SanghyukChun.github.io/29" target="new">단기강좌 인터넷 속의 수학</a>의 강의 들을 요약하는 포스트입니다.</p>


<h5 id="34-1-review">Review of last post</h5>


<p><a href="http://SanghyukChun.github.io/32" target="new">지난 포스트</a>에서는 전반적인 강의의 개요 및 간단한 Network Problem들에 대해 다뤘다. 특히 그 중에서 밀그램의 편지 실험에 대해 다시 한번 살펴보자. 이 실험은 사람과 사람 사이의 사회적 거리를 측정하기 위한 실험이다. 여기에서 사회적 거리 혹은 social distance는 우리가 흔히 'distance'라는 컨셉에서 쉽게 생각할 수 있는 유클리언 distance와는 조금 다른 개념인데, 유클리언 distance가 지리적, 공간적인 거리의 개념이라면 social ditance는 내가 이 사람과 얼마나 가까우냐에 대한 얘기이다. 즉, 내가 미국에 유학가있는 친구와 유클리언 거리는 무지막지 멀지만 사회적거리는 엄청 가깝고, 옆 연구실의 학생분들은 유클리언 거리는 매우 가깝지만 안타깝게도 사회적 거리는 엄청 먼 셈이다. 구체적으로 social distance를 정의해보자. 이 값은 social network 위에서 내 node에서 다른 목표 node로 이동할 때 이동해야하는 총 거리를 의미한다. 즉, 밀그럼의 실험에서 실험 참가자들의 평균적인 사회적 거리는 약 5 정도가 되는 것이다. (이전에도 언급했듯, Facebook에서 같은 실험을 해보면 4.74가 나온다.)</p>


<p>자, 다시 한번 이전에 설명했던 실제 네트워크, 허브라는 개념 등에 대해서 생각해보자. 이렇게 전혀 상관없어 보이는 사람들 사이의 사회적 거리가 짧게나오는 이유는 사회적 네트워크의 토폴로지가 (그래프의 모양이) 독특하기 때문이다. 아래 그림을 봤을 때 구조적으로 멀어 보이는 지점을 이어주는 엄청나게 긴 장거리 연결 링크 (long-range link)가 존재한다는 것을 알 수 있다.</p>


<p><img src="/images/post/32-7.png" width="300"></p>

<p>그리고 실제 네트워크는 뭉침현상(clustering)이 존재한다. 무슨 얘기이냐 하면, 특정 노트들끼리 뭉쳐있을 수 가 있다는 (cluster를 형성한다는) 의미이다. 따라서 밀그럼의 편지 실험에서 아무에게나 마구잡이로 편지를 전달하게 된다면 성공할 확률이 극히 낮아질 수 있다. (내부 cluster안에서만 편지가 빙빙 돌다가 실험이 끝날 수 있다.) 따라서 목표 지점과 현재 위치라는 굉장히 제한된 정보를 가지고 편지를 전달하기 위한 전략이 필요하고, 이를 다시 문제로 바꾸어서 생각해보면, 국지적인 정보만을 가지고 네트워크의 특정 지점에서 다른 특정 지점을 연결하는 가장 짧은 경로를 찾는 social search algorithm을 구현하기 위해서는 단순히 random하게 정보를 전달하는 것이 아니라, 어떤 특정한 rule이 필요하다는 것이다. 몇 가지 아이디어가 있는데, 대표적인 아이디어 중 하나는 사람들끼리의 연결은 그 정도가 같지 않다는 것이다. 즉, 내가 최종적으로 편지를 전달해야하는 사람이 은행가이므로 내 친구 중에서 간호사와 주식거래인이 있을 때 간호사보다는 주식거래인이 은행가와 확률적으로 사회적 거리가 더 짧을 것이라고 예측할 수 있을 것이다. 이런 식으로 특정 rule을 가지고 search를 하는 것이 매우 중요하다.</p>


<h5 id="34-2-smallworld">Small world & Network Modeling</h5>


<p>자, 이제 중요한 개념 몇 개를 다시 정리해보자.</p>


<ul>
    <li>Social Distance: Social Network에서 특정 node에서 다른 특정 node로 가기 위해 이동해야하는 가장 짧은 경로의 총 거리</li>
    <li>Clustering coefficient: Social Netwrok에서 특정 node들끼리 얼마나 cluster를 형성할 것인지를 결정하는 계수. 이 값이 클 수록 cluster를 더 많이 형성한다. 수학적으로 다시 정의하자면 Network에서 node들의 connection이 connected triple을 일고 있을 확률을 의미한다. 아래 그림을 참고하면 더 이해가 쉬울 것이다.</li>
    <li><img src="/images/post/34-1.png" width="500"></li>
    <li>Diameter: Social Network에서 가장 긴 Social Distance의 길이</li>
    <li>Length of Network(L): 모든 social distance의 중간값. 일반적으로 그래프의 크기가 커지면 같이 커진다</li>
    <li>Small World: Network의 크기가 증가하는 속도보다 L이 증가하는 속도가 더 느린 형태의 네트워크 (보통 증가비율이 Logarithm scale이면 small network라고 한다.)</li>
</ul>


<p>위의 용어들을 다시 명시한 채로 (몇 개는 새로 정의하였다) Real network를 생각해보자. 이전 실험들을 통해서 우리는 real network의 diameter는 매우 작은 편이라는 것을 알고 있고, 또한 clustering coefficient는 크다는 것을 알 수 있다. 그리고 중요한 컨셉 중 하나가 모든 social distance의 중간값인 L인데, 실제 네트워크에서는 그 네트워크의 크기가 커지는 속도보다 L이 더 천천히 증가한다. 이를 위에서도 언급했듯 Small World라고 한다.</p>


<p>근데 문제는 이런 Small world를 (한국어로는 좁은 세상이라고 한다) 수학적으로 모델링하는 것이 쉽지 않다. Power-Law 분포를 가진 네트워크를 앞에서 설명헀었는데, 이 모델을 (푸아송 모델이라고 한다) 적용해서 문제를 바라보게 되면 거리 혹은 지름이 짧다는 점에서 사실적지만, 모든 node가 independent possibility로 연결되어 있어서 뭉침계수가 작다는 점에서는 사실적이지 않다. 다시 뭉침계수를 설명하자면, 이어진 세 마디가 삼각형을 이루고 있을 확률이 뭉침계수이다. 그렇다면 Regular Network는 어떨까? 이 경우는 Clustering coefficient는 크지만 Diameter 역시 크다는 점에서 unrealistic하다. (이를 보완하기 위해서 그 둘을 적절하게 섞은 The Watts-Strogatz-Newman Model이라는 것이 있다. 이에 대해서는 아래에서 자세히 설명하도록 하겠다.)</p>


<h5 id="34-3-poissonregularnetwork">Poisson Network vs Regular Network</h5>


<p>푸아송 네트워크는 각 마디가 power-law distribution을 가지는 p라는 independent possibility로 연결이 되어있는 형태이다. random한 연결이 많기 때문에 diameter가 많다는 것은 충분히 이해할 수 있을 것이다. 그러나 이 경우에는 모든 마디가 p의 확률로 연결이 되기 떄문에, 엄청나게 약한 연결도 '연결'이 되기 때문에 cluster coefficient가 \(C=p\)로 작아서 사실적인 네트워크 모델이 될 수 없다. 반면 정규 네트워크는 네트워크 자체가 원형으로 구성되며 자기 자신과 가까운 c명에게 연결하고 있는 형태이다. 이 경우 cluster coefficient는 \(C=\frac {3(c-2)} {4(c-1)}\)로 크지만 (c의 값이 2명 값이 0이고 4면 0.5, 무한대로 가면 0.75가 된다. 이 정도면 엄청나게 높은거다.) diameter가 크기 때문에 사실적인 모형이 아니다. 때문에 이 둘을 적절히 결합한 The Watts-Strogatz-Newman Model이라는 것이 등장하게 되는데, 제일 가까운 c명과 연결이 되어있으면서 (regular network의 성질, 이로 인해 높은 clustering coefficient를 가지는 것이 가능하다.) 또한 특정한 independent possibility p로 random한 node와 link를 가지고 있다. (poisson network의 성질, 이로 인해 낮은 diameter를 가지는 것이 가능하다.) 이 모델은 얼마나 random하게 link를 형성하느냐에 따라 그 네트워크의 topology나, 성질 등이 달라지게 될 것이다. (아래 그림을 보면 이해가 될 것이다.)</p>


<p><img src="/images/post/34-2.png" width="400">
<img src="/images/post/34-3.jpeg" width="400"></p>

<p>아래 그림은 <a href="http://www.scholarpedia.org/article/Small-world_network" target="new">scholarpedia</a>에서 가져온 그림이다. p가 0이면 정규 네트워크처럼 diameter와 clustering coefficient가 모두 높지만, p를 증가시키면 점점 Poisson network와 비슷해지는 것을 알 수 있다. 따라서 적절한 p를 고르는 것이 small world를 모델링하기 위해 매우 중요하다고 할 수 있다.</p>


<p><img class="<a" src="href="http://www.scholarpedia.org/w/images/9/97/Swlc.png">http://www.scholarpedia.org/w/images/9/97/Swlc.png</a>" width="400"></p>

<h5 id="34-4-socialsearch">Fining paths - social search</h5>


<p>그러면 이제 다시 local information만을 가지고 global shortest path를 찾는 문제로 돌아가서 생각해보자. 사실 이 문제는 optimization 문제로 치환해서 생각이 가능하지만, 안타깝게도 convex model이 아니기 떄문에 마냥 쉽게 적용하기는 쉽지 않다. 아무튼 다시 본론으로 돌아서, 가장 쉽게 생각할 수 있는 알고리듬은 greedy search algorithm이다. 내 neighbor 중에서 목표 node와 가장 가까울 것으로 생각되는 node로 넘어가고, 그 node에서도 마찬가지 과정을 반복하는 것이다. 하지만 당연한 얘기지만 이 알고리듬은 완벽하지 않다. 쉽게 생각해서, 내가 은행가와 가장 가까울 것이라고 예측한 주식거래인은 그 은행가를 직접적으로 모르지만, 간호사가 알고보니 그 은행가와 고등학교 동문이라 바로 연결이 되는 상황이라면? 이런 경우는 greedy algorithm이 global optima를 보장할 수 없게되는 것이다.</p>


<p>search algorithm을 위해 도임되는 모델 중에서 클라인버그(Kleinberg) 검색 모델이라는 것도 있다. 이 모형은 국지적으로 connection을 가지고 있고 거리 r에 따라 멀리 있는 사람과 \(C * r^{-a}\)의 확률로 connection을 가지고 있다고 가정한다. 이 모델에 따르면 \(a = 2\) 일 때만 빠른 전달이 가능한데 그 모델링을 통해 예측한 결과는 아래 그래프와 같다.</p>


<p><img src="/images/post/34-4.gif" width="400"></p>

<p>그 이외에도 사람 사이의 관계를 tree로 정의하고 social ditance를 tree에서 거쳐야 하는 단계 수로 정의하는 Watts-Dodds-Newman Model이라는 것도 존재한다. 이 모델의 Social distance를 정의하는 두 사람이 서로를 알 확률 \(p_m\)은 \(p_m = K 2^{\alpha m}\) 로 정의가 된다. 이 모델에서 level의 길이는 \(log_2 \frac n g\)로 정의가 되고, 평균적인 최단 거리도 계산이 가능하지만, 식이 꽤 복잡하기도 하고 이 모델의 reference도 찾지 못해 이 포스트에서는 생략을 하도록 하겠다 (직관적인 값이 아니라 이해를 위해 래퍼를 찾아봤는데 나오지 않는다) 아무튼 이 모델의 평균적인 최단거리에 node의 개수가 g이고 전체 사람이 n, a = 1이라는 특수한 경우로 문제를 바꾸어 생각해보면 평균 최단거리는 \(log^2 ( \frac n g )\) 에 비례한다. 특이점이라면, 이 모델은 tree 구조로 생각을 했기 때문에 Hub의 존재는 고려가 되지 않는다는 점이다.</p>


<h5 id="34-5-conclusion">Conclusion</h5>


<p>degree와 clustering을 동시에 만족하는 Network model은 현재까지는 없기 때문에 높은 clustering을 가지는 random distribution을 만드는 것도 활발한 연구 주제 중 하나라고 한다. 아무튼 network search의 핵심은 단순히 국지적인 정보만을 가지고 있어도 모든 Network에 정보 전파가 가능하다는 것이다. 아직도 연구가 활발히 진행되고 있는 분야이고, 정답도 없는 분야인 만큼 더 공부가 필요한 부분이라고 생각이 들었다. 이 포스트가 잘 이해가 되지 않거나 네트워크라는 것에 대해 흥미가 생긴다면 Linked: The New Science of Networks (Albert-laszlo Barabasi, Jennifer Frangos) 를 참고하면 될 것 같다.</p>


<p>+ 추가로 정송 교수님의 comment를 추가하고 글을 마무리 짓도록 하겠다.</p>


<p>Network search algoritm을 주변 resource를 검색하는 것으로 해석할 수 있을 것 같다. (ex 동물들의 먹이 탐색활동) genetic algorithm.. 현재 search space 내에서 solution에 대한 initial guess를 가지고 solution을 가지고 찾다가 간헐적으로 mutation이 일어나 다른 candidate space에서 solution을 찾는 모델이 있음. 지금 network search에 대한 설명을 들어보니 그와 비슷한 것 같다. 클라인버그 검색 모형에서도 a에 따라 a 세팅을 잘못하면 국지적으로 값을 찾을 수 없거나 혹은 너무 mutation이 자주 일어나서 잦은 swing현상으로 인해 최적화가 안된다.</p>


<p>Modern network에 P2P같은 형태가 존재한다. 움직임에 의한 연결. 둘이 움직이다가 연결이 일어난다고 생각해보자. 만약 네브라스카가 움직이지 않는 static한 network라면 그 contact이 없지만, 만약 그 사람 중 하나가 mobility를 가지고 예를 들어 여행을 많이 다니는 사람이 하나 있어서 그 connection이 많이 일어나는 사람이 있다면 그 사람이 Network의 key가 되며 이것에 대한 수학적 모델링을 통한 연구가 이뤄지고 있다.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[인터넷 속의 수학 - Can I really reach anyone in 6 steps? (1/2)]]></title>
    <link href="http://SanghyukChun.github.io/32/"/>
    <updated>2013-12-03T17:58:00+09:00</updated>
    <id>http://SanghyukChun.github.io/32</id>
    <content type="html"><![CDATA[<p>본 포스팅은 <a href="http://SanghyukChun.github.io/29" target="new">단기강좌 인터넷 속의 수학</a>의 강의 들을 요약하는 포스트입니다.</p>


<h5 id="32-1-intro">Introduction</h5>


<p>흔히 이 세상의 모든 사람들은 나와 6다리 만 건너면 이어져있다고들 말한다. (밀그램의 편지실험) 심지어 나와 상관없어보이는 버락 오바마 대통령도 사회적 거리가 생각보다 가까울 수 있다는 것이다. Facebook의 조사결과에 따르면 Facebook 상에서 연결된 <a href="http://arxiv.org/abs/1111.4570" target="new">다리의 평균값은 4.74</a> 정도라고 한다. 근데, 진짜 정말로 모든 사람들과 6 steps로 연결이 가능할까? 이 글에서는 이런 현상에 대해서 설명하고, 실제 사람과 사람 간의 네트워크가 어떤 식으로 구성되고, 그것을 수학적으로 어떻게 모델링하고 있는지를 다루게 될 것이다.</p>


<p>최근 10년 사이 네트워크는 사람들의 생활에 정말 정말 큰 영향을 미치고 있다. 특히 소셜 네트워크 혹은 SNS라고 불리는 새로운 형태의 서비스의 등장으로 인해 사람들과 사람들 사이의 긴밀한 연결이 더 가능해졌다. 이런 네트워크가 파생된 것은 사실 생각보다 역사가 짧은데, 실제 정보를 전달할 때는 전기신호로 보내야하고, 그 신호를 보내는 channel이 굉장히 noisy한데, 과연 이런 nosiy channel로 realistic한 시간 안으로 정보를 온전하게 전달할 수 있을까? 당연히 정보가 손실되면 retransmission을 시도해서 상대편이 정보를 다시 받을 수 있도록 할 수 있지만, 그 반복해서 보내는 retransmission이 실제 의미있는 숫자 이내로 성공할 수 있겠냐는 문제에 대해 아무도 답을 할 수가 없었기 때문에 연구가 지지부진한 상태였다. 그러나 지금으로부터 약 60여년 전 클로이 섀넌이라는 기라성같은 연구자가 noisy한 channel에서 error-free communication이 가능하다는 것을 증명해냈고, 그 이후로 통신학의 급격한 발전이 이루어졌다. 우리가 쓰는 인터넷은 군대 및 연구기관의 '알파넷'이라는 통신 기술이 그 전신인데, 이 기술은 전쟁으로 인해 한 기관이 파괴되어도 다른 곳에서 정보를 전송할 수 있도록 분산시킬 용도로 개발되었다고 한다. 지금 우리가 사용하는 스위칭, 패킷 등의 기술도 이때 개발 되었다. 우리가 진짜 '인터넷' 이라고 부르는 월드 와이드 웹은 유럽의 입자 가속기 연구서 (CERN)에서 데이터 교환의 용이성을 위해 처음 등장하게 되었다. 그리고 수 많은 사람들의 노력으로 우리가 현재 쓰는 모습의 인터넷 네트워크가 탄생한 것이다.</p>


<h5 id="32-2-graph">Network Problems - Graph Theory</h5>


<p>앞서 네트워크의 역사에 대해 간략하게 설명했는데, 그렇다면 실제 이런 네트워크를 잘 구성하기 위해서 우리가 풀어야하는 몇 가지 문제점들이 존재한다. 특히 네트워크에 요구되는 사항들을 충족시키려면 네트워크를 잘 이해하는 것이 필요하고 이런 것을 위해 네트워크 과학이라는 분야까지 생겼을 정도로 문제가 생각보다 광대하다. 몇 가지를 꼽아보자면, 좋은 네트워크는 (1) 효율적인 소통을 해야하고, (2) 외부의 공격에 견고하게 방어를 할 수 있어야하고, (3) 복잡성이 낮고 간결해야 한다. 그렇다면 이런 사항들을 충족시키기 위한 몇 가지 문제들을 살펴보자. 최초의 네트워크 문제는 쾨니히스베르크의 다리라고 불리는 문제이다. 누가 처음 만들었는지는 모르고 언제부터 존재했는지는 모르지만, 1735년 오일러가 이를 수학적으로 증명해낸 문제이다. 이 문제에서 부터 사실 네트워크 이론이 나왔다고 해도 과언이 아니다. 문제는 간단하다. 아래의 그림을 보면서 자세히 설명해보자.</p>


<p><img src="/images/post/32-1.png" width="400"></p>

<p>오래전에 프로이센이라는 국가의 <a class="red tip" title="지금의 러시아 칼리닌그라드">쾨니히스베르크</a>라는 자그마한 도시가 하나 있었다. 이 도시의 지식인들이 그냥 도시를 산책하다가 심심했던 모양인지 생각해낸 문제이다. 쾨니히스베르크에는 프레겔 강이 흐르고 있고, 이 강에는 두 개의 큰 섬이 있다. 그리고 이 섬들과 도시의 나머지 부분을 연결하는 7개의 다리가 있다. 이때 7개의 다리들을 한 번만 건너면서 처음 시작한 위치로 돌아오는 길이 있는가 하는 것이 문제이다. (출처: <a class="red tip" title="http://ko.wikipedia.org/wiki/%EC%BE%A8%EB%8B%88%ED%9E%88%EC%8A%A4%EB%B2%A0%EB%A5%B4%ED%81%AC%EC%9D%98_%EB%8B%A4%EB%A6%AC_%EB%AC%B8%EC%A0%9C">위키피디아</a>) 이 문제가 꽤 오랜 기간 동안 풀리지 않은채로 존재하다가 오일러가 이를 엄청나게 간단한 방법을 통해 해결을 해버렸다.</p>


<p><img src="/images/post/32-2.jpg" width="400"></p>

<p>다리와 섬을 위의 그림처럼 '그래프'로 표현하게 되면 문제가 엄청나게 쉬워진다. 이 그래프가 한붓그리기가 가능하기 위해서는 엣지가 홀수 개인 노드가 1개만 있어야하는데 이 그림에서 볼 수 있듯 그보다 그런 노드가 많음을 알 수 있다. 오일러의 이 풀이로 인해 '그래프 이론'이라는 새로운 분야가 창조되었고, 이는 우리가 풀고싶은 네트워크 문제를 해결하기 위해 필요한 가장 기본적이고 필수적인 분야 중 하나라고 할 수 있을 것이다.</p>


<h5 id="32-3-milgramexp">Network Problems - 6 degree of separation</h5>


<p>또 다른 실험을 하나 살펴보자. 1967년, 미국의 스탠리 밀그램은 아래와 같은 간단한 실험을 제작했다.</p>


<ol>
   <li>네브래스카 주 오마하라는 작은 도시에 사는 주민 296명에게 메사추세츠 주 보스턴의 은행가로 가는 편지를 전달시키는 것이 이 실험의 목적이다.</li>
   <li>전달은 반드시 전달자가 직접적으로 친밀한 사람에게만 (first-name basis) 가능하다. 즉, 최종 수신인은 정해져있는 상황에서, 최종 수신인을 모르는 경우에 그 사람을 가장 잘 알만한 자신의 지인들에게 이 편지를 전달하는 것이다.</li>
   <li>매번 편지가 전달될 때마다 편지에 보내는 사람의 이름과 서명을 첨부하고, 또한 하버드로 엽서를 따로 보내 traking을 용이하게 하였다.</li>
</ol>


<p><p>이 실험은 결국 미국이라는 network에서 지리적, 사회적으로 가장 고립되었을 것이라고 예상되는 두 node로 이동하기 위해서 평균적으로 얼마나 많은 step이 요구되는가를 측정하기 위한 실험이다. 결과는 어땠을까? 10? 20? 100? 아래 그래프가 그 결과이다.<p>
<img src="/images/post/32-3.png" width="400">
<p>당연한 얘기지만 가로축은 얼마나 많은 사람을 거쳤는가를 의미하고, 세로축은 해당 거리에 해당하는 사람이 얼마나 많은가를 의미한다. 이 실험은 총 217개의 편지 중에서 64개의 편지만 최종적으로 도달하게 되었고 (성공확률 약 30%) 평균 거리는 약 5.2이며 중간값은 6이었다. 때문에 이 실험결과를 일컬어 모든 사람들이 6step으로 이어져있다고 해석해 6단계 분리이론이라고도 부르기도 한다. 이 실험이 완벽하지 않고 logic whole이 존재한다고 주장하는 일부 비판적인 시선이 있는 것은 사실이지만, 이 실험은 충분히 의미가 있고, 무엇보다 실제로 이를 실험적으로 증명하는 것을 시도한 첫 번째 실험이라는 점에서 의미가 있다.</p>
<p>이와 비슷한 다른 예시가 있다. 수학에서 <a href="http://ko.wikipedia.org/wiki/%EC%97%90%EB%A5%B4%EB%90%98%EC%8B%9C_%EC%88%98" target="new">에르도쉬 숫자</a>라는 것이 존재하는데, 이 사람은 엄청나게 많은 공동연구를 진행한 사람이고, 그래서 업적이 뛰어난 사람일수록 이 사람과 공저자를 한 경험이 많다고 한다. 그래서 그 아이디어를 차용해 그 사람이 얼마나 학계에서 권위가 있는지를 측정하는 지표로 쓰이는 것이 이 숫자인데, 에르도쉬 본인은 이 숫자가 0이다. 그리고 에르도쉬와 공저를 한 경험이 있는 연구자의 숫자는 1이다. 만약 내가 직접적으로 에르도쉬와 공저를 하지 않았더라도, 에르도쉬 넘버가 1인 사람과 공저를 한 경우에 내 에르도쉬 넘버는 2가 된다. 즉, 내가 얼마나 에르도쉬라는 사람과 가까운 관계인지를 측정하는 수단인 것이다. 참고로 나는 조만간 에르도쉬 넘버가 3이 될텐데, <a href="https://sites.google.com/site/mijirim/" target="new">내 지도교수님</a>의 <a class="red tip" title="Erdos - Tetali - Shin">에르도쉬 넘버가 2</a>이기 때문이다.</p>
<p>비슷한 숫자로 케빈베이컨 숫자라는 것이 있는데, 이번에는 논문 공저자라는 다소 strict한 rule이 아니라 영화 배우 케빈베이컨과 같이 영화를 출연한 사람에게 (엑스트라도 포함) 같은 방식으로 숫자를 매기는 것이다. 꽤 재미있는 것은, 미국의 그 어떤 영화배우도 이 배우와 거리가 6이하라고 한다. <a href="http://oracleofbacon.org/" target="new">인터넷 웹사이트</a>도 있다. 사실 케빈 베이컨이 가장 뛰어난 배우이거나 많은 작품을 출연했기 때문이 아니라 그 어떤 배우를 대상으로 하여도 비슷한 결과가 나온다고 한다. (이 사이트에 의하면 평균을 취했을 때 가장 평균 거리가 짧은 배우는 <a href="http://oracleofbacon.org/center_list.php">Harvey Keitel</a>이라고 한다)</p>
<h5 id="32-4-regularnet">Mathmetical Approach &ndash; Regular Network</h5>
<p>자 이게 과연 정말 뜨악스럽고 놀랄만한 일일까? 정말 간단한 수학적 모델로 한 번 검증을 시도해보자. 가정을 하나 해보자. 만약 &lsquo;모든 사람'이 아는 사람이 딱 10명 씩 있다고 가정해보자. 뭐 어느 정도는 납득해볼만한 가정이지 않은가? (나중에 얘기하겠지만 틀린 얘기다.) 그렇다면 한 단계 더 건너면 10 * 10 = 100, 또 한 단계를 건너면 10 * 10 * 10 = 100, 그리고 만약 내가 6 step 만큼 건너갔을 때 아는 사람의 숫자는 (10<sup>7</sup>), 즉 1000만 명의 사람과 연결이 되어있는 것이다. 이것을 보고 정규 네트워크 (regular network) 라고 부르며, 이렇게 문제를 가정하고 생각하면 생각보다 문제가 간단해진다. 이 방법이 에르도쉬가 문제를 풀이한 방법이다. network 내부에서 node와 node가 연결되는 것은 확률의 문제이고, 만약 모든 사람들이 이 확률을 비슷하게 가지고 있다고 가정하면, 위와 같은 정규 네트워크가 나오게 되는 것이다. (구체적으로는 node가 연결되는 숫자가 정규분포로 나오기 때문에 정규 네트워크라고 한다.) 이 네트워크의 모양은 아래와 같다.</p>
<img src="/images/post/32-4.png" width="300">
<p>근데 정말 세상은 이렇게 구성이 되어있다고 말할 수 있을까? 실제 세상은 과연 정말 정규 네트워크일까? 당연한 얘기지만 그렇지 않다.</p>
<h5 id="32-5-realnet">Mathmetical Approach &ndash; Real Network</h5>
<p>일단 정규 네트워크는 가정 자체가 글러먹었다. 모든 사람이 평균적으로 같은 숫자의 친구를 가지고 있다? 안타깝게도 사람마다 친구의 숫자가 천차만별이고, 구체적으로 말하자면 사람마다 가지고 있는 node를 형성할 probability나 node가 형성될 기회의 숫자가 차이가 나기 때문에 차이가 발생하게 된다. 특히 실제 모형의 확률은 정규 분포가 아니라 Power-law distribution이라는 것이 실제 연구를 통해서 밝혀졌으며, 이 분포를 따르게 되면 친구의 숫자가 최대 수백에서 수천배까지도 나게 된다. 따라서 이런 네트워크에서는 connection이 한 지점으로 몰리는 Hub가 존재하는데, 이 사실은 모든 node가 같은 connection을 가진다는 정규 네트워크의 가설과는 매우 다르다.</p>
<img src="/images/post/32-5.jpeg" width="300">
<p>Power-law distribution은 위의 그림에서 자세히 확인이 가능하다. 또한 이런 분포로 만들어진 네트워크의 모양은 아래 그림과 같다. Hub가 존재한다는 사실을 다시 한 번 생각해보고 그림을 보면 이해가 잘 될 것이다.</p><br/>
<img src="/images/post/32-6.jpg" width="300">
<img src="/images/post/32-7.png" width="300">
<p>이제 이런 경우에 대해서 node당 평균 10개의 connection이 있다고 다시 가정해보자. 비록 평균 connection이 10개가 있더라도, 정규 네트워크와는 다르게, power-law 네트워크는 한 node가 그 connection을 독식할 수도 있다. 즉, 이전에는 10개의 connection을 가진 1000개의 node가 있었다고 해보면, 지금은 그 중 하나의 connection이 모두 한 node에 쏠려 한 node가 1000개의 connection을 가지고 있는 셈이다.</p>
<p>이런 특이한 모양 (topology라고 한다) 때문에 생기는 특성 중 하나로는 확산의 형태가 다르다는 점이다. 정규 네트워크는 네트워크에서 어떤 무언가가 전파되는 데에 (간단하게 전염병이라고 생각해보자) 모두가 같은 connection을 가지고 있으므로 시간이 오래 걸리거나 일정 threshold를 넘지 못하면 전체 네트워크가 전염되지 않지만, Power-law Network에서는 그 threshold가 비교적 매우 작고, 몇 개의 hub만 감염이 되어도 모든 node가 influence될 수 있는 가능성이 엄청나게 커지는 것이다. 이 특성을 특정 hub를 격리하거나 백신을 투여해 전염병의 효율적 예방을 하는 데에 쓸 수도 있고, 마케팅의 측면에서 소비자 행동양식 변화 혹은 물건 구매 등으로 주변에 영향력이 큰 몇 명의 핵심 사용자들에게 무료로 물건을 나누어주거나 후기를 작성하게하는 등의 마케팅도 가능할 것이다.</p>
<p>이렇듯 실제 네트워크에서 발생하는 특성들을 사용하면 재미있는 결과가 나오게 된다. 과연 어떤 특성들이 있으며, 수학적으로 어떻게 증명하거나 접근해야하는지, 그리고 마지막으로 이런 특성들을 어떻게 사용할 것인지에 대해서는 다음 포스팅에서 자세히 다루도록 하겠다.</p></p>
]]></content>
  </entry>
  
</feed>
