
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>The Basic Principles in Deep Neural Networks - README</title>
  <meta name="author" content="Sanghyuk Chun">

  
  <meta name="description" content="2014/06/16 장민석 박사님의 Deep learning seminar 요약 내용">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://SanghyukChun.github.io/54">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/layout480.css" media="only screen and (max-width : 500px)" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="README" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
	<script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/bootstrap.js" type="text/javascript"></script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">



<script>
$(function() {
	$('.tip').attr('data-toggle','tooltip');
	$('.tip').attr('data-placement','top');
	$('.tip').tooltip();
});
</script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42711199-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  
	<div id="fb-root"></div>
	<script>(function(d, s, id) {
	  var js, fjs = d.getElementsByTagName(s)[0];
	  if (d.getElementById(id)) return;
	  js = d.createElement(s); js.id = id;
	  js.src = "//connect.facebook.net/ko_KR/all.js#xfbml=1&appId=182012898639519";
	  fjs.parentNode.insertBefore(js, fjs);
	}(document, 'script', 'facebook-jssdk'));</script>
  
  <div id="main">
  	<header role="banner"><hgroup>
  <h1><a id="blog-title" href="/">README</a>
  
    <span>&nbsp;&nbsp; SanghyukChun's Blog</span>
  
  </h1>
</hgroup>

</header>
  	<nav role="navigation"><ul class="main-navigation list-inline">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="http://sanghyuk.kaist.ac.kr/aboutMe/">About Me</a></li>
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
</ul>

</nav>
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">The Basic Principles in Deep Neural Networks</h1>
    
    
      <p class="meta text-right mB50">
        








  


<time datetime="2014-06-17T19:23:00+09:00" pubdate data-updated="true">Jun 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


<div class="entry-content"><h5>들어가기 전에</h5>


<p>이 포스트는 2014년 6월 16일 카이스트에서 유명한 Yoshua Bengio 교수님 연구실에서 포스트 닥터 과정을 밟고 계신 장민석 박사님의 The Basic Principles in Deep Neural Networks 라는 이름의 semiar를 요약한 내용이다. 내용은 주로 Deep learnining을 supervised learning, unsupervised learning의 관점에서 각각 바라보면서 어떤 컨셉들이고, 어떤 연구들이 진행이 되어있는지 훑어보는 정도의 간단한 내용이었다.</p>


<h5>Introduction</h5>


<p>Deep learning은 Machine Learning의 분야 중 하나이다. 그렇다면 Machine Learning은 무엇일까? 뭐 이거에 대한 얘기는 워낙 많이 했었고, 조만간 시간이 되면 내가 생각하고 있는 머신러닝에 대해 다시 포스팅을 할 예정이니 생략하도록 하겠다. 일단 이 세미나에서는 간단하게 머신러닝은 모델이 데이터에서 러닝하고 러닝한 데이터를 가지고 들어온 쿼리에 대해 answer하는 것이 머신러닝의 전부다! 라고 얘기해주셨다.</p>


<p>그리고 perception이라는 것에 대해서도 설명해주셨는데, 우리말로 하면 &#8216;인지&#8217; 정도 되겠다. 조금 더 구체적으로 얘기하면 내가 지금 인지하고 있는 물체에 대한 정보를 &#8216;안지&#8217; 하는 것이다. 즉, 내가 지금 읽고 있는 이 글이 어떤 철자를 가지고 있고 어떤 의미를 가지고 있는가에 대해 판단하는 것 아니면 사진 안에 있는 무언가가 고양이인지 개인지 확인하는 것, &#8216;인지&#8217;라는 단어가 한국어인지 일본어인지 판단하는 것들이 perception의 한 예라 할 수 있겠다. 우리는, 즉 사람은 이런 과정을 매우 손쉽게 하지만, 실제로 이것은 굉장히 어려운 작업이다. Deep learning이란 결국 사람이 perception을 어떻게 하는가를 기반으로 learning을 해보자라는 컨셉이다. 즉, Human learning에서 motive를 얻는 것인데, 사실 사람이 이런 인지를 한다는 것은 뇌에 의해서 일어나는 현상이며 사실은 물리적으로 매우 간단한 뉴런이라는 것들이 복합적으로 작용하면서 일어나는 것이다. 그렇기 때문에 사람의 뇌를 모방하여 매우 간단한 뉴런이라는 것들을 조합하여 인지 능력을 향상시키는 것이 Neural Network이고, 그것들을 또 폭발적으로 많이 조합한 것이 Deep learning이라 할 수 있겠다.</p>


<p>근데 사실 NN은 거의 4-50년 가까이된 무지하게 오래된 분야임 왜 이제와서 핫한가? 에 대한 질문이 있을 수 있다. history를 보면 더 명확해지는데, 아래의 리스트를 한 번 보자.</p>


<ul>
<li>1958 Rosenblatt proposed perceptrons</li>
<li>1980 Neocognitron (Fukushima, 1980)</li>
<li>1982 Hopfield network, SOM (Kohonen, 1982), Neural PCA (Oja, 1982)</li>
<li>1985 Boltzmann machines (Ackley et al., 1985)</li>
<li>1986 Multilayer perceptrons and backpropagation (Rumelhart et al., 1986) 1988 RBF networks (Broomhead&amp;Lowe, 1988)</li>
<li>1989 Autoencoders (Baldi&amp;Hornik, 1989), Convolutional network (LeCun, 1989) 1992 Sigmoid belief network (Neal, 1992)</li>
<li>1993 Sparse coding (Field, 1993)</li>
</ul>


<p>즉 우리가 지금 쓰고 있는 Neural network의 기본적인 연구는 이미 90년대 이전에 다 끝나있었다. 심지어 1995년에 Machine Learning에 어마어마한 연구 결과를 남긴 Vapnik과 Jackel이 10년 뒤인 2005년에 아무도 Neural net을 쓰고 있지 않을 것이라고 내기를 했을 정도니까.. 근데 갑자기 Deep learning이 정말 갑자기 빵! 하고 히트를 쳐버렸다. 그 배경을 보자면, ImageNet이라는 것이 있는데, 그냥 쉽게 생각하면 사진을 주고 어떤 물체인지 인식을 하는 일종의 race 비슷한 것이다. 그런데 그 이전까지 모든 최고의 image recognition 연구하는 사람들이 이뤄놓은 결과가 0.27 ~ 0.30정도 였는데 (아마 27%에서 30% 정도만 틀린다는 의미일 것이다) 갑자기 2012년에 Deep convolutional neural network를 하는 팀이 0.153으로 거의 2배 가까운 성능 향상을 보여주었다. 그리고 그 다음 해에는 상위 20개 팀에서 2개 팀 빼고 전부 Deep learning을 써서 Classification을 했다고 한다. 최고 성능은 또 0.117로 엄청나게 개선되고.</p>


<p>그리고 Deep learning을 기본 기술로 사용하는 스타트업도 엄청나게 늘어나고 있고, (<a href="http://techcrunch.com/2014/01/26/google-deepmind/" target="new">Deep learning 기술 회사인 Deep mind M 이상에 인수</a>, <a href="http://techneedle.com/archives/15662" target="new">Captcha 퍼즐 암호 99.8% 성공률로 해석</a>, <a href="http://www.technologyreview.com/news/525586/facebook-creates-software-that-matches-faces-almost-as-well-as-you-do/" target="new">사람의 얼굴 인식 능력을 상회하는 소프트웨어 개발</a>) 심지어 현재 구글이나 애플 등에서 음성 인식에 쓰는 알고리듬이 deep learning이라고 하니, 단순히 학계에서만 붐인 것이 아니라 산업에서도 엄청나게 핫하다고 할 수 있다.</p>


<p>아니 근데 그래서 Deep learning이 뭘까? 뭐가 Deep하다는 걸까? 기존 Machine Learning이랑은 무엇이 다를까? 등의 질문이 들 수밖에 없다.</p>


<p>기존 머신러닝은 크게 3단계로 이뤄진다. Feature engineering, Learning, Inference. 그렇기 때문에 맨 처음 Feature extraction에서 Data의 Domain knowledge과 general machine learning이 분리가 된다. 즉, 내가 image를 이용해 machine learning을 한다고 해서 Learning 알고리듬이나 Inference에 영향을 주지는 않는다. 그러나 실제로는 inference가 learning에도 영향을 미치고, domain knowledge에도 영향을 미치는 등, 이 세가지는 분리가 되어있지 않다. 그래서 초기 Deep learning은 1a Feature engineering 1b Feature/Representation learning 2. Learning 3. Inference. 이렇게 데이터에서 나온 learnign결과를 접목하여 성능을 개선시키려는 노력에서 부터 시작되었다고 한다. 현재 쓰이는 실제 딥러닝은 1. Jointly learn everything 2. Inference 단 두가지 단계로, 데이터 자체에서 모든 것을 처리하는 것이라고 한다. 아래 그림을 보면 조금 이해가 빠를 것 같다.</p>


<p><img src="/images/post/54-1.png" width="500">
<img src="/images/post/54-2.png" width="500">
<img src="/images/post/54-3.png" width="500"></p>

<p>세미나 중에 박사님께서 Yoshua Bengio교수님 얘기 중에서 상당히 인상적이라고 했었던 얘기라면서 해줬던 얘기가 &#8220;Let the data decides&#8221; 였다. 즉, 우리가 데이터에서 피쳐 뽑는데, 좋은 모델을 찾는데에 시간을 쓰지 말고, 처음부터 좋은 머신러닝 모델을 가져와서 데이터에서부터 좋은 결과를 만들어낼 수 있도록 데이터가 알아서 하게 해라.. 뭐 이런 얘기라고 한다.</p>


<p>아무도 쓰지 않던 Deep learning 혹은 Neural network를 갑자기 사람들이 많이 쓰는 이유는 결국 사람들이 따로따로 연구하던 PCA, Neural PCA, Probabilistic PCA, Autoencoder, Belief Network, Restricted Boltzmann Machine이 서로 각자의 특수한 케이스이거나 혹은 다른 표현형이라는 것이 알려지면서 결국 한 분야로 수렴하기도 하였고, 이제는 많은 것들이 알려져서 이전에는 learning하기 어려웠던 것들을 쉽게 learning할 수 있다고 한다. 특히 이제 더 이상 non-convex optimization에 대해 두랴워 할 필요가 없다는 것이 가장 큰 이유라고 한다. 또한 inference와 training사이의 interaction에 대해서도 더 많이 이해하고 있으며, 예전보다 computation power가 exponential하게 증가했으며 특히 GPU를 사용하게 되면 정말 계산량이 폭발적으로 늘어난다고 한다.</p>


<p><img src="/images/post/54-4.png" width="600"></p>

<p>위의 그림은 각 종과 현재 개발된 NN들의 뉴런 개수를 비교한 것이데 스케일은 log scale이다. 맨 처음 DBN이 나올 때만 해도 편충보다 뉴런이 조금 많고 거머리보다 10배 적었는데, 나중에 AlexNet에서는 개미보다 조금 많고 벌에 비해서 한참 적다. 그리고 여전히 우리는 개구리의 뉴런 개수보다 적은 양의 뉴런만을 가지고 있다. 사람이 가지고 있는 뉴런의 개수만큼 발전을 하려면 아직까지 갈 길이 멀다는 얘기이다. 단순히 뉴런의 개수를 늘릴 수 없는 이유는 역시 시간이 오래걸리기 때문이다. 아직까지도 발전할 여지는 많이 있는 학문이라는 뜻이려나.</p>


<h5>Supervised Neural Network</h5>


<p>이 부분에서는 neural network로 supervised learning, 특히 classification을 어떻게 푸는지에 대해 얘기가 되며, Multilayer perceptron과 그것의 learning, regularization, 그리고 기타 등등에 대해 다르게 될 것이다.</p>


<p>Supervised learning이란 무엇인가. 데이터가 \(D = { (x_1, y_1), (x_2, y_2), &#8230;, (x_N, y_N) }\) 으로 주어졌을 때, 어떤 assumption \(y_n = f^* (x_n) \)을 찾는 것이 supervised learning이라 할 수 있다. 이때, 주어진 데이터는 완벽한 데이터가 아니라 다소 noise가 끼어있다고 가정한다. 또한 이것을 D에 포함되지 않은 데이터에 대해 잘 설명할 수 있는 assumption을 찾는 것이 목표인데 이유는 모든 데이터가 noisy하다고 생각하기 때문이다.</p>


<p>Probabilistic view로 보면 Underlying distribution X and Y|X이 존재한다고 했을 때, 데이터는 이 distribution에서부터 만들어지는 것이라 생각할 수 있다. 이때 우리가 찾고자하는 assumption은 \(p(y|x\)가 된다. 마찬가지로 D에 속하지 않은 데이터에 대해서 잘 설명할 수 있는 distribution을 찾는 것이 목적이다.</p>


<p>근데 &#8216;잘&#8217; 설명한다는 것은 무엇일까. 즉, Evaluation and Generalization은 어떻게 하는 것일까. 이건 원래 함수를 f라고 하고 추측한 함수를 f* 라고 했을 때 아래 그림과 같은 방법으로 추측하게 된다. 그런데 이때 이것은 확률적으로 바라봤을 때 KL divergence와 동일하기 때문에 그 아래 그림과 같이 설명할 수도 있다. 보통은 MC approximation (샘플을 막 뽑아서 성능 특정)을 사용해서 우리가 가지고 있는 샘플 중 일부분을 추출해 제외하고 f*를 찾아서 그 에러를 줄이는 방식으로 테스트를 한다.</p>


<p><img src="/images/post/54-5.png" width="500"></p>

<p>근데 왜 D가 아닌 D test에 대해 솔루션을 찾을까? 이유는 우리가 가진 resource가 finite하기 때문이다. 만약 시간이 무한하면 우리가 취하고 있는 몬테카를로가 언젠가 진짜 확률로 수렴하겠지만, 우리가 가진 자원이 유한하기 때문에 반드시 샘플 에러가 발생하게 된다. 또한 실제로 이것이 굉장히 큰 문제이기 때문에 우리가 못 봤던 테스트 셋으로 테스트를 하여 성능을 측정하는 것이다.</p>


<p></p>

<p>자 뭐 이것의 대표적인 예로는 linear regression혹은 ridge, lasso 등이 있다고 설명을 해줬지만 사실 부연 설명에 불과하므로 패스. 그렇다면 우리가 흔히 말하는 MLP, multilayer perceptron도 이것으로 설명이 가능한데, 아래와 같다.</p>


<p><img src="/images/post/54-6.png" width="500"></p>

<p>맨 아래 식은 일종의 cost function에 대한 optimization이다. 그리고 우리는 이런 optimization을 하기 위한 알고리듬으로 gradient descent algorithm을 가지고 있는데, 이 방법의 문제는 모든 데이터에 대해 코스트를 계산하여 step을 진행하기 때문에 너무 느리다는 것이다. 따라서 우리는 수 많은 데이터들 중에서 하나만 골라서 업데이트를 하는 Stochastic Gradient Descent를 사용한다. 하지만 이 경우 Convex가 아니라면 둘이 서로 다른 곳으로 수렴을 하게 된다는 문제점이 발생하지만, 사실 크게 상관없다고 한다.</p>


<p>그리고 neural network에서 쓰는 Gradient descent method는 backpropagation이 있다. <a href="/42" taget="new">이전</a>에 설명했던 컨셉이니 생략하고, 중요한 점만 얘기하면, 이 방법을 쓰면 모든 노드의 derivative를 전부 계산할 필요가 없다는 것이다. 대신 우리는 매우 적은 양의 계산으로 마치 전체의 gradient를 계산한 것과 같은 효과를 얻을 수 있다.</p>


<p>여기에서 질문이 하나 나왔는데, 사실 이렇게 할 수 있는 이유는 chain rule을 적용할 수 있기 때문인데 (아까 건 링크 참고) 혹시 그렇다뎐 Hessian을 계산할 수는 없을까라는 질문이 나왔다. 결론적으로 말하자면, 실제 NN에서 Hessian 등의 2nd derivative를 계산하는 것은 매우 expensive하다는 것이며, 구현도 복잡하다고 한다. 대신 H를 직접 구하지 않고 그것의 역수를 계산하는 것들이 있긴 있다고 한다. 그러나 여전히 큰 NN에는 부적합하기 때문에 보통 Gradient를 사용한다고 한다.</p>


<p>Regularization &ndash; MAP.
Prob perspective: find a model M by ML (argmax p(D|M) ), MAP(argmax p(M|D) )
ML은 bayes rule! 둘을 쉽게 바꿀 수 있다.
prior distribution이 전체 model의 prob를 scope을 줄여주는 역할을 한다!
Regularization의 Omega term이 prior 역할을 하는 것.
NN의 Reg. (1) Weight Decay.
Prior: 모델은 너무 sharp하지 않다! 모델은 굉장히 smooth 할 것이다. theta_j ~ N(0, (M lambda)^-1 )
theta = argmin( loss function + lambda sum theta<sup>2</sup> )
(2) Smoothness and Noise Injection.
Input space의 굉장히 작은 부분만 관심이 있으니깐 그 부분에만 smooth하게 만들자.
instance 주변에도 비슷한 값이어야 한다. f(x) <del>~ f(x+e) &lt;=> min sum | d f(x<sup>n</sup>) / dx | ^2
&lt;=> 근데 이걸 계산하는건 계산할 때 마다 white Gaussian noise를 넣어서 계산하는 것과 동일한 결과를 낸다 1995 Bishop
(3) Ensemble learning and dropout
computation이 빨라졌으니까, 한 50개 learning하고 그걸 가지고 ensemble learning하자!
예전에는 트레이닝이 잘 안되서 잘 안했던건데, 이제는 트레이닝이 잘 되니까 그게 잘 된다
아이디어: NN을 learning할 때 마다 서로 다른 preprocessing을 하고나서 모아서 averaging 하자 object recognition은 사람보다 성능이 좋음 헐 ㅋㅋ
(4) dropout.
하나만 배우면서 exponentially many classifiers를 하자! 힌튼 2012
매번 feedforward를 할 때마다 random하게 node 를  drop하자.
수학적으로 얘기하면, lower bound를 optimization을 한다. 하고 안하고는 10</del>20% gain을 늘린다.
실제로 쓰기에는 너무 variation이 크다. 그래서 실제 classification에 좋은 결과가 안나올 수 있음. 그래서 activation을 절반으로 까는 방식으로!
결과적으로 0.5를 드랍, 0.5를 까는 것이 general하게 좋은 것으로 보인다.
다른 식으로 값을 러닝해보자는 아이디어로 해봤더니 값이 전부 0.5로 컨벌지 하더라 헐 ㅋㅋㅋㅋㅋ</p>

<p>Common Recipe for DNN.
1. User a piecewise linear hidden unit. (Rectifier, Maxout) => max{0,x} h({x1m,, xp}) = max {x1, ,,,,, xp). differentiable하지 않은데? sub gradient랑 비슷하고, 아니면 dropout이랑 비슷하게 생각하면 됨. 계속 NN을 다른 것을 쓴다고 보면 됨. 0이 되었던 애들은 뉴런이 없다고 보고.. 뭐 결국 sub gradient라고 하네요
2. Preprocess data and choose features carefully. Image: Whitening, Raw, SIFT, HoG, Speech: Raw? Spectrum?, Text: Characters? words? tree?, General: z-Normalization?
3. User Dropout and other regularization methods
4. Unsuperviesd Pretraining (Hinton et al 2006) &ndash;> a lot a unlabeled samples. label 데이터 많으면 안해도 된다네요
5. Carefully search for hyperparameters (Random search, Bayesian optimization..) => greed search 하면 exponential하게 많아서 안됨 ㅠㅠ
6. Often, deeper the better (이미지 &ndash; 레이어 7개 이상, 스피치 &ndash; 12개, 14개… 막 올라감, 그 이외에는 hyper parameter. 보통 난 2개 부터 시작한다)
7. Build and ensemble of neural networks
8. Use GPU. 파워랑 보드 좋은거 사야하고 쿨링 잘하고 전기세 조심하고..</p>

<p>Hessian의 값이 너무 크고, 그러니까 계산하기도 힘들고 저장도 하기 힘들고 그걸 inverse 하는건 더 힘들고!!
가장 큰 단점은 stochastic method가 없다 한 업데이트가 너무 expensive하다 ㅠㅠ
그러니깐 2nd order가 좋은건 알고 있고, 진짜 이론적으로 좋지만, in practice, 실제로는 model이 너무 크기 때문에 힘들다 으엉 ㅠㅠ</p>

<p>Domain Knowledge?
Data Preprocessing and feature extraction… Contrast normalization, Relative coordinate, Bag-of-Words representation.
NN의 좋은 점. 예를 들어서 SVM은 튜닝할 여지가 거의 없지만, NN은 처음부터 domain knowledge를 적용해서 model을 만들 수 있음.
ex. Convolutional Neural Network: Translation, Rotation, Temporal, Frequency invariance
Convolution and Pooling
Convolution: filter 하나만 가지고 전부 적용하면 된다
Pooling: local에서 계산한 convolution의 max를 취하고,… 뭐 그래서 구하는 듯
Convolution layer
1. Contrast Normalization
2. Convolution
3. Pooling
4. NonLinearity
Deep CNN: conv layer를 무지하게 쌓고 마지막에 full connection을 이어준다.</p>

<p>Recursive Neural Network (RNN)
Text: Compositional Structure. Tree 형태가 된다.
근데 문장에 따라 tree가 달라져 ㅠㅠ
아이디어: 같은 NN을 모든 tree의 edge에 apply를 한다 ( input NP, VP => S )
sentence &ndash;> parser로 쪼갬 &ndash;> filter를 NN으로 갈아낌</p>

<p>Unsupervised learning
Label이 없다!
DNN을 써서 visualization.</p>

<p>Feature extraction. => without domain knowledge &ndash;> learned feature!!
Generative Model.
Underlying diet. X~Pr(D)</p>

<p>Classification, Missing value reconstruction, Denoising, Structured Output Prediction, Outlier Detection.
Ultimately it comes down to learning a diet of x.</p>

<p>Density/Distribution Estimation.
Latent Variable Models p(x). Define a parametric form of joint dist. Derive a learning rule for theta.
RBM. Markov random field 의 특정 케이스.
Joint distribution, Marginal distribution.. Learning rule Maximum Likelihood.
Belief Network. Joint distribution은 구할 수 있음. Marginal distribution… 못구함. MLE로 learning. (중요하지 않음)
NADE. no latent variable h. Joint dist = Marginal dist. condition들을 NN으로 모델링하자. ML. (중요하지 않음)
Intractability!!!!
Boltzmann Machine. 다 어려움.
RBM. Marginal Probability, Posterior Prob를 구할 수 있지만 normalization constant와 conditional prob가 어려움.
Belief net norm만 없음
NADE nomr x margi x posterior x. 근데 conditional prob가 잘 안됨. 그리고 퍼포먼스가 안좋다.</p>

<p>GM &ndash; learning to infer
All we want is to infer the conditional diet of unknown variables.
Approximate Inference in a Graphical Model. p(x_mis|x_obs) ~~ Q(x_mis|x_obs)
Methods: Loopy belief propagation, variational inference/message-passing
Q<sup>k</sup>(x_mis|x_obs) = f(Q<sup>k-1</sup> (x_mis|x_obs) ). => chain 처럼 이을 수 있음</p>

<p>NADE-k. => graphical 하게 시작한 RBM같은 애들은 structure가 고정되는데 얘는 이런 모델을 만들고 싶으면 그냥 만들면 된다
Lesson!!!
Do not maximize log-likelihood but minimize actual cost!
&lt;=> Don’t do what model tells you to do but do what you aim to do.
… popular science journalists don’t care about GM ㅠㅠ</p>

<p>Manifold learning &ndash; semi supervised learning
GM이 뜨는 이유는 Pre training은 왜 하는가..? 그냥 하는게 아니다
Classification이라는 hot한 supervised learning의 task에서도 unlabled data가 performance를 향상시킨다.
Manifold learning &ndash; New representation
1. phi should reflect changes along the manifold 2. phi should not change for orthogonal noise
문제. representation을 어떻게 learnig할 것이며 어떻게 transform할 것이냐
Solution. Denosing Autoencoder.
manifold…</p>

<p>Semi-supervised learning in action (1) Layer-wise Pretraining
manifold를 어떻게 러닝할 것이냐 data를 스트레칭 아웃. 원래 데이터가 구석에 있었는데 representation을 진행할 때 마다 다른empty space를 무시하게..
각각 pretraining하는 데이터는 label이 있거나 없거나 상관없다. unsupervised learning으로 끝나버린다. hyperparameter의 개수와 sensitivity가 크게 줄어든다.
visualizaion에 쓴다. manifold embedding and visualization.
non linear visualization은 non parametic. 새 data가 들어오면 새로 learning해야 함.
하지만 autoencoder는 parametric model이라 그냥 feed forward만 하면 된다.</p>

<p>What other applications for unsupervised DNN?
Deep Reinforcement learning.. NN의 input을 state 로 하여 새로운 function을 define
NLP.. Natural Language is a huge set of variable length sequences of high dim vectors.
Hugh set. 데이터가 어마어마하지만 실제 set도 커버 못함. 거기에 input까지 variable length ㅠㅠ sequence도 high dim vector 으앙
시멘틱을 보존하면서 encoding&hellip;</p>

<p>random function은 high dimension local optima가 e로 bound가 된다고 하네요. 많아도 다 비슷한 값을 가진다. 근데 뭐가 문제? flat한 지점이 무지하게 많은겨 (saddle point)
Saddle point를 벗어나는 방법은? 2nd order method! … 오히려 2nd order를 쓰면 그 지점들에 멈추는 경우가 많음.
Saddle-Free Newton Method (<a href="http://arxiv.org/pdf/1406.2572.pdf">http://arxiv.org/pdf/1406.2572.pdf</a>)</p>

<p>Deep Neural Network를 보면 Theory가 거의 없다.. 사실 많이 되어있다. 특히 circuit theory, dynamics.. 등으로 할 수 있음
근데 그 어떤 것도 Rectifier에 대해 분석한게 없다 최근 좀 되고 있음 (<a href="http://arxiv.org/pdf/1402.1869.pdf">http://arxiv.org/pdf/1402.1869.pdf</a>)</p>
</div>

<hr>
  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Sanghyuk Chun</span></span>

      








  


<time datetime="2014-06-17T19:23:00+09:00" pubdate data-updated="true">Jun 17<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/machine-learning/'>Machine-Learning</a>, <a class='category' href='/blog/categories/neural-network/'>Neural-Network</a>, <a class='category' href='/blog/categories/seminar/'>Seminar</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://SanghyukChun.github.io/54/" data-via="SanghyukChun" data-counturl="http://SanghyukChun.github.io/54/" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="380" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/53/" title="Previous Post: 나의 창작욕에 대하여">&laquo; 나의 창작욕에 대하여</a>
      
      
        <a class="basic-alignment right" href="/55/" title="Next Post: 2014 ICML 후기">2014 ICML 후기 &raquo;</a>
      
    </p>
  </footer>
</article>


  <section>
    <h1>Comments</h1>
    <div id="facebook_comments" aria-live="polite">
      <div class="fb-comments" data-href="http://SanghyukChun.github.io/54/" data-width="400" data-num-posts="10"></div>
    </div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/56/">2014년 2분기 회고</a>
      </li>
    
      <li class="post">
        <a href="/55/">2014 ICML 후기</a>
      </li>
    
      <li class="post">
        <a href="/54/">The Basic Principles in Deep Neural Networks</a>
      </li>
    
      <li class="post">
        <a href="/53/">나의 창작욕에 대하여</a>
      </li>
    
      <li class="post">
        <a href="/52/">Network Science - Scale Free Network (Barabasi-Albert Network)</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/SanghyukChun">@SanghyukChun</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'SanghyukChun',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Sanghyuk Chun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=182012898639519&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
